{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80e17eff",
   "metadata": {},
   "source": [
    "다음을 리뷰 :\n",
    "https://github.com/Project-MONAI/tutorials/blob/master/3d_segmentation/ignite/unet_training_array.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b88021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib    # nifti 포맷 파일 생성때만 이용\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import monai\n",
    "## decollate_batch : 배치 텐서를 리스트의 텐서로 변환\n",
    "from monai.data import ImageDataset, create_test_image_3d, decollate_batch\n",
    "from monai.transforms import (\n",
    "    Activations, \n",
    "    AddChannel, \n",
    "    AsDiscrete, \n",
    "    Compose, \n",
    "    RandRotate90,\n",
    "    RandSpatialCrop, \n",
    "    Resize,\n",
    "    ScaleIntensity, \n",
    "    EnsureType\n",
    ")\n",
    "\n",
    "# 삭제\n",
    "# from monai.metrics import DiceMetric\n",
    "# from monai.inferers import sliding_window_inference\n",
    "# from monai.visualize import plot_2d_or_3d_image\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "## 새롭게 추가\n",
    "\n",
    "# Events : process point를 지정 Events.EPOCH_COMPETED\n",
    "from ignite.engine import Events, create_supervised_evaluator, create_supervised_trainer\n",
    "# ModelCheckpoint : training 동안 모델 계속 저장\n",
    "from ignite.handlers import EarlyStopping, ModelCheckpoint\n",
    "from monai.handlers import (\n",
    "    MeanDice,          # val_metric {}를 정의시 넣음\n",
    "    StatsHandler,      # 각 epoch마다 loss, metric 출력\n",
    "    TensorBoardImageHandler,\n",
    "    TensorBoardStatsHandler,    # 각 epoch마다 loss, metric plot\n",
    "    stopping_fn_from_metric,    # ignite EarlyStopping 과 연결, metric기준 stopping\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "562c9694",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff3a3139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.9.dev2152\n",
      "Numpy version: 1.21.2\n",
      "Pytorch version: 1.8.1+cu102\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: c5bd8aff8ba461d7b349eb92427d452481a7eb72\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.6\n",
      "Nibabel version: 3.2.1\n",
      "scikit-image version: 0.18.3\n",
      "Pillow version: 8.4.0\n",
      "Tensorboard version: 2.6.0\n",
      "gdown version: 4.2.0\n",
      "TorchVision version: 0.11.0a0\n",
      "tqdm version: 4.62.3\n",
      "lmdb version: 1.2.1\n",
      "psutil version: 5.8.0\n",
      "pandas version: 1.3.4\n",
      "einops version: 0.3.2\n",
      "transformers version: 4.12.5\n",
      "mlflow version: 1.21.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "generating synthetic data to ./dataset (this may take a while)\n",
      "torch.Size([2, 1, 96, 96, 96]) torch.Size([2, 1, 96, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "tempdir = './dataset'\n",
    "monai.config.print_config()\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '6'\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '5,6'\n",
    "\n",
    "## 디렉토리에 40개 랜덤이미지, 마스크 생성\n",
    "print(f\"generating synthetic data to {tempdir} (this may take a while)\")\n",
    "for i in range(40):\n",
    "    # np image 생성\n",
    "    im, seg = create_test_image_3d(128, 128, 128, num_seg_classes=1)  \n",
    "#     print(type(im), type(seg))  # np.array\n",
    "#     print(im.shape, seg.shape)  # (128, 128, 128) (128, 128, 128) 3d 라서 img, seg가 같은 dim인 듯?\n",
    "\n",
    "    n = nib.Nifti1Image(im, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, f\"img{i:d}.nii.gz\"))\n",
    "\n",
    "    n = nib.Nifti1Image(seg, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, f\"seg{i:d}.nii.gz\"))\n",
    "\n",
    "## 파일이름들 가져오기\n",
    "images = sorted(glob(os.path.join(tempdir, \"im*.nii.gz\")))    # 40개 nifti file 리스트\n",
    "segs = sorted(glob(os.path.join(tempdir, \"seg*.nii.gz\")))\n",
    "\n",
    "## transform 정의\n",
    "train_imtrans = Compose(\n",
    "    [\n",
    "        ScaleIntensity(),\n",
    "        AddChannel(),\n",
    "        # aug\n",
    "        RandSpatialCrop((96, 96, 96), random_size=False),\n",
    "#         RandRotate90(prob=0.5, spatial_axes=(0, 2)),\n",
    "        EnsureType(),\n",
    "    ]\n",
    ")\n",
    "train_segtrans = Compose(\n",
    "    [\n",
    "        # 스케일링 필요없나 봄 (1또는 0이므로)\n",
    "        AddChannel(),\n",
    "        # aug (img와 같은 aug를 해주는가..? -> 맞음.. 왜인진.. 모름)\n",
    "        RandSpatialCrop((96, 96, 96), random_size=False),\n",
    "#         RandRotate90(prob=0.5, spatial_axes=(0, 2)),\n",
    "        EnsureType(),\n",
    "    ]\n",
    ")\n",
    "val_imtrans = Compose([ScaleIntensity(), AddChannel(), Resize((96, 96, 96)), EnsureType()])\n",
    "val_segtrans = Compose([AddChannel(), Resize((96, 96, 96)), EnsureType()])\n",
    "\n",
    "## define image dataset, data loader\n",
    "check_ds = ImageDataset(\n",
    "    images, segs, transform=train_imtrans, seg_transform=train_segtrans\n",
    ")\n",
    "check_loader = DataLoader(\n",
    "    check_ds, batch_size=2, num_workers=2, \n",
    "#     pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "im, seg = monai.utils.misc.first(check_loader)\n",
    "print(im.shape, seg.shape)\n",
    "\n",
    "## train, val loader\n",
    "train_ds = ImageDataset(\n",
    "    images[:20], segs[:20], transform=train_imtrans, seg_transform=train_segtrans\n",
    ")\n",
    "# num_workers = 4 * torch.cuda.device_count()\n",
    "train_loader = DataLoader(\n",
    "    train_ds, \n",
    "    batch_size=4, \n",
    "    shuffle=True, \n",
    "    num_workers=4, \n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "val_ds = ImageDataset(\n",
    "    images[-20:], segs[-20:], transform=val_imtrans, seg_transform=val_segtrans\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=2, num_workers=2, pin_memory=torch.cuda.is_available()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d798e20",
   "metadata": {},
   "source": [
    "### ~~(post-proc)~~, ~~(metric)~~, model 정의\n",
    "\n",
    "차이\n",
    "* metric(for valid) 정의, post-proc들이 ignite valid 아랫과정으로 넘어감\n",
    "* post-proc 과정이 하나 더생김(label에다 적용하는데 안해도 될듯.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0e797dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A100-SXM4-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the A100-SXM4-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = monai.networks.nets.UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)\n",
    "\n",
    "# net = monai.networks.nets.UNet(\n",
    "#     spatial_dims=3,\n",
    "#     in_channels=1,\n",
    "#     out_channels=1,\n",
    "#     channels=(16, 32, 64, 128, 256),\n",
    "#     strides=(2, 2, 2, 2),\n",
    "#     num_res_units=2,\n",
    "# )\n",
    "# net = nn.DataParallel(net, device_ids = [4,5,6,7])\n",
    "# net.cuda()\n",
    "\n",
    "\n",
    "\n",
    "loss = monai.losses.DiceLoss(sigmoid=True)\n",
    "opt = torch.optim.Adam(net.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5e9dea",
   "metadata": {},
   "source": [
    "### Ignite - training 관련 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edda7dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignite trainer expects batch=(img, seg) and returns output=loss at every iteration,\n",
    "# user can add output_transform to return other values, like: y_pred, y, etc.\n",
    "trainer = create_supervised_trainer(net, opt, loss, device, False)\n",
    "\n",
    "\n",
    "###### !!Check Point!! : 모델 저장\n",
    "checkpoint_handler = ModelCheckpoint(\n",
    "    dirname=\"./runs_array/\",\n",
    "    filename_prefix=\"net\",\n",
    "    n_saved=5,    # 딱 10개만 저장, 더 업데이트 되면 덮어쓰기\n",
    "    require_empty=False  # True: 기존 모델이 dir에 있다면 덮어쓰지 않고 오류\n",
    ")\n",
    "trainer.add_event_handler(\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    handler=checkpoint_handler,\n",
    "    to_save={\"net\": net, \"opt\": opt}    # opt는 딱히 뭔진 모르겠음\n",
    ")\n",
    "\n",
    "###### !! StatsHandler!! : 각 iter와 각 epoch 마다 loss와 metrics를 출력\n",
    "# StatsHandler prints loss at every iteration and print metrics at every epoch,\n",
    "# we don't set metrics for trainer here, so just print loss, user can also customize print functions\n",
    "# and can use output_transform to convert engine.state.output if it's not a loss value\n",
    "# trainer에 metrics만 설정 해뒀다면 loss뿐 아니라 프린트를 커스터 마이징 가능(여기엔 안되어 있음)\n",
    "train_stats_handler = StatsHandler(name=\"trainer\", output_transform=lambda x: x)\n",
    "train_stats_handler.attach(trainer)\n",
    "\n",
    "###### !! TensorBoardStatsHandler!! : 각 iter, epoch마다 loss와 metric을 plot. statshandler와 같음\n",
    "# TensorBoardStatsHandler plots loss at every iteration and plots metrics at every epoch, same as StatsHandler\n",
    "train_tensorboard_stats_handler = TensorBoardStatsHandler(output_transform=lambda x:x)\n",
    "train_tensorboard_stats_handler.attach(trainer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70b8231",
   "metadata": {},
   "source": [
    "### Ignite-valid 관련 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2457df5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=30.\n",
      "ERROR:ignite.engine.engine.Engine:Current run is terminating due to exception: Unable to find a valid cuDNN algorithm to run convolution\n",
      "ERROR:trainer:Exception: Unable to find a valid cuDNN algorithm to run convolution\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 834, in _run_once_on_dataset\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/__init__.py\", line 92, in update\n",
      "    y_pred = model(x)\n",
      "  File \"/home/ducke/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/networks/nets/unet.py\", line 281, in forward\n",
      "    x = self.model(x)\n",
      "  File \"/home/ducke/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ducke/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 119, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/ducke/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/networks/blocks/convolutions.py\", line 324, in forward\n",
      "    res: torch.Tensor = self.residual(x)  # create the additive residual from x\n",
      "  File \"/home/ducke/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ducke/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 520, in forward\n",
      "    return F.conv3d(input, self.weight, self.bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: Unable to find a valid cuDNN algorithm to run convolution\n",
      "ERROR:trainer:Exception: Unable to find a valid cuDNN algorithm to run convolution\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 744, in _internal_run\n",
      "    time_taken = self._run_once_on_dataset()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 848, in _run_once_on_dataset\n",
      "    self._handle_exception(e)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 467, in _handle_exception\n",
      "    self._fire_event(Events.EXCEPTION_RAISED, e)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 424, in _fire_event\n",
      "    func(*first, *(event_args + others), **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/handlers/stats_handler.py\", line 158, in exception_raised\n",
      "    raise e\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 834, in _run_once_on_dataset\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/__init__.py\", line 92, in update\n",
      "    y_pred = model(x)\n",
      "  File \"/home/ducke/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/networks/nets/unet.py\", line 281, in forward\n",
      "    x = self.model(x)\n",
      "  File \"/home/ducke/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ducke/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 119, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/ducke/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/networks/blocks/convolutions.py\", line 324, in forward\n",
      "    res: torch.Tensor = self.residual(x)  # create the additive residual from x\n",
      "  File \"/home/ducke/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ducke/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 520, in forward\n",
      "    return F.conv3d(input, self.weight, self.bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unable to find a valid cuDNN algorithm to run convolution",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43108/1976783206.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mtrain_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_handlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_fire_event\u001b[0;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mothers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/handlers/stats_handler.py\u001b[0m in \u001b[0;36mexception_raised\u001b[0;34m(self, _engine, e)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \"\"\"\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_default_epoch_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Current run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_handlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_fire_event\u001b[0;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mothers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/handlers/stats_handler.py\u001b[0m in \u001b[0;36mexception_raised\u001b[0;34m(self, _engine, e)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \"\"\"\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_default_epoch_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/networks/nets/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/networks/blocks/convolutions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# create the additive residual from x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0mcx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# apply x to sequence of operations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mres\u001b[0m  \u001b[0;31m# add the residual to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    518\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_triple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m                             self.dilation, self.groups)\n\u001b[0;32m--> 520\u001b[0;31m         return F.conv3d(input, self.weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    521\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unable to find a valid cuDNN algorithm to run convolution"
     ]
    }
   ],
   "source": [
    "post_pred = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(threshold=0.5)])   # 정답(label)에 대한 post-proc\n",
    "metric_name = \"Mean_Dice\"\n",
    "val_metrics = {metric_name: MeanDice()}\n",
    "validation_every_n_epochs = 1\n",
    "\n",
    "## post-processing과정이 까다롭다..\n",
    "evaluator = create_supervised_evaluator(\n",
    "    net,\n",
    "    val_metrics,\n",
    "    device,\n",
    "    True,\n",
    "    # 순서 바꿔도 되야하지 않나\n",
    "    output_transform=lambda x, y, y_pred: ([post_pred(i) for i in decollate_batch(y_pred)], [post_label(i) for i in decollate_batch(y)]),\n",
    ")\n",
    "\n",
    "###### !! evaluator proc 정의 !!\n",
    "@trainer.on(Events.EPOCH_COMPLETED(every=validation_every_n_epochs))\n",
    "def run_validation(engine):\n",
    "    evaluator.run(val_loader)\n",
    "\n",
    "###### !! EarlyStopping !!\n",
    "early_stopper = EarlyStopping(\n",
    "    patience=4,\n",
    "    score_function=stopping_fn_from_metric(metric_name),\n",
    "    trainer=trainer\n",
    ")\n",
    "evaluator.add_event_handler(\n",
    "    event_name=Events.EPOCH_COMPLETED, \n",
    "    handler=early_stopper\n",
    ")\n",
    "\n",
    "###### !! StatsHandler!! : 각 iter와 각 epoch 마다 loss와 metrics를 출력 for validation\n",
    "val_stats_handler = StatsHandler(\n",
    "    name=\"evaluator\",\n",
    "    output_transform=lambda x: None,   # no need to print loss value, so disable per iteration output\n",
    "    global_epoch_transform=lambda x: trainer.state.epoch,    # trainer에서 global epoch number 가져오기\n",
    ")\n",
    "val_stats_handler.attach(evaluator)\n",
    "\n",
    "###### !! TensorBoardStatsHandler!! : 각 iter, epoch마다 loss와 metric을 plot. statshandler와 같음\n",
    "val_tensorboard_stats_handler = TensorBoardStatsHandler(\n",
    "    output_transform=lambda x: None,  # no need to plot loss value, so disable per iteration output\n",
    "    global_epoch_transform=lambda x: trainer.state.epoch,\n",
    ")\n",
    "val_tensorboard_stats_handler.attach(evaluator)\n",
    "\n",
    "###### !! TensorBoardImageHandler!! : 마지막 배치(?)에서 첫 번째 이미지와 해당 레이블 및 모델 출력을 그리는 핸들러 추가.\n",
    "# 매 validation spoch에서 그림그리기\n",
    "# add handler to draw the first image and the corresponding label and model output in the last batch\n",
    "# here we draw the 3D output as GIF format along Depth axis, at every validation epoch\n",
    "\n",
    "# batch_transform : ignite.engine.state.batch 에서 이미지와 레이블 가져올 수 있음\n",
    "# output_transform : ignite.engine.state.output 에서 prediction 결과 이미지 가져옴, output[index] index는 몇번째 element인지\n",
    "val_tensorboard_image_handler = TensorBoardImageHandler(\n",
    "    batch_transform=lambda batch: (batch[0], batch[1]),\n",
    "    output_transform=lambda output: output[0],\n",
    "    global_iter_transform=lambda x: trainer.state.epoch,\n",
    ")\n",
    "evaluator.add_event_handler(\n",
    "    event_name=Events.EPOCH_COMPLETED, handler=val_tensorboard_image_handler\n",
    ")\n",
    "\n",
    "train_epochs = 30\n",
    "state = trainer.run(train_loader, train_epochs)\n",
    "print(state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89068fec",
   "metadata": {},
   "source": [
    "logging을 주면 standardOUT 으로 확인 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef243be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ignite.engine.events.State,\n",
       " ['__class__',\n",
       "  '__delattr__',\n",
       "  '__dict__',\n",
       "  '__dir__',\n",
       "  '__doc__',\n",
       "  '__eq__',\n",
       "  '__format__',\n",
       "  '__ge__',\n",
       "  '__getattribute__',\n",
       "  '__gt__',\n",
       "  '__hash__',\n",
       "  '__init__',\n",
       "  '__init_subclass__',\n",
       "  '__le__',\n",
       "  '__lt__',\n",
       "  '__module__',\n",
       "  '__ne__',\n",
       "  '__new__',\n",
       "  '__reduce__',\n",
       "  '__reduce_ex__',\n",
       "  '__repr__',\n",
       "  '__setattr__',\n",
       "  '__sizeof__',\n",
       "  '__str__',\n",
       "  '__subclasshook__',\n",
       "  '__weakref__',\n",
       "  '_update_attrs',\n",
       "  'batch',\n",
       "  'dataloader',\n",
       "  'epoch',\n",
       "  'epoch_length',\n",
       "  'event_to_attr',\n",
       "  'get_event_attrib_value',\n",
       "  'iteration',\n",
       "  'max_epochs',\n",
       "  'metrics',\n",
       "  'output',\n",
       "  'seed',\n",
       "  'times'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state 확인가능 한지 보자.\n",
    "type(state), dir(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afede207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 96, 96, 96])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch는 마지막 배치\n",
    "state.batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2fbc537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9895de4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17da8c5a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e2c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142778aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "295ab862",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f0678e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.9.dev2152\n",
      "Numpy version: 1.21.2\n",
      "Pytorch version: 1.10.0a0+0aef44c\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: c5bd8aff8ba461d7b349eb92427d452481a7eb72\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.6\n",
      "Nibabel version: 3.2.1\n",
      "scikit-image version: 0.18.3\n",
      "Pillow version: 8.4.0\n",
      "Tensorboard version: 2.6.0\n",
      "gdown version: 4.2.0\n",
      "TorchVision version: 0.11.0a0\n",
      "tqdm version: 4.62.3\n",
      "lmdb version: 1.2.1\n",
      "psutil version: 5.8.0\n",
      "pandas version: 1.3.4\n",
      "einops version: 0.3.2\n",
      "transformers version: 4.12.5\n",
      "mlflow version: 1.21.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "generating synthetic data to ./dataset (this may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 08:23:07,428 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State:\n",
      "\titeration: 160\n",
      "\tepoch: 32\n",
      "\tepoch_length: 5\n",
      "\tmax_epochs: 50\n",
      "\toutput: 0.4166615605354309\n",
      "\tbatch: <class 'list'>\n",
      "\tmetrics: <class 'dict'>\n",
      "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "\tseed: <class 'NoneType'>\n",
      "\ttimes: <class 'dict'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '5,6'\n",
    "\n",
    "monai.config.print_config()\n",
    "tempdir = './dataset'\n",
    "\n",
    "# create a temporary directory and 40 random image, mask pairs\n",
    "print(f\"generating synthetic data to {tempdir} (this may take a while)\")\n",
    "for i in range(40):\n",
    "    im, seg = create_test_image_3d(128, 128, 128, num_seg_classes=1)\n",
    "\n",
    "    n = nib.Nifti1Image(im, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, f\"im{i:d}.nii.gz\"))\n",
    "\n",
    "    n = nib.Nifti1Image(seg, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, f\"seg{i:d}.nii.gz\"))\n",
    "\n",
    "images = sorted(glob(os.path.join(tempdir, \"im*.nii.gz\")))\n",
    "segs = sorted(glob(os.path.join(tempdir, \"seg*.nii.gz\")))\n",
    "\n",
    "# define transforms for image and segmentation\n",
    "train_imtrans = Compose(\n",
    "    [\n",
    "        ScaleIntensity(),\n",
    "        AddChannel(),\n",
    "        RandSpatialCrop((96, 96, 96), random_size=False),\n",
    "        RandRotate90(prob=0.5, spatial_axes=(0, 2)),\n",
    "        EnsureType(),\n",
    "    ]\n",
    ")\n",
    "train_segtrans = Compose(\n",
    "    [AddChannel(), RandSpatialCrop((96, 96, 96), random_size=False), \n",
    "     RandRotate90(prob=0.5, spatial_axes=(0, 2)), EnsureType()]\n",
    ")\n",
    "val_imtrans = Compose(\n",
    "    [ScaleIntensity(), AddChannel(), Resize((96, 96, 96)), EnsureType()]\n",
    ")\n",
    "val_segtrans = Compose([AddChannel(), Resize((96, 96, 96)), EnsureType()])\n",
    "\n",
    "# # define image dataset, data loader\n",
    "# check_ds = ImageDataset(\n",
    "#     images, segs, transform=train_imtrans, seg_transform=train_segtrans\n",
    "# )\n",
    "# check_loader = DataLoader(\n",
    "#     check_ds, batch_size=10, num_workers=2, pin_memory=torch.cuda.is_available()\n",
    "# )\n",
    "# im, seg = monai.utils.misc.first(check_loader)\n",
    "# print(im.shape, seg.shape)\n",
    "\n",
    "# create a training data loader\n",
    "train_ds = ImageDataset(\n",
    "    images[:20], segs[:20], transform=train_imtrans, seg_transform=train_segtrans\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "# create a validation data loader\n",
    "val_ds = ImageDataset(\n",
    "    images[-20:], segs[-20:], transform=val_imtrans, seg_transform=val_segtrans\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=2, num_workers=4, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "# create UNet, DiceLoss and Adam optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = monai.networks.nets.UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)\n",
    "loss = monai.losses.DiceLoss(sigmoid=True)\n",
    "lr = 1e-3\n",
    "opt = torch.optim.Adam(net.parameters(), lr)\n",
    "\n",
    "# Ignite trainer expects batch=(img, seg) and returns output=loss at every iteration,\n",
    "# user can add output_transform to return other values, like: y_pred, y, etc.\n",
    "trainer = create_supervised_trainer(net, opt, loss, device, False)\n",
    "\n",
    "# adding checkpoint handler to save models (network params and optimizer stats) during training\n",
    "checkpoint_handler = ModelCheckpoint(\n",
    "    \"./runs_array/\", \"net\", n_saved=10, require_empty=False\n",
    ")\n",
    "trainer.add_event_handler(\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    handler=checkpoint_handler,\n",
    "    to_save={\"net\": net, \"opt\": opt},\n",
    ")\n",
    "\n",
    "# StatsHandler prints loss at every iteration and print metrics at every epoch,\n",
    "# we don't set metrics for trainer here, so just print loss, user can also customize print functions\n",
    "# and can use output_transform to convert engine.state.output if it's not a loss value\n",
    "train_stats_handler = StatsHandler(name=\"trainer\", output_transform=lambda x: x)\n",
    "train_stats_handler.attach(trainer)\n",
    "\n",
    "# TensorBoardStatsHandler plots loss at every iteration and plots metrics at every epoch, same as StatsHandler\n",
    "train_tensorboard_stats_handler = TensorBoardStatsHandler(output_transform=lambda x: x)\n",
    "train_tensorboard_stats_handler.attach(trainer)\n",
    "\n",
    "validation_every_n_epochs = 1\n",
    "# Set parameters for validation\n",
    "metric_name = \"Mean_Dice\"\n",
    "# add evaluation metric to the evaluator engine\n",
    "val_metrics = {metric_name: MeanDice()}\n",
    "\n",
    "post_pred = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(threshold=0.5)])\n",
    "\n",
    "# Ignite evaluator expects batch=(img, seg) and returns output=(y_pred, y) at every iteration,\n",
    "# user can add output_transform to return other values\n",
    "evaluator = create_supervised_evaluator(\n",
    "    net,\n",
    "    val_metrics,\n",
    "    device,\n",
    "    True,\n",
    "    output_transform=lambda x, y, y_pred: ([post_pred(i) for i in decollate_batch(y_pred)], [post_label(i) for i in decollate_batch(y)]),\n",
    ")\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED(every=validation_every_n_epochs))\n",
    "def run_validation(engine):\n",
    "    evaluator.run(val_loader)\n",
    "\n",
    "# add early stopping handler to evaluator\n",
    "early_stopper = EarlyStopping(\n",
    "    patience=20, score_function=stopping_fn_from_metric(metric_name), trainer=trainer\n",
    ")\n",
    "evaluator.add_event_handler(\n",
    "    event_name=Events.EPOCH_COMPLETED, handler=early_stopper\n",
    ")\n",
    "\n",
    "# add stats event handler to print validation stats via evaluator\n",
    "val_stats_handler = StatsHandler(\n",
    "    name=\"evaluator\",\n",
    "    output_transform=lambda x: None,  # no need to print loss value, so disable per iteration output\n",
    "    global_epoch_transform=lambda x: trainer.state.epoch,\n",
    ")  # fetch global epoch number from trainer\n",
    "val_stats_handler.attach(evaluator)\n",
    "\n",
    "# add handler to record metrics to TensorBoard at every validation epoch\n",
    "val_tensorboard_stats_handler = TensorBoardStatsHandler(\n",
    "    output_transform=lambda x: None,  # no need to plot loss value, so disable per iteration output\n",
    "    global_epoch_transform=lambda x: trainer.state.epoch,\n",
    ")  # fetch global epoch number from trainer\n",
    "val_tensorboard_stats_handler.attach(evaluator)\n",
    "\n",
    "# add handler to draw the first image and the corresponding label and model output in the last batch\n",
    "# here we draw the 3D output as GIF format along Depth axis, at every validation epoch\n",
    "val_tensorboard_image_handler = TensorBoardImageHandler(\n",
    "    batch_transform=lambda batch: (batch[0], batch[1]),\n",
    "    output_transform=lambda output: output[0],\n",
    "    global_iter_transform=lambda x: trainer.state.epoch,\n",
    ")\n",
    "evaluator.add_event_handler(\n",
    "    event_name=Events.EPOCH_COMPLETED, handler=val_tensorboard_image_handler\n",
    ")\n",
    "\n",
    "train_epochs = 50\n",
    "state = trainer.run(train_loader, train_epochs)\n",
    "print(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f39c32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
