{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e00d7ef7",
   "metadata": {},
   "source": [
    "다음을 리뷰 :\n",
    "https://github.com/Project-MONAI/tutorials/blob/master/3d_segmentation/torch/unet_training_array.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a36a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import monai\n",
    "## decollate_batch : 배치 텐서를 리스트의 텐서로 변환\n",
    "from monai.data import ImageDataset, create_test_image_3d, decollate_batch\n",
    "from monai.transforms import Activations, AddChannel, AsDiscrete, Compose, RandRotate90\n",
    "from monai.transforms import RandSpatialCrop, ScaleIntensity, EnsureType\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.visualize import plot_2d_or_3d_image\n",
    "\n",
    "# tensorboard가 읽을 수 있도록 loss, metric, out image, out_seg 를 기록 \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7226ce",
   "metadata": {},
   "source": [
    "**ImageDataset**\n",
    "* 이건 image, seg 파일 배열을 넣어주면 데이터셋을 만들어주는 API인듯하다\n",
    "* segmentation 한정 사용가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff100b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdir = './dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf1019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "monai.config.print_config()\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "# 디렉토리에 40개 랜덤이미지, 마스크 생성\n",
    "print(f\"generating synthetic data to {tempdir} (this may take a while)\")\n",
    "for i in range(40):\n",
    "    # np image 생성\n",
    "    im, seg = create_test_image_3d(128, 128, 128, num_seg_classes=1)  \n",
    "#     print(type(im), type(seg))  # np.array\n",
    "#     print(im.shape, seg.shape)  # (128, 128, 128) (128, 128, 128) 3d 라서 img, seg가 같은 dim인 듯?\n",
    "#     print(im)\n",
    "\n",
    "#     print(np.eye(4))  # 2차원 identity 행렬(4x4) 생성\n",
    "    n = nib.Nifti1Image(im, np.eye(4))\n",
    "#     print(type(n), n)   # nifti 이미지\n",
    "    nib.save(n, os.path.join(tempdir, f\"img{i:d}.nii.gz\"))\n",
    "\n",
    "    n = nib.Nifti1Image(seg, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, f\"seg{i:d}.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f8f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77abac70",
   "metadata": {},
   "source": [
    "### image, seg 파일 리스트 Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ced7974",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sorted(glob(os.path.join(tempdir, \"img*.nii.gz\")))    # 40개 nifti file 리스트\n",
    "segs = sorted(glob(os.path.join(tempdir, \"seg*.nii.gz\")))\n",
    "len(images), len(segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7023da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 MRI도 이런진 확인 필요.\n",
    "im.max(), im.min(), seg.max(), seg.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aefe7b1",
   "metadata": {},
   "source": [
    "### Transform 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad34c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms for image and segmentation\n",
    "train_imtrans = Compose(\n",
    "    [\n",
    "        ScaleIntensity(),\n",
    "        AddChannel(),\n",
    "        # aug\n",
    "        RandSpatialCrop((96, 96, 96), random_size=False),\n",
    "        RandRotate90(prob=0.5, spatial_axes=(0, 2)),\n",
    "        EnsureType(),\n",
    "    ]\n",
    ")\n",
    "train_segtrans = Compose(\n",
    "    [\n",
    "        # 스케일링 필요없나 봄 (1또는 0이므로)\n",
    "        AddChannel(),\n",
    "        # aug (img와 같은 aug를 해주는가..? -> 맞음.. 왜인진.. 모름)\n",
    "        RandSpatialCrop((96, 96, 96), random_size=False),\n",
    "        RandRotate90(prob=0.5, spatial_axes=(0, 2)),\n",
    "        EnsureType(),\n",
    "    ]\n",
    ")\n",
    "val_imtrans = Compose([ScaleIntensity(), AddChannel(), EnsureType()])\n",
    "val_segtrans = Compose([AddChannel(), EnsureType()])\n",
    "\n",
    "train_ds = ImageDataset(images[:20], segs[:20], transform=train_imtrans, seg_transform=train_segtrans)\n",
    "# worker : cores threads\n",
    "# pin_memory : If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4, pin_memory=torch.cuda.is_available())\n",
    "# create a validation data loader\n",
    "val_ds = ImageDataset(images[-20:], segs[-20:], transform=val_imtrans, seg_transform=val_segtrans)\n",
    "val_loader = DataLoader(val_ds, batch_size=2, num_workers=3, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88acb72",
   "metadata": {},
   "source": [
    "ImageDataset은 파일 경로로부터 데이터를 로딩하는 API.\n",
    "\n",
    "train_ds 는 데이터셋 객체 이지만 index를 이용하여 접근 가능. image, seg (tensor([[]]), tensor([[]])) 의 형태"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52e45a5",
   "metadata": {},
   "source": [
    "### 데이터셋 확인\n",
    "그려 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0de8ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplots(1, 2, figsize=(8, 8))\n",
    "# for each in train_loader:\n",
    "#     img = each[0].numpy()\n",
    "#     seg = each[1].numpy()\n",
    "#     print(type(img), img.shape)    # <class 'numpy.ndarray'> (4, 1, 96, 96, 96) batch, C, W, H, D\n",
    "#     print(type(seg), seg.shape)    # segmentation에선 shape이 GT와 img가 같다.\n",
    "#     img = img[0, 0, 0, :, :]\n",
    "#     seg = seg[0, 0, 0, :, :]\n",
    "#     print(img.shape)\n",
    "# #     plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "# #     plt.imshow(img, cmap=\"gray\")\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.xlabel('img')\n",
    "#     plt.imshow(img)\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.xlabel('seg')\n",
    "#     plt.imshow(seg)\n",
    "# #     raise AssertionError(\"!!!\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960d1431",
   "metadata": {},
   "source": [
    "### post-process, metrics, model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f2e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0~1로 맞추고 0.5로 threshold\n",
    "# AsDiscrete는 onehot도 가능\n",
    "# 하나씩 빼보면서 더 해볼필요\n",
    "post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "# dice의 parameters는 확인 필요\n",
    "# 왜 필요한지 알아보자.(validation check을 위해서 인듯하다.)\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = monai.networks.nets.UNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        channels=(16, 32, 64, 128, 256),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=2,\n",
    "    ).to(device)\n",
    "loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bd2d0f",
   "metadata": {},
   "source": [
    "```python\n",
    "## activation sigmoid, asdiscrete 테스트\n",
    "\n",
    "test = [-1, -0.4, 0.2, 0.4, 0.8, 1.5]\n",
    "post_trans_test1 = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "print(post_trans_test(test))\n",
    "# [tensor(0.), tensor(0.), tensor(1.), tensor(1.), tensor(1.), tensor(1.)]\n",
    "\n",
    "post_trans_test2 = Compose([EnsureType(), Activations(sigmoid=True)])\n",
    "print(post_trans_test2(test))\n",
    "# [tensor(0), tensor(0.4013), tensor(0.5498), tensor(0.5987), tensor(0.6900), tensor(0.8176)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be8c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405e5a20",
   "metadata": {},
   "source": [
    "### model 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66bccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train set 사이즈와 안맞춰주면 정확도 확 감소\n",
    "\n",
    "model = monai.networks.nets.UNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        channels=(16, 32, 64, 128, 256),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=2,\n",
    "    ).to(device)\n",
    "loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "\n",
    "epochs = 5\n",
    "epoch_loss_values = list()\n",
    "val_interval = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "#     pass\n",
    "    print('-'*20)\n",
    "    print(f'epoch: {epoch}/{epochs} ')\n",
    "    \n",
    "    epoch_loss=0\n",
    "    model.train()\n",
    "    step = 0\n",
    "    for batch in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size\n",
    "        print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    if (epoch + 1) % val_interval == 0:  # 2번 epoch마다 validation.\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "#                 print(f'original shape : {val_images.shape}')\n",
    "                val_outputs = model(val_images)\n",
    "#                 print(f'val_out shape: {val_outputs.shape}')\n",
    "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                print(dice_metric.aggregate())\n",
    "            print(dice_metric.aggregate())\n",
    "            dice_metric.reset()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785aa505",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67319d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = monai.networks.nets.UNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        channels=(16, 32, 64, 128, 256),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=2,\n",
    "    ).to(device)\n",
    "loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "\n",
    "epochs = 5\n",
    "epoch_loss_values = list()\n",
    "val_interval = 2\n",
    "metric_values = list()\n",
    "best_metric = -1\n",
    "best_epoch = -1\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "#     pass\n",
    "    print('-'*20)\n",
    "    print(f'epoch: {epoch + 1}/{epochs} ')\n",
    "    \n",
    "    epoch_loss=0\n",
    "    model.train()\n",
    "    step = 0\n",
    "    for batch in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size\n",
    "        print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "        \n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    if (epoch + 1) % val_interval == 0:  # 2번 epoch마다 validation.\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                roi_size = (96, 96, 96)\n",
    "                sw_batch_size = 4\n",
    "                \n",
    "                # validation image가 model을 training하는데 썼던 traing보다 크기가 큰경우 sliding 방식으로 추론\n",
    "                # 나오는 output은 original validation img size만큼 나오게 되나 더 정확한 추론.\n",
    "                val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
    "#                 print(f'val_out : {val_outputs.shape}')    ## [1, 1, 128, 128, 128]\n",
    "\n",
    "                ## decollate_batch는 post_transform과 함께 쓰임.\n",
    "#                 val_outputs_test = [post_trans(i) for i in val_outputs]\n",
    "#                 print(f'val_out shape-test: {len(val_outputs_test)} {val_outputs_test}')\n",
    "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "#                 print(f'val_out shape: {len(val_outputs)} {val_outputs}')\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "#                 dice_metric(y_pred=val_outputs_test, y=val_labels)  # 같다\n",
    "#                 print(dice_metric.aggregate())\n",
    "    \n",
    "            # aggregate the final mean dice result\n",
    "#             print(dice_metric.aggregate())\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            dice_metric.reset()\n",
    "        \n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), \"./models/best_metric_model_segmentation3d_array.pth\")\n",
    "                print(\"saved new best metric model\")\n",
    "            \n",
    "            print(\n",
    "                    \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n",
    "                        epoch + 1, metric, best_metric, best_epoch )\n",
    "                )\n",
    "            writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n",
    "            # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
    "            plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
    "            plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
    "            plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
    "            \n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_epoch}\")\n",
    "writer.close()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0096fe30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
