{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제 : colab에서는 실행되나, jupyter - monai에선 실행 한댐\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCS-d1T3znj2"
   },
   "source": [
    "# Convolutional Neural Networks for Sentence Classification using Ignite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjZMYxFoznj9"
   },
   "source": [
    "This is a tutorial on using Ignite to train neural network models, setup experiments and validate models.\n",
    "\n",
    "In this experiment, we'll be replicating [\n",
    "Convolutional Neural Networks for Sentence Classification by Yoon Kim](https://arxiv.org/abs/1408.5882)! This paper uses CNN for text classification, a task typically reserved for RNNs, Logistic Regression, Naive Bayes.\n",
    "\n",
    "We want to be able to classify IMDB movie reviews and predict whether the review is positive or negative. IMDB Movie Review dataset comprises of 25000 positive and 25000 negative examples. The dataset comprises of text and label pairs. This is binary classification problem. We'll be using PyTorch to create the model, torchtext to import data and Ignite to train and monitor the models!\n",
    "\n",
    "Lets get started! \n",
    "\n",
    "* IMDB 영화 리뷰 분류, 25,000개 긍정문, 25,000부정문으로 구성\n",
    "* text, label 쌍으로 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZty7-RWznkA"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VKTazeAkznkB"
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxThg0YTznkD"
   },
   "source": [
    "`torchtext` is a library that provides multiple datasets for NLP tasks, similar to `torchvision`. Below we import the following:\n",
    "* **datasets**: A module to download NLP datasets.\n",
    "* **GloVe**: A module to download and use pretrained GloVe embedings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XrXE-f7jznkD"
   },
   "outputs": [],
   "source": [
    "from torchtext import datasets      # 공개 데이터셋\n",
    "from torchtext.vocab import GloVe   # pretraining embeding dataset이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch-ignite torchtext==0.9.1 spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchtext==0.9.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivAnTyEfznkE"
   },
   "source": [
    "We import torch, nn and functional modules to create our models! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gbEFAWr0znkE"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q22BGKi8znkF"
   },
   "source": [
    "`Ignite` is a High-level library to help with training neural networks in PyTorch. It comes with an `Engine` to setup a training loop, various metrics, handlers and a helpful contrib section! \n",
    "\n",
    "\n",
    "\n",
    "Below we import the following:\n",
    "* **Engine**: Runs a given process_function over each batch of a dataset, emitting events as it goes.\n",
    "* **Events**: Allows users to attach functions to an `Engine` to fire functions at a specific event. Eg: `EPOCH_COMPLETED`, `ITERATION_STARTED`, etc.\n",
    "* **Accuracy**: Metric to calculate accuracy over a dataset, for binary, multiclass, multilabel cases. \n",
    "* **Loss**: General metric that takes a loss function as a parameter, calculate loss over a dataset.\n",
    "* **RunningAverage**: General metric to attach to Engine during training. \n",
    "* **ModelCheckpoint**: Handler to checkpoint models. \n",
    "* **EarlyStopping**: Handler to stop training based on a score function. \n",
    "* **ProgressBar**: Handler to create a tqdm progress bar.\n",
    "\n",
    "[정리]\n",
    "* Engine : training loop, metrics, handler, 데이터셋의 각 배치의 process_fuction을 실행, event를 발생\n",
    "* Events : 특정 이벤트에서 특정 기능을 추하할 수 있게 함\n",
    "* RunningAverage : 훈련 중 Engine에 연결할 metric\n",
    "* ProgressBar : tqdm 진행률 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "enczLgLTznkH"
   },
   "outputs": [],
   "source": [
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.utils import manual_seed\n",
    "\n",
    "SEED = 1234\n",
    "manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-39hgxiUMCq9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '5,6,7'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZYyXYB5znkH"
   },
   "source": [
    "## Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irv_ebeDb8yV"
   },
   "source": [
    "We first set up a tokenizer using `torchtext.data.utils`.\n",
    "The job of a tokenizer to split a sentence into \"tokens\". You can read more about it at [wikipedia](https://en.wikipedia.org/wiki/Lexical_analysis).\n",
    "We will use the tokenizer from the \"spacy\" library which is a popular choice. Feel free to switch to \"basic_english\" if you want to use the default one or any other that you want.\n",
    "\n",
    "docs: https://pytorch.org/text/stable/data_utils.html\n",
    "\n",
    "spacy 라이브러리를 이용하여 토크나이징 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting en-core-web-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "     |████████████████████████████████| 13.6 MB 207 kB/s            \n",
      "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from en-core-web-sm==3.1.0) (3.1.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (21.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /opt/conda/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.62.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (58.2.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.26.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.21.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "YNRd5Z_KMANB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ducke/.local/lib/python3.8/site-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "tokenizer = get_tokenizer(\"spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZknfGdqedSjN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ignite',\n",
       " 'is',\n",
       " 'a',\n",
       " 'high',\n",
       " '-',\n",
       " 'level',\n",
       " 'library',\n",
       " 'for',\n",
       " 'training',\n",
       " 'and',\n",
       " 'evaluating',\n",
       " 'neural',\n",
       " 'networks',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토크나이징 예시\n",
    "tokenizer(\"Ignite is a high-level library for training and evaluating neural networks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvAmyqHygcZg"
   },
   "source": [
    "Next, the IMDB training and test datasets are downloaded. The `torchtext.datasets` API returns the train/test dataset split directly without the preprocessing information. Each split is an iterator which yields the raw texts and labels line-by-line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "E_jNgWXHhMBQ"
   },
   "outputs": [],
   "source": [
    "train_iter, test_iter = datasets.IMDB(split=('train','test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNKvG9b7jadd"
   },
   "source": [
    "Now we set up the train, validation and test splits.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VzJG7Uh_L9q-"
   },
   "outputs": [],
   "source": [
    "# We are using only 1000 samples for faster training\n",
    "# set to -1 to use full data\n",
    "N = 1000 \n",
    "\n",
    "# We will use 80% of the `train split` for training and the rest for validation\n",
    "train_frac = 0.8\n",
    "_temp = list(train_iter)\n",
    "\n",
    "\n",
    "random.shuffle(_temp)\n",
    "_temp = _temp[:(N if N > 0 else len(_temp) )]\n",
    "n_train = int(len(_temp)*train_frac)\n",
    "\n",
    "train_list = _temp[:n_train]\n",
    "validation_list = _temp[n_train:]\n",
    "test_list = list(test_iter)\n",
    "test_list = test_list[:(N if N > 0 else len(test_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('neg',\n",
       "  \"David Mamet is a very interesting and a very un-equal director. His first movie 'House of Games' was the one I liked best, and it set a series of films with characters whose perspective of life changes as they get into complicated situations, and so does the perspective of the viewer.<br /><br />So is 'Homicide' which from the title tries to set the mind of the viewer to the usual crime drama. The principal characters are two cops, one Jewish and one Irish who deal with a racially charged area. The murder of an old Jewish shop owner who proves to be an ancient veteran of the Israeli Independence war triggers the Jewish identity in the mind and heart of the Jewish detective.<br /><br />This is were the flaws of the film are the more obvious. The process of awakening is theatrical and hard to believe, the group of Jewish militants is operatic, and the way the detective eventually walks to the final violent confrontation is pathetic. The end of the film itself is Mamet-like smart, but disappoints from a human emotional perspective.<br /><br />Joe Mantegna and William Macy give strong performances, but the flaws of the story are too evident to be easily compensated.\"),\n",
       " ('neg',\n",
       "  'not to long after Jeff Jarrett left the WWF for good he spoke of that night . Owen Hart and him where good friends and both 2nd generation wrestlers. Jeff first remarks \"I was literally pushed thru the curtain as my lifeless friends body was wheeled past me \" . Debra McMichael( Steve Austin\\'s Ex wife as well as Steve Mondo McMichael Ex wife\".) <br /><br />As Owen Hart Fell, a video promo the ring was darkened, as a Blue Blazer (owen Hart Promo was played. The fall and video of owen in the ring was never showed on TV. There are a few news photos that got posted. When they came back from the video promo Jim ross was talking over a all we had was a crowd shot \\\\., He stated that Owen Hart as The blue blazer has fallen and doesn\\'t look good. Lawler then came back from the ring his face was ashen he told Jim that the situation was very critical paramedics where working hard to revive him. Rock And HHH where going there match in a private room when another Referee came in and told them Owen fell at first,knowing Owen Harts constantly being a prankster they thought it wasn\\'t real. But both later stated that the look of the referee face said it all. In fact as he fell ,as mentioned in other post , he yelled for the referee and ring announcer to move. <br /><br />Brother Bret hart was a plane heading to LA to do a angle on the Tonight Show , he couldn\\'t get any of the plane phones to work, One of the captains got a message to call home something had happened. When he landed in La Eric bishoff was there told him what had happened, and put him on a charter flight to Kansas City to the morgue, Bret even later with Owens widow Martha went up to the top of the arena where Owen was standing. Police found no foul play formerly closed as a accident .<br /><br />Most of the Information in Bret Harts book as well as the book by Martha Hart ,')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-qYvdeplMIs"
   },
   "source": [
    "Let's explore a data sample to see what it looks like.\n",
    "Each data sample is a tuple  of the format `(label, text)`.\n",
    "\n",
    "The value of label can is either 'pos' or 'neg'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qrlLB7PxkIW_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " text: Now I'll be the first to admit it when I say something that may be blasphemous or unfair, so I would like to apologize in advance for my ranting about how much I disliked this movie.<br /><br />That about sums it up too. I disliked this movie. To be more specific, I disliked the concept of this movie. The cinematography was good. The mood was nice. And the acting was satisfactory.<br /><br /> However, the story is fatuous, unacurate and misleading. It is also offensive.<br /><br />I am a quarter Cree Indian, and for some reason I feel insulted, on a personal level, by the nature of Whitaker's character. First of all, he's a black guy. And this isn't a racist remark, I swear. The thought of a White, Hispanic or even Native American swinging a katana on a rooftop offends everything that the katana represents. The katana represents the soul of a Samurai, imbibed with the souls of his ancestors who guide and protect the Samurai. For Ghost Dog to use his guns instead of the Katana is also an insult to the blade and the souls inside, and where the heck did he get a Katana anyway? It must be one of those replicas, which insults the Samurai caste even more.<br /><br />Also, Ghost Dog showed no honor. Near the end of the movie, he shoots a bodyguard in the back through a window and then assassinates a man by shooting him in the face through a faucet drain. Not only is this a cowards way to kill an enemy, it's more like a ninjas way; silent assassins; a group that samurais deny exists, but hates none-the-less.<br /><br />Then he tries to kill his boss, when he finds out his boss is a baddie. You know what a true Samurai does when he learns his master is proven bad or dishonorable? He kills himself, to prove that he would rather die then lower himself to the level of his doggish master.<br /><br />Everything about the character was a giant contradiction to the real code that all Samurai adhere to: Bushido.<br /><br />So, we have great cinematography, good ambiance and so-so acting encompassing a satiricle plot and premise, (which unfortunately is the most important aspect of it) , making it an unsatisfactory overall film, and an insult to everything a honorable bushi(samurai) holds dear.<br /><br /> 2.5/10 Bleah\n",
      "label: neg\n"
     ]
    }
   ],
   "source": [
    "random_sample = random.sample(train_list,1)[0]\n",
    "print(' text:', random_sample[1])\n",
    "print('label:', random_sample[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mN5cHrazmMDG"
   },
   "source": [
    "Now that we have the datasets splits, let's build our vocabulary. For this, we will use the `Vocab` class from `torchtext.vocab`. It is important that we build our vocabulary based on the train dataset as validation and test are **unseen** in our experimenting. \n",
    "\n",
    "`Vocab` allows us to use pretrained **GloVE** 100 dimensional word vectors. This means each word is described by 100 floats! If you want to read more about this, here are a few resources.\n",
    "* [StanfordNLP - GloVe](https://github.com/stanfordnlp/GloVe)\n",
    "* [DeepLearning.ai Lecture](https://www.coursera.org/lecture/nlp-sequence-models/glove-word-vectors-IxDTG)\n",
    "* [Stanford CS224N Lecture by Richard Socher](https://www.youtube.com/watch?v=ASn7ExxLZws)\n",
    "\n",
    "Note than the GloVE download size is around 900MB, so it might take some time to download. \n",
    "\n",
    "An instance of the `Vocab` class has the following attributes:\n",
    "* `extend` is used to extend the vocabulary\n",
    "* `freqs` is a dictionary of the frequency of each word\n",
    "* `itos` is a list of all the words in the vocabulary.\n",
    "* `stoi` is a dictionary mapping every word to an index.\n",
    "* `vectors` is a torch.Tensor of the downloaded embeddings\n",
    "\n",
    "----\n",
    "어휘(vocab) build. 'torchtext.vocab의 Vocab 클래스 이용'. 학습중에 valid, test는 쓰지 않기 때문에 train 데이터셋을 이용한 어휘구축이 중요. \bpretrained `GloVE`를 이용하여 100차원 단어벡터 생성. 즉, 각 단어는 100개의 float으로 설명가능하다는 의미.\n",
    "\n",
    "Vocab클래스의 attributes:\n",
    "* extend: 어휘 확장\n",
    "* freqs : 각 단어의 frequence dict\n",
    "* itos : 어휘에 있는 모든 단어의 ordered 리스트\n",
    "* stoi : 모든 단어를 index에 맵핑하는 dict\n",
    "* vectors : 다운로드한 임베딩의 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "T_ukillQMKsh"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "for (label, line) in train_list:\n",
    "    counter.update(tokenizer(line))\n",
    "\n",
    "vocab = Vocab(\n",
    "    counter,\n",
    "    min_freq=10,\n",
    "    vectors=GloVe(name='6B', dim=100, cache='/tmp/glove/')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "VYYGwfYsM2Pr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the new vocab is 2004\n",
      "The index of '<BOS>' is 0\n",
      "The token at index 2 is the\n"
     ]
    }
   ],
   "source": [
    "print(\"The length of the new vocab is\", len(vocab))\n",
    "new_stoi = vocab.stoi\n",
    "print(\"The index of '<BOS>' is\", new_stoi['<BOS>'])\n",
    "new_itos = vocab.itos\n",
    "print(\"The token at index 2 is\", new_itos[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2004, 100]),\n",
       " tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "         ...,\n",
       "         [ 0.1388,  0.7624,  1.1537,  ...,  0.4456,  0.4540,  0.4101],\n",
       "         [-0.0863, -0.3406,  0.8735,  ..., -1.0531, -0.2014,  1.4113],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.vectors.shape, vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 2, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['The'], vocab['the'], vocab['of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 2, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.stoi['The'], vocab.stoi['the'], vocab.stoi['of']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Y72cqB6Qhqt"
   },
   "source": [
    "We now create `text_transform` and `label_transform`, which are callable objects, such as a `lambda` func here, to process the raw text and label data from the dataset iterators (or iterables like a `list`). You can add the special symbols such as `<BOS>` and `<EOS>` to the sentence in `text_transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "z_9hw21lP1nG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input to the text_transform: here is an example\n",
      "output of the text_transform: [163, 9, 42, 563]\n"
     ]
    }
   ],
   "source": [
    "text_transform = lambda x: [vocab[token] for token in tokenizer(x)]\n",
    "label_transform = lambda x: 1 if x == 'pos' else 0\n",
    "\n",
    "# Print out the output of text_transform\n",
    "print(\"input to the text_transform:\", \"here is an example\")\n",
    "print(\"output of the text_transform:\", text_transform(\"here is an example\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtZSEqjJQPxM"
   },
   "source": [
    "For generating the data batches we will use `torch.utils.data.DataLoader`. You could customize the data batch by defining a function with the `collate_fn` argument in the DataLoader. Here, in the `collate_batch` func, we process the raw text data and add padding to dynamically match the longest sentence in a batch.\n",
    "\n",
    "DataLoader로 배치생성, collate_fn인수로 데이터일괄처리.(배치에서 가장 긴문장으로 맞춰주도록 패딩 추가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "NHHIEfpRP4TV"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_transform(_label))\n",
    "        processed_text = torch.tensor(text_transform(_text))\n",
    "        text_list.append(processed_text)\n",
    "    return torch.tensor(label_list), pad_sequence(text_list, padding_value=3.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "3IQd3EVbQvTo"
   },
   "outputs": [],
   "source": [
    "batch_size = 8  # A batch size of 8\n",
    "\n",
    "# train, validation, test 순으로 dataloader 생성\n",
    "def create_iterators(batch_size=8):\n",
    "    \"\"\"Heler function to create the iterators\"\"\"\n",
    "    dataloaders = []\n",
    "    for split in [train_list, validation_list, test_list]:\n",
    "        print(len(split))\n",
    "        dataloader = DataLoader(\n",
    "            split, batch_size=batch_size,\n",
    "            collate_fn=collate_batch\n",
    "            )\n",
    "        dataloaders.append(dataloader)\n",
    "    return dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "CudYIZitUNgx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "200\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "train_iterator, valid_iterator, test_iterator = create_iterators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "787zNPm6RtKE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 1, 0, 1, 1, 0, 0]),\n",
       " tensor([[731,  35, 331,  ...,  12,  12,  12],\n",
       "         [  0,   8,   0,  ..., 239, 184,  33],\n",
       "         [  9, 240,  50,  ...,   8,  35, 131],\n",
       "         ...,\n",
       "         [  3,   3,   3,  ...,   3,   3,   3],\n",
       "         [  3,   3,   3,  ...,   3,   3,   3],\n",
       "         [  3,   3,   3,  ...,   3,   3,   3]]),\n",
       " torch.Size([665, 8]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seq는 컬럼별로 한문장씩 들어가 있음\n",
    "l, seq = next(iter(train_iterator))\n",
    "l, seq, seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 665]),\n",
       " tensor([[731,   0,   9,  ...,   3,   3,   3],\n",
       "         [ 35,   8, 240,  ...,   3,   3,   3],\n",
       "         [331,   0,  50,  ...,   3,   3,   3],\n",
       "         ...,\n",
       "         [ 12, 239,   8,  ...,   3,   3,   3],\n",
       "         [ 12, 184,  35,  ...,   3,   3,   3],\n",
       "         [ 12,  33, 131,  ...,   3,   3,   3]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8개 배치(행), 1문장의 token index (각 token index는 vocab을 이용하여 단어별 100차원의 벡터(2D 이미지의 채널 개념)로 만들 수 있다.)\n",
    "seq.T.shape, seq.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 731,    0,    9,    6,   63,  193,    5,    6,   63,    0,   17,    0,\n",
       "         212,    4,  525,  110,   22,   44,    0,    7,    0,   44,   19,    2,\n",
       "          37,   12,  444,  144,    3,    5,   11,  279,    6,  228,    7,  122,\n",
       "          21,  133,  539, 1959,    7,  136, 1618,   20,   47,   91,   95,    0,\n",
       "           0,    3,    5,   49,   81,    2, 1959,    7,    2,    0,   18, 1112,\n",
       "           9,   44,    0,   44,   73,   43,    2,  592,  538,    8,  279,    2,\n",
       "         395,    7,    2,  593,    8,    2,  554,  737,  470,    4,   25,    0,\n",
       "         133,   31,  113, 1072,    3,   37, 1483,    5,   37,    0,   48,  849,\n",
       "          21,    6,    0,    0, 1613,    4,   25,  548,    7,   42,  211, 1483,\n",
       "        1814, 1443,   48,    0,    8,   36,   42,    0,    0,    7,    2,    0,\n",
       "           0,  503,    0,    2, 1483,    0,   10,    2,  395,    5,  545,    7,\n",
       "           2, 1483,    0,   18,  345,    9,   71,    2, 1637,    7,    2,   23,\n",
       "          31,    2,   58,  639,    4,   25,    0,    7,    0,    9,    0,    5,\n",
       "         231,    8,  266,    3,    2,  621,    7, 1483,    0,    9,    0,    3,\n",
       "           5,    2,  105,    2, 1340, 1345,    0,    8,    2,  599, 1465,    0,\n",
       "           9, 1288,    4,   25,  154,    7,    2,   23,  474,    9,    0,   17,\n",
       "          46, 1378,    3,   28,    0,   43,    6,  435,  948,    0,   18,    0,\n",
       "           0,    5, 1181,    0,  246,  590,  396,    3,   28,    2, 1637,    7,\n",
       "           2,   74,   31,  117,    0,    8,   36,  947,    0,    4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(text_transform(train_list[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  35,    8,  240,  116,    0,    0,  340,    2,    0,   24,   64,   38,\n",
       "           0,    7,   13,  414,    4,    0, 1593,    5,   96,  143,   64,  394,\n",
       "           5,  290,    0, 1932,    0,    4,    0,  110,    0,   15,   12,   19,\n",
       "        1139,    0, 1689,    2,    0,   20,   85,    0,  394, 1028,   19,    0,\n",
       "         464,   89,   15,    4,    0,    0,   26, 1178,    0,   14,    0,  287,\n",
       "          20,   99,   20, 1178,    0,    0,    0,  287,   15,    4,   27,  123,\n",
       "         124,   18,  840,    0, 1593,    0,    3,    6,  387,    0,    2,    0,\n",
       "          19,    0,    3,   20,    6,    0,    0,   26,    0, 1593,    0,   19,\n",
       "         244,    4,   25,  908,    5,  387,    7,    0,   10,    2,    0,   19,\n",
       "         131, 1377,   29,  252,    4,  165,   31,    6,  191, 1796,    0,   13,\n",
       "         195,    0,    4,  313,   47,  358,  147,   43,    2,  387,    0, 1858,\n",
       "           0,   19,  643,  145,    6,   45,   93,   84,   19,    6,    0,  375,\n",
       "           0,    3,  164,    0,   13,    0, 1593,   20,   25,    0,    0,   50,\n",
       "           0,    5,   81,   30,  196,   64,    4,    0,  111,  358,  147,   43,\n",
       "           2,    0,   34,  564,   19,    0,   38,  519, 1858,   13,    2, 1048,\n",
       "          19,   63,    0,    0,  143,  730,  231,    8,    0,   96,    4, 1020,\n",
       "         132,    0,  143,  187,   60,    0,   10,    6, 1965,  550,   70,  205,\n",
       "           0,  358,   10,    5,  519,  108,    0, 1416,   39,  110,    3, 1282,\n",
       "           0,    0, 1517,  121,    6,    0,   47,  237,   11,   19,   30,  152,\n",
       "           4,  129,  290,  332,    0,   13,    2,  196,    7,    2,    0,  564,\n",
       "         308,   11,   45,    4,  146,  227,   20,   38, 1416,    3,   20, 1210,\n",
       "          10,   92, 1668,    3,   38,    0,   24,    2,    0,    5,    0,    0,\n",
       "           8, 1211,    4,  123,  124,   18,    0,    0,    0,   19,    6, 1290,\n",
       "           0,    8,    0,    8,   57,    6, 1879,   29,    2,    0, 1492,    3,\n",
       "          38,   82,   30,   91,  114,    7,    2, 1290,    0,    8,  175,    3,\n",
       "         346,    7,    2,    0,  195,    6,  955,    8,  822,  410,  150,   84,\n",
       "         544,    4,  313,   38,    0,   10,    0, 1851,    0,   19,   60,  519,\n",
       "          96,   66,   84,  544,    3,    5,  278,   96,   29,    6,    0,    0,\n",
       "           8,    0, 1588,    8,    2,    0,    3,    0,   75,  332,   21,    0,\n",
       "           0,    0,  479,   68,    8,    2,  323,    7,    2,    0,  143,    0,\n",
       "          19,    0,    4,    0,  268,   83,    0,  350,    0,    0,   20,    6,\n",
       "           0,    0,   18,    0,    7,    2,    0,   10,    0,    0,  347,   20,\n",
       "          99,   20,    2,  347,   40,    0, 1593,    3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(text_transform(train_list[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2azJGL6znkM"
   },
   "source": [
    "Let's actually explore what the output of the iterator is, this way we'll know what the input of the model is, how to compare the label to the output and how to setup are process_functions for Ignite's `Engine`.\n",
    "* `batch[0][0]` is the label of a single example. We can see that `vocab.stoi` was used to map the label that originally text into a float.\n",
    "* `batch[1][0]` is the text of a single example. Similar to label, `vocab.stoi` was used to convert each token of the example's text into indices.\n",
    "\n",
    "Now let's print the lengths of the sentences of the first 10 batches of `train_iterator`. We see here that all the batches are of different lengths, this means that the iterator is working as expected.\n",
    "\n",
    "* 아래에서 Ignite 'Engine'의 process_fuctions 설정할수있다.\n",
    "* batch[문장번호][0] : 레이블\n",
    "* batch[문장번호][1] : 문장텐서\n",
    "* 아래 10개 배치를 출력해보면, 배치마다 문장길이가 다르다는 점을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Ga2xDXfyznkN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch[0][0] :  tensor(0)\n",
      "batch[1][0] :  tensor([[[731,  35, 331,  ...,  12,  12,  12],\n",
      "         [  0,   8,   0,  ..., 239, 184,  33],\n",
      "         [  9, 240,  50,  ...,   8,  35, 131],\n",
      "         ...,\n",
      "         [  3,   3,   3,  ...,   3,   3,   3],\n",
      "         [  3,   3,   3,  ...,   3,   3,   3],\n",
      "         [  3,   3,   3,  ...,   3,   3,   3]]])\n",
      "Lengths of first 10 batches :  [665, 628, 1182, 369, 695, 816, 943, 570, 343, 806, 469]\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iterator))\n",
    "print('batch[0][0] : ', batch[0][0])\n",
    "print('batch[1][0] : ', batch[1][[0] != 1])\n",
    "\n",
    "lengths = []\n",
    "for i, batch in enumerate(train_iterator):\n",
    "    x = batch[1]\n",
    "    lengths.append(x.shape[0])\n",
    "    if i == 10:\n",
    "        break\n",
    "\n",
    "print ('Lengths of first 10 batches : ', lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10개 batch를 살펴봤을 때, 문장길이가 다 다름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsUrKRr3znkO"
   },
   "source": [
    "## TextCNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pldMpTv-znkO"
   },
   "source": [
    "Here is the replication of the model, here are the operations of the model:\n",
    "* **Embedding**: Embeds a batch of text of shape (N, L) to (N, L, D), where N is batch size, L is maximum length of the batch, D is the embedding dimension. \n",
    "\n",
    "* **Convolutions**: Runs parallel convolutions across the embedded words with kernel sizes of 3, 4, 5 to mimic trigrams, four-grams, five-grams. This results in outputs of (N, L - k + 1, D) per convolution, where k is the kernel_size. \n",
    "\n",
    "* **Activation**: ReLu activation is applied to each convolution operation.\n",
    "\n",
    "* **Pooling**: Runs parallel maxpooling operations on the activated convolutions with window sizes of L - k + 1, resulting in 1 value per channel i.e. a shape of (N, 1, D) per pooling. \n",
    "\n",
    "* **Concat**: The pooling outputs are concatenated and squeezed to result in a shape of (N, 3D). This is a single embedding for a sentence.\n",
    "\n",
    "* **Dropout**: Dropout is applied to the embedded sentence. \n",
    "\n",
    "* **Fully Connected**: The dropout output is passed through a fully connected layer of shape (3D, 1) to give a single output for each example in the batch. sigmoid is applied to the output of this layer.\n",
    "\n",
    "* **load_embeddings**: This is a method defined for TextCNN to load embeddings based on user input. There are 3 modes - rand which results in randomly initialized weights, static which results in frozen pretrained weights, nonstatic which results in trainable pretrained weights. \n",
    "\n",
    "\n",
    "Let's note that this model works for variable text lengths! The idea to embed the words of a sentence, use convolutions, maxpooling and concantenation to embed the sentence as a single vector! This single vector is passed through a fully connected layer with sigmoid to output a single value. This value can be interpreted as the probability a sentence is positive (closer to 1) or negative (closer to 0).\n",
    "\n",
    "The minimum length of text expected by the model is the size of the smallest kernel size of the model.\n",
    "\n",
    "* Embedding : (N, L)모양의 input을 (N, L, D) 모양으로 변경 N: 배치크기, L: 배치내의 최대길이, D: 임베딩차원(100)\n",
    "  * 여기서 쓴 vocab은 각 단어를 100개의 벡터차원으로 만들기 때문에 임베딩 차원은 100\n",
    "* Convolution: 커널크기가 3, 4, 5인 임베딩 단어들을 병렬 conv를 실행하여 trigrams, four-grams, five-grams을 모방(?). 결과적으로 conv당 (N, L-k+1, D)의 출력. k(커널크기)\n",
    "* Activation : relu\n",
    "* Polling : 윈도크기가 L-k+1인 conv에서 병렬 풀링 작업하여 풀링당 (N, 1, D)모양이 생성됨\n",
    "* Concat : (N, 3D) 모양생성, 이건 각 문장에 대한 단일 임베딩을 의미.\n",
    "* FC : (3D, 1)모양의 fc layer를 통과하여 단일 출력 제공, sigmoid로 확률 출력\n",
    "* load_embeddings : 사용자 입력을 기반으로 임베딩을 로드하도록 정의된 메서드, 3가지 모드가 있음. \n",
    "  * randomly initialized weights\n",
    "  * frozen pretrained weights\n",
    "  * trainable pretrained weights\n",
    "  \n",
    "본, 모델은 가변 텍스트에 대해 동작 가능. 모델이 예상하는 최소 텍스트 길이는 가장작은 커널 사이즈가 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "63z1tffDznkO"
   },
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        embedding_dim, \n",
    "        kernel_sizes, \n",
    "        num_filters, \n",
    "        num_classes, d_prob, mode):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.num_filters = num_filters\n",
    "        self.num_classes = num_classes\n",
    "        self.d_prob = d_prob\n",
    "        self.mode = mode\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size, embedding_dim, padding_idx=0)   # 1.배치크기(8), 배치최대길이(한문장) -> 8, 배치최대길이(한문장), 임베딩차원(100)\n",
    "        self.load_embeddings()\n",
    "        # 2.배치크기(8), 커널이용한 문장 축소(L-k+1), 임베딩차원(100)\n",
    "        self.conv = nn.ModuleList([nn.Conv1d(in_channels=embedding_dim,\n",
    "                                             out_channels=num_filters,\n",
    "                                             kernel_size=k, stride=1) for k in kernel_sizes])\n",
    "        self.dropout = nn.Dropout(d_prob)\n",
    "        self.fc = nn.Linear(len(kernel_sizes) * num_filters, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, sequence_length = x.shape\n",
    "        x = self.embedding(x.T).transpose(1, 2)\n",
    "        x = [F.relu(conv(x)) for conv in self.conv]   # x는 커널 3,4,5당 하나씩 생김\n",
    "        x = [F.max_pool1d(c, c.size(-1)).squeeze(dim=-1) for c in x] # 3. 커널 당, 배치크기(8), 1, 임베딩차원(100) 생성\n",
    "        x = torch.cat(x, dim=1) # 배치크기(8), 300<임베딩차원(100)*3> 생성\n",
    "        x = self.fc(self.dropout(x)) # 배치당 1개의 값변경\n",
    "        return torch.sigmoid(x).squeeze()\n",
    "\n",
    "    def load_embeddings(self):\n",
    "        if 'static' in self.mode:\n",
    "            self.embedding.weight.data.copy_(vocab.vectors)\n",
    "            if 'non' not in self.mode:\n",
    "                self.embedding.weight.data.requires_grad = False\n",
    "                print('Loaded pretrained embeddings, weights are not trainable.')\n",
    "            else:\n",
    "                self.embedding.weight.data.requires_grad = True\n",
    "                print('Loaded pretrained embeddings, weights are trainable.')\n",
    "        elif self.mode == 'rand':\n",
    "            print('Randomly initialized embeddings are used.')\n",
    "        else:\n",
    "            raise ValueError('Unexpected value of mode. Please choose from static, nonstatic, rand.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6G3TW4c-znkO"
   },
   "source": [
    "## Creating Model, Optimizer and Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7nH55oXznkP"
   },
   "source": [
    "Below we create an instance of the TextCNN model and load embeddings in **static** mode. The model is placed on a device and then a loss function of Binary Cross Entropy and Adam optimizer are setup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2004, 100])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "HM_7LQE3znkP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained embeddings, weights are not trainable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ducke/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:104: UserWarning: \n",
      "A100-SXM4-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the A100-SXM4-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "vocab_size, embedding_dim = vocab.vectors.shape\n",
    "\n",
    "model = TextCNN(vocab_size=vocab_size,\n",
    "                embedding_dim=embedding_dim,\n",
    "                kernel_sizes=[3, 4, 5],\n",
    "                num_filters=100,\n",
    "                num_classes=1, \n",
    "                d_prob=0.5,\n",
    "                mode='static')\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-3)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjxbAwvIznkP"
   },
   "source": [
    "## Training and Evaluating using Ignite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8Rl7spqznkQ"
   },
   "source": [
    "### Trainer Engine - process_function\n",
    "\n",
    "Ignite's Engine allows user to define a process_function to process a given batch, this is applied to all the batches of the dataset. This is a general class that can be applied to train and validate models! A process_function has two parameters engine and batch. \n",
    "\n",
    "\n",
    "Let's walk through what the function of the trainer does:\n",
    "\n",
    "* Sets model in train mode. \n",
    "* Sets the gradients of the optimizer to zero.\n",
    "* Generate x and y from batch.\n",
    "* Performs a forward pass to calculate y_pred using model and x.\n",
    "* Calculates loss using y_pred and y.\n",
    "* Performs a backward pass using loss to calculate gradients for the model parameters.\n",
    "* model parameters are optimized using gradients and optimizer.\n",
    "* Returns scalar loss. \n",
    "\n",
    "Below is a single operation during the trainig process. This process_function will be attached to the training engine.\n",
    "\n",
    "Ignite 엔진 사용하면 사용자가 주어진 배치를 처리하기 위해 process_fuction을 정의할 수 있음. 이때 한배치에 대한 함수정의만 해두면, 이걸로 모든 배치에 적용가능.(즉, epoch 설정을 안해도 되는 정도). 이렇게 fuction정의하면 training, validate에 둘다 적용. `engine`, `batch` 파라미터가 있음\n",
    "\n",
    "아래처럼 정의하면 training engine에 붙어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Q4ncIcYcznkQ"
   },
   "outputs": [],
   "source": [
    "def process_function(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    y, x = batch\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiiQr_GYznkQ"
   },
   "source": [
    "### Evaluator Engine - process_function\n",
    "\n",
    "Similar to the training process function, we setup a function to evaluate a single batch. Here is what the eval_function does:\n",
    "\n",
    "* Sets model in eval mode.\n",
    "* Generates x and y from batch.\n",
    "* With torch.no_grad(), no gradients are calculated for any succeding steps.\n",
    "* Performs a forward pass on the model to calculate y_pred based on model and x.\n",
    "* Returns y_pred and y.\n",
    "\n",
    "Ignite suggests attaching metrics to evaluators and not trainers because during the training the model parameters are constantly changing and it is best to evaluate model on a stationary model. This information is important as there is a difference in the functions for training and evaluating. Training returns a single scalar loss. Evaluating returns y_pred and y as that output is used to calculate metrics per batch for the entire dataset.\n",
    "\n",
    "All metrics in Ignite require y_pred and y as outputs of the function attached to the Engine. \n",
    "\n",
    "evaluator에 metric을 붙여야함. trainer는 loss를 반환, evaluate함수는 y_pred, y를 반환. 이걸로 배치당 metric을 계산하게 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "b9-G-9iVznkR"
   },
   "outputs": [],
   "source": [
    "def eval_function(engine, batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y, x = batch\n",
    "        y = y.to(device)\n",
    "        x = x.to(device)\n",
    "        y = y.float()\n",
    "        y_pred = model(x)\n",
    "        return y_pred, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcmIEZuNznkS"
   },
   "source": [
    "### Instantiating Training and Evaluating Engines\n",
    "\n",
    "Below we create 3 engines, a trainer, a training evaluator and a validation evaluator. You'll notice that train_evaluator and validation_evaluator use the same function, we'll see later why this was done! \n",
    "\n",
    "위를 이용하여 train, evaluating 엔진의 인스턴스를 만든다\n",
    "rain_evaluator와 validation_evaluator가 같은 기능을 사용한다는 것을 알 수 있을 것입니다. 우리는 이것이 왜 수행되었는지 나중에 알게 될 것입니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "k1CxFQs_znkS"
   },
   "outputs": [],
   "source": [
    "trainer = Engine(process_function)\n",
    "train_evaluator = Engine(eval_function)\n",
    "validation_evaluator = Engine(eval_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVu91uVtznkS"
   },
   "source": [
    "### Metrics - RunningAverage, Accuracy and Loss\n",
    "\n",
    "To start, we'll attach a metric of Running Average to track a running average of the scalar loss output for each batch. \n",
    "\n",
    "시작하려면 trainer에 Running Average의 메트릭을 연결하여 각 배치에 대한 스칼라 손실 출력의 실행 평균을 추적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "P-98lPU9znkS"
   },
   "outputs": [],
   "source": [
    "RunningAverage(output_transform=lambda x: x).attach(trainer, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mufkp6mnznkS"
   },
   "source": [
    "Now there are two metrics that we want to use for evaluation - accuracy and loss. This is a binary problem, so for Loss we can simply pass the Binary Cross Entropy function as the loss_function. \n",
    "\n",
    "For Accuracy, Ignite requires y_pred and y to be comprised of 0's and 1's only. Since our model outputs from a sigmoid layer, values are between 0 and 1. We'll need to write a function that transforms `engine.state.output` which is comprised of y_pred and y. \n",
    "\n",
    "Below `thresholded_output_transform` does just that, it rounds y_pred to convert y_pred to 0's and 1's, and then returns rounded y_pred and y. This function is the output_transform function used to transform the `engine.state.output` to achieve `Accuracy`'s desired purpose.\n",
    "\n",
    "Now, we attach `Loss` and `Accuracy` (with `thresholded_output_transform`) to train_evaluator and validation_evaluator. \n",
    "\n",
    "To attach a metric to engine, the following format is used:\n",
    "* `Metric(output_transform=output_transform, ...).attach(engine, 'metric_name')`\n",
    "\n",
    "----\n",
    "\n",
    "* evaluation에 사용하기위한 2가지 metric(accuracy, loss). 2진분류기 때문에 BCE를 사용함. \n",
    "* accuracy를 위해선, ignite metric에선 y_pred, y가 0과 1로만 구성되어야 함. 위의 모델에서 정의하길 sigmoid layer가 있기 때문에 0~1의 확률값이 나올테고 즉,, engine.state.output을 변환하는 함수를 작성해야 함.\n",
    "* 그 이후 loss, accuracy를 evaluator에 연결함(연결을 위해 아래의 문법을 사용) - loss는 불필요\n",
    "* `Metric(output_transform=output_transform, ...).attach(engine, 'metric_name')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "KAK6nXEbznkS"
   },
   "outputs": [],
   "source": [
    "def thresholded_output_transform(output):\n",
    "    y_pred, y = output\n",
    "    y_pred = torch.round(y_pred)  # 0.5를 기준으로 정수화\n",
    "    return y_pred, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "QkcC2R4qznkT"
   },
   "outputs": [],
   "source": [
    "# 뒤에 문자열 'accuracy', 'bce'는 사용자 임의의 이름을 붙여주는 것임\n",
    "Accuracy(output_transform=thresholded_output_transform).attach(train_evaluator, 'accuracy')\n",
    "Loss(criterion).attach(train_evaluator, 'bce')  # loss는 0,1변환 필요 x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "tLtT5f11znkT"
   },
   "outputs": [],
   "source": [
    "Accuracy(output_transform=thresholded_output_transform).attach(validation_evaluator, 'accuracy')\n",
    "Loss(criterion).attach(validation_evaluator, 'bce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbS2h_2eznkU"
   },
   "source": [
    "### Progress Bar\n",
    "\n",
    "Next we create an instance of Ignite's progess bar and attach it to the trainer and pass it a key of `engine.state.metrics` to track. In this case, the progress bar will be tracking `engine.state.metrics['loss']`\n",
    "\n",
    "Ignite의 progress bar를 trainer에 연결, metrics 키를 전달. 이렇게 되면 진행바는 `engine.state.metrics['loss']`를 추적함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "qteztuB3znkU"
   },
   "outputs": [],
   "source": [
    "pbar = ProgressBar(persist=True, bar_format=\"\")\n",
    "pbar.attach(trainer, ['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4DxUwXfznkU"
   },
   "source": [
    "### EarlyStopping - Tracking Validation Loss\n",
    "\n",
    "Now we'll setup a Early Stopping handler for this training process. EarlyStopping requires a score_function that allows the user to define whatever criteria to stop trainig. In this case, if the loss of the validation set does not decrease in 5 epochs, the training process will stop early.  \n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "early stopping에선 score_function으로 훈련을 중지할 기준을 전달함. 아래 코드는 5 epoch동안 valid set의 손실(bce)가 감소하지 않으면 학습 프로세스가 중지됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "wPM6-USgznkU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ignite.engine.events.RemovableEventHandle at 0x7f2f83f83820>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['bce']\n",
    "    return -val_loss   # 감소할 수록 좋은거니 -를 붙임(원래 3->2 면 stop, -3 -2면 stop안함)\n",
    "\n",
    "handler = EarlyStopping(patience=5, score_function=score_function, trainer=trainer)\n",
    "validation_evaluator.add_event_handler(Events.COMPLETED, handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfeL6EkhznkU"
   },
   "source": [
    "### Attaching Custom Functions to Engine at specific Events\n",
    "\n",
    "Below you'll see ways to define your own custom functions and attaching them to various `Events` of the training process.\n",
    "\n",
    "The functions below both achieve similar tasks, they print the results of the evaluator run on a dataset. One function does that on the training evaluator and dataset, while the other on the validation. Another difference is how these functions are attached in the trainer engine.\n",
    "\n",
    "The first method involves using a decorator, the syntax is simple - `@` `trainer.on(Events.EPOCH_COMPLETED)`, means that the decorated function will be attached to the trainer and called at the end of each epoch. \n",
    "\n",
    "The second method involves using the add_event_handler method of trainer - `trainer.add_event_handler(Events.EPOCH_COMPLETED, custom_function)`. This achieves the same result as the above. \n",
    "\n",
    "----\n",
    "\n",
    "### 특정 이벤트 시점에서 에서 Egine에 사용자 함수 연결 \n",
    "사용자 정의 함수를 정의하고 training 과정의 다양한 event 시점에 연결하는 방법을 살펴본다. 아래 함수 두개는 비슷한 작업을 수행하며 데이터 세트에서 실행한 evaluator의 결과를 실행. 하나는 train evaluator에 실행하고 다른하나는 validation evaluator에 실행. \n",
    "\n",
    "* 방법 1: '@' 데코레이터 사용, trainer.on(Events.EPOCH_COMPLETED)는 각 epoch가 끝날때 호출\n",
    "* 방법 2: `trainer.add_event_handler(Events.EPOCH_COMPLETED, custom_function)` 사용, 같은 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "3XsmcAA2znkV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ignite.engine.events.RemovableEventHandle at 0x7f2f803914f0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(engine):\n",
    "    train_evaluator.run(train_iterator)\n",
    "    metrics = train_evaluator.state.metrics\n",
    "    avg_accuracy = metrics['accuracy']\n",
    "    avg_bce = metrics['bce']\n",
    "    pbar.log_message(\n",
    "        \"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "        .format(engine.state.epoch, avg_accuracy, avg_bce))\n",
    "    \n",
    "def log_validation_results(engine):\n",
    "    validation_evaluator.run(valid_iterator)\n",
    "    metrics = validation_evaluator.state.metrics\n",
    "    avg_accuracy = metrics['accuracy']\n",
    "    avg_bce = metrics['bce']\n",
    "    pbar.log_message(\n",
    "        \"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "        .format(engine.state.epoch, avg_accuracy, avg_bce))\n",
    "    pbar.n = pbar.last_print_n = 0\n",
    "\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, log_validation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAQEr88cznkW"
   },
   "source": [
    "### ModelCheckpoint\n",
    "\n",
    "Lastly, we want to checkpoint this model. It's important to do so, as training processes can be time consuming and if for some reason something goes wrong during training, a model checkpoint can be helpful to restart training from the point of failure.\n",
    "\n",
    "Below we'll use Ignite's `ModelCheckpoint` handler to checkpoint models at the end of each epoch. \n",
    "\n",
    "체크포인트 : 훈련 프로세스가 시간이 많이 소요될텐데 중간에 끊기면 다시 시작 가능. 아래코드를 이용하여 각 epoch가 끝날 때 모델을 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "9Gl6WT0YznkW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ignite.engine.events.RemovableEventHandle at 0x7f2f83ede280>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint('models_textcnn', 'textcnn', n_saved=2, create_dir=True, save_as_state_dict=True)\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpointer, {'textcnn': model})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxCIriIEznkW"
   },
   "source": [
    "### Run Engine\n",
    "\n",
    "Next, we'll run the trainer for 20 epochs and monitor results. Below we can see that progess bar prints the loss per iteration, and prints the results of training and validation as we specified in our custom function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export TORCH_CUDA_ARCH_LIST=8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "sPe46cQOznkX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ignite.engine.engine.Engine:Current run is terminating due to exception: CUDA error: no kernel image is available for execution on the device\n",
      "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: CUDA error: no kernel image is available for execution on the device\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1340/1554393505.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Current run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1340/879238988.py\u001b[0m in \u001b[0;36mprocess_function\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1340/3998341408.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# x는 커널 3,4,5당 하나씩 생김\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# 3. 커널 당, 배치크기(8), 1, 임베딩차원(100) 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1916\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device"
     ]
    }
   ],
   "source": [
    "trainer.run(train_iterator, max_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1+cu102'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting pytorch\n",
      "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pytorch\n",
      "  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/conda/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-na2v2ml_/pytorch_31350aa890a34774b922c3460b955fde/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-na2v2ml_/pytorch_31350aa890a34774b922c3460b955fde/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-ajty9sb7\n",
      "       cwd: /tmp/pip-install-na2v2ml_/pytorch_31350aa890a34774b922c3460b955fde/\n",
      "  Complete output (5 lines):\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"/tmp/pip-install-na2v2ml_/pytorch_31350aa890a34774b922c3460b955fde/setup.py\", line 15, in <module>\n",
      "      raise Exception(message)\n",
      "  Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for pytorch\n",
      "Failed to build pytorch\n",
      "Installing collected packages: pytorch\n",
      "    Running setup.py install for pytorch ... \u001b[?25lerror\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-na2v2ml_/pytorch_31350aa890a34774b922c3460b955fde/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-na2v2ml_/pytorch_31350aa890a34774b922c3460b955fde/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-m93vr007/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ducke/.local/include/python3.8/pytorch\n",
      "         cwd: /tmp/pip-install-na2v2ml_/pytorch_31350aa890a34774b922c3460b955fde/\n",
      "    Complete output (5 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-na2v2ml_/pytorch_31350aa890a34774b922c3460b955fde/setup.py\", line 11, in <module>\n",
      "        raise Exception(message)\n",
      "    Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: /opt/conda/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-na2v2ml_/pytorch_31350aa890a34774b922c3460b955fde/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-na2v2ml_/pytorch_31350aa890a34774b922c3460b955fde/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-m93vr007/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ducke/.local/include/python3.8/pytorch Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpqXiZUsznkY"
   },
   "source": [
    "That's it! We have successfully trained and evaluated a Convolutational Neural Network for Text Classification. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
