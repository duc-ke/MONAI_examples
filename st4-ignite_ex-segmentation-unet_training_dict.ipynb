{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4458cef1",
   "metadata": {},
   "source": [
    "다음을 리뷰 :\n",
    "https://github.com/Project-MONAI/tutorials/blob/master/3d_segmentation/ignite/unet_training_dict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9003715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib    # nifti 포맷 파일 생성때만 이용\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import monai\n",
    "## decollate_batch : 배치 텐서를 리스트의 텐서로 변환\n",
    "from monai.data import ImageDataset, create_test_image_3d, decollate_batch\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsChannelFirstd,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    RandCropByPosNegLabeld,  # randomly crop patch samples from big image based on pos / neg ratio.\n",
    "    RandRotate90d,\n",
    "    ScaleIntensityd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.data import Dataset   # dict에선 ImageDataset대신 이용\n",
    "from monai.data import list_data_collate\n",
    "\n",
    "\n",
    "# Events : process point를 지정 Events.EPOCH_COMPETED\n",
    "from ignite.engine import (\n",
    "    Events,  \n",
    "    _prepare_batch,                    ### 새롭게 들어옴\n",
    "    create_supervised_evaluator, \n",
    "    create_supervised_trainer\n",
    ")\n",
    "# ModelCheckpoint : training 동안 모델 계속 저장\n",
    "from ignite.handlers import EarlyStopping, ModelCheckpoint\n",
    "from monai.handlers import (\n",
    "    MeanDice,          # val_metric {}를 정의시 넣음\n",
    "    StatsHandler,      # 각 epoch마다 loss, metric 출력\n",
    "    TensorBoardImageHandler,\n",
    "    TensorBoardStatsHandler,    # 각 epoch마다 loss, metric plot\n",
    "    stopping_fn_from_metric,    # ignite EarlyStopping 과 연결, metric기준 stopping\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8b517e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.9.dev2152\n",
      "Numpy version: 1.21.2\n",
      "Pytorch version: 1.10.0a0+0aef44c\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: c5bd8aff8ba461d7b349eb92427d452481a7eb72\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.6\n",
      "Nibabel version: 3.2.1\n",
      "scikit-image version: 0.18.3\n",
      "Pillow version: 8.4.0\n",
      "Tensorboard version: 2.6.0\n",
      "gdown version: 4.2.0\n",
      "TorchVision version: 0.11.0a0\n",
      "tqdm version: 4.62.3\n",
      "lmdb version: 1.2.1\n",
      "psutil version: 5.8.0\n",
      "pandas version: 1.3.4\n",
      "einops version: 0.3.2\n",
      "transformers version: 4.12.5\n",
      "mlflow version: 1.21.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "generating synthetic data to ./dataset (this may take a while)\n"
     ]
    }
   ],
   "source": [
    "tempdir = './dataset'\n",
    "monai.config.print_config()\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '5,6,7,8'\n",
    "\n",
    "## 디렉토리에 40개 랜덤이미지, 마스크 생성\n",
    "print(f\"generating synthetic data to {tempdir} (this may take a while)\")\n",
    "for i in range(40):\n",
    "    # np image 생성\n",
    "    im, seg = create_test_image_3d(128, 128, 128, num_seg_classes=1, channel_dim=-1)  \n",
    "#     print(type(im), type(seg))  # np.array, (128, 128, 128, 1)\n",
    "#     print(im.shape, seg.shape)  # (128, 128, 128) (128, 128, 128) 3d 라서 img, seg가 같은 dim인 듯?\n",
    "\n",
    "    n = nib.Nifti1Image(im, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, f\"img{i:d}.nii.gz\"))\n",
    "\n",
    "    n = nib.Nifti1Image(seg, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, f\"seg{i:d}.nii.gz\"))\n",
    "\n",
    "## 파일이름들 가져오기\n",
    "images = sorted(glob(os.path.join(tempdir, \"img*.nii.gz\")))    # 40개 nifti file 리스트\n",
    "segs = sorted(glob(os.path.join(tempdir, \"seg*.nii.gz\")))\n",
    "\n",
    "train_files = [{\"img\": img, \"seg\": seg}for img, seg in zip(images[:20], segs[:20])]\n",
    "val_files = [{\"img\": img, \"seg\": seg}for img, seg in zip(images[-20:], segs[-20:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f070f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 96, 96, 96]) torch.Size([8, 1, 96, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "## transform 정의\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),   # list에선 ImageDataset을 대신썻기 때문에 LoadImage가 포함되어있었음\n",
    "        AsChannelFirstd(keys=[\"img\", \"seg\"], channel_dim=-1),\n",
    "        ScaleIntensityd(keys=\"img\"),   # scaling은 img에만.\n",
    "        # aug\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"img\", \"seg\"],\n",
    "            label_key=\"seg\",\n",
    "            spatial_size=[96, 96, 96],\n",
    "            pos=1,   # foreground voxel as a center rather than a background voxel. ``pos / (pos + neg)``\n",
    "            neg=1,\n",
    "            num_samples=4    # 1개 이미지당 4개 결과생성. 즉 4배로 뻥튀기\n",
    "        ),\n",
    "        RandRotate90d(keys=[\"img\", \"seg\"], prob=0.5, spatial_axes=[0, 2]),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"])\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),  \n",
    "        AsChannelFirstd(keys=[\"img\", \"seg\"], channel_dim=-1),\n",
    "        ScaleIntensityd(keys=\"img\"), \n",
    "        EnsureTyped(keys=[\"img\", \"seg\"])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 잘 되는지 프로세스 검증\n",
    "check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "# RandCrop에서 samples 4개 만들면, 이게 리스트로 만들어짐. 이걸 풀어서 tensor 하나에 8개(2x4)를 넣어주는게 list_data_collate임\n",
    "check_loader = DataLoader(check_ds, batch_size=2, num_workers=4, collate_fn=list_data_collate)\n",
    "# check_loader = DataLoader(check_ds, batch_size=2, num_workers=4)\n",
    "check_data = monai.utils.misc.first(check_loader)\n",
    "print(check_data[\"img\"].shape, check_data[\"seg\"].shape)\n",
    "\n",
    "\n",
    "train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "# create a validation data loader\n",
    "val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(\n",
    "    val_ds, \n",
    "    batch_size=5, num_workers=8, \n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f5d8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = monai.networks.nets.UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)\n",
    "loss = monai.losses.DiceLoss(sigmoid=True)\n",
    "opt = torch.optim.Adam(net.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03565fe8",
   "metadata": {},
   "source": [
    "### Ignite -training 관련 정의\n",
    "dict form일때 prepare_batch 만 달라짐, trainer 만들때 넣어줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36c04200",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### !! prepare_batch : dictform + ignite 일때 꼭 해줘야 하는듯\n",
    "# Ignite trainer expects batch=(img, seg) and returns output=loss at every iteration,\n",
    "# user can add output_transform to return other values, like: y_pred, y, etc.\n",
    "def prepare_batch(batch, device=None, non_blocking=False):\n",
    "    return _prepare_batch((batch[\"img\"], batch[\"seg\"]), device, non_blocking)\n",
    "\n",
    "trainer = create_supervised_trainer(\n",
    "    net, opt, loss, device, False, prepare_batch=prepare_batch\n",
    ")\n",
    "\n",
    "###### !!Check Point!! : 모델 저장\n",
    "checkpoint_handler = ModelCheckpoint(\n",
    "    dirname=\"./runs_dict/\",\n",
    "    filename_prefix=\"net\",\n",
    "    n_saved=5,    # 딱 10개만 저장, 더 업데이트 되면 덮어쓰기\n",
    "    require_empty=False  # True: 기존 모델이 dir에 있다면 덮어쓰지 않고 오류\n",
    ")\n",
    "trainer.add_event_handler(\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    handler=checkpoint_handler,\n",
    "    to_save={\"net\": net, \"opt\": opt}    # opt는 딱히 뭔진 모르겠음\n",
    ")\n",
    "\n",
    "###### !! StatsHandler!! : 각 iter와 각 epoch 마다 loss와 metrics를 출력\n",
    "# StatsHandler prints loss at every iteration and print metrics at every epoch,\n",
    "# we don't set metrics for trainer here, so just print loss, user can also customize print functions\n",
    "# and can use output_transform to convert engine.state.output if it's not a loss value\n",
    "# trainer에 metrics만 설정 해뒀다면 loss뿐 아니라 프린트를 커스터 마이징 가능(여기엔 안되어 있음)\n",
    "train_stats_handler = StatsHandler(name=\"trainer\", output_transform=lambda x: x)\n",
    "train_stats_handler.attach(trainer)\n",
    "\n",
    "###### !! TensorBoardStatsHandler!! : 각 iter, epoch마다 loss와 metric을 plot. statshandler와 같음\n",
    "# TensorBoardStatsHandler plots loss at every iteration and plots metrics at every epoch, same as StatsHandler\n",
    "train_tensorboard_stats_handler = TensorBoardStatsHandler(output_transform=lambda x:x)\n",
    "train_tensorboard_stats_handler.attach(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b1391",
   "metadata": {},
   "source": [
    "### Ignite - valid 관련 정의\n",
    "달라진점. \n",
    "* dict-form이라 달라진게 아니라 validation도 iter마다 볼수있게 코드 수정\n",
    "* prepare_batch를 evaluator 만들때 넣어줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85bed355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 16:20:40,403 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State:\n",
      "\titeration: 38\n",
      "\tepoch: 4\n",
      "\tepoch_length: 10\n",
      "\tmax_epochs: 5\n",
      "\toutput: 0.5253188610076904\n",
      "\tbatch: <class 'dict'>\n",
      "\tmetrics: <class 'dict'>\n",
      "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "\tseed: <class 'NoneType'>\n",
      "\ttimes: <class 'dict'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric_name = \"Mean_Dice\"\n",
    "val_metrics = {metric_name: MeanDice()}\n",
    "validation_every_n_iters = 1    # listform일때, validation_every_n_epochs = 1\n",
    "post_pred = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(threshold=0.5)])   # 정답(label)에 대한 post-proc\n",
    "\n",
    "## post-processing과정이 까다롭다..\n",
    "evaluator = create_supervised_evaluator(\n",
    "    net,\n",
    "    val_metrics,\n",
    "    device,\n",
    "    True,\n",
    "    # 순서 바꿔도 되야하지 않나\n",
    "    output_transform=lambda x, y, y_pred: ([post_pred(i) for i in decollate_batch(y_pred)], [post_label(i) for i in decollate_batch(y)]),\n",
    "    prepare_batch=prepare_batch,\n",
    ")\n",
    "\n",
    "###### !! evaluator proc 정의 !!\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=validation_every_n_iters))  ## 각 iter끝날때 마다로 변경\n",
    "def run_validation(engine):\n",
    "    evaluator.run(val_loader)\n",
    "    \n",
    "###### !! EarlyStopping !!\n",
    "early_stopper = EarlyStopping(\n",
    "    patience=4,\n",
    "    score_function=stopping_fn_from_metric(metric_name),\n",
    "    trainer=trainer\n",
    ")\n",
    "evaluator.add_event_handler(\n",
    "    event_name=Events.EPOCH_COMPLETED, \n",
    "    handler=early_stopper\n",
    ")\n",
    "\n",
    "###### !! StatsHandler!! : 각 iter와 각 epoch 마다 loss와 metrics를 출력 for validation\n",
    "val_stats_handler = StatsHandler(\n",
    "    name=\"evaluator\",\n",
    "    output_transform=lambda x: None,   # no need to print loss value, so disable per iteration output\n",
    "    global_epoch_transform=lambda x: trainer.state.epoch,    # trainer에서 global epoch number 가져오기\n",
    ")\n",
    "val_stats_handler.attach(evaluator)\n",
    "\n",
    "###### !! TensorBoardStatsHandler!! : 각 iter, epoch마다 loss와 metric을 plot. statshandler와 같음\n",
    "val_tensorboard_stats_handler = TensorBoardStatsHandler(\n",
    "    output_transform=lambda x: None,  # no need to plot loss value, so disable per iteration output\n",
    "    global_epoch_transform=lambda x: trainer.state.iteration,   # ?? epoch?? iteration????????????????????\n",
    ")\n",
    "val_tensorboard_stats_handler.attach(evaluator)\n",
    "\n",
    "###### !! TensorBoardImageHandler!! : 마지막 배치(?)에서 첫 번째 이미지와 해당 레이블 및 모델 출력을 그리는 핸들러 추가.\n",
    "# 매 validation spoch에서 그림그리기\n",
    "# add handler to draw the first image and the corresponding label and model output in the last batch\n",
    "# here we draw the 3D output as GIF format along Depth axis, at every validation epoch\n",
    "\n",
    "# batch_transform : ignite.engine.state.batch 에서 이미지와 레이블 가져올 수 있음\n",
    "# output_transform : ignite.engine.state.output 에서 prediction 결과 이미지 가져옴, output[index] index는 몇번째 element인지\n",
    "val_tensorboard_image_handler = TensorBoardImageHandler(\n",
    "    batch_transform=lambda batch: (batch[\"img\"], batch[\"seg\"]),\n",
    "    output_transform=lambda output: output[0],\n",
    "    global_iter_transform=lambda x: trainer.state.epoch,\n",
    ")\n",
    "evaluator.add_event_handler(\n",
    "    event_name=Events.ITERATION_COMPLETED(every=2), handler=val_tensorboard_image_handler\n",
    ")\n",
    "\n",
    "train_epochs = 5\n",
    "state = trainer.run(train_loader, train_epochs)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59aaa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39adbea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "state.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f3e8d6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_53681/2603388734.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'engine' is not defined"
     ]
    }
   ],
   "source": [
    "engine.state.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9540ccf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1a6ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f655bd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b193fee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20850b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f016ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba23d6e7",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aff2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from ignite.engine import (\n",
    "    Events,\n",
    "    _prepare_batch,\n",
    "    create_supervised_evaluator,\n",
    "    create_supervised_trainer,\n",
    ")\n",
    "from ignite.handlers import EarlyStopping, ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import monai\n",
    "from monai.data import create_test_image_3d, list_data_collate, decollate_batch\n",
    "from monai.handlers import (\n",
    "    MeanDice,\n",
    "    StatsHandler,\n",
    "    TensorBoardImageHandler,\n",
    "    TensorBoardStatsHandler,\n",
    "    stopping_fn_from_metric,\n",
    ")\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsChannelFirstd,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandRotate90d,\n",
    "    ScaleIntensityd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    ")\n",
    "\n",
    "tempdir = './dataset'\n",
    "monai.config.print_config()\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '5,6,7,8'\n",
    "\n",
    "# create a temporary directory and 40 random image, mask pairs\n",
    "print(f\"generating synthetic data to {tempdir} (this may take a while)\")\n",
    "for i in range(40):\n",
    "    im, seg = create_test_image_3d(128, 128, 128, num_seg_classes=1, channel_dim=-1)\n",
    "\n",
    "    n = nib.Nifti1Image(im, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, f\"img{i:d}.nii.gz\"))\n",
    "\n",
    "    n = nib.Nifti1Image(seg, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, f\"seg{i:d}.nii.gz\"))\n",
    "\n",
    "images = sorted(glob(os.path.join(tempdir, \"img*.nii.gz\")))\n",
    "segs = sorted(glob(os.path.join(tempdir, \"seg*.nii.gz\")))\n",
    "train_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images[:20], segs[:20])]\n",
    "val_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images[-20:], segs[-20:])]\n",
    "\n",
    "# define transforms for image and segmentation\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "        AsChannelFirstd(keys=[\"img\", \"seg\"], channel_dim=-1),\n",
    "        ScaleIntensityd(keys=\"img\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"img\", \"seg\"],\n",
    "            label_key=\"seg\",\n",
    "            spatial_size=[96, 96, 96],\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "        ),\n",
    "        RandRotate90d(keys=[\"img\", \"seg\"], prob=0.5, spatial_axes=[0, 2]),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "        AsChannelFirstd(keys=[\"img\", \"seg\"], channel_dim=-1),\n",
    "        ScaleIntensityd(keys=\"img\"),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# define dataset, data loader\n",
    "check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "check_loader = DataLoader(\n",
    "    check_ds,\n",
    "    batch_size=2,\n",
    "    num_workers=4,\n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "check_data = monai.utils.misc.first(check_loader)\n",
    "print(check_data[\"img\"].shape, check_data[\"seg\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c73834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a training data loader\n",
    "train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "# create a validation data loader\n",
    "val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=5,\n",
    "    num_workers=8,\n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "# create UNet, DiceLoss and Adam optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = monai.networks.nets.UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)\n",
    "loss = monai.losses.DiceLoss(sigmoid=True)\n",
    "lr = 1e-3\n",
    "opt = torch.optim.Adam(net.parameters(), lr)\n",
    "\n",
    "# Ignite trainer expects batch=(img, seg) and returns output=loss at every iteration,\n",
    "# user can add output_transform to return other values, like: y_pred, y, etc.\n",
    "def prepare_batch(batch, device=None, non_blocking=False):\n",
    "    return _prepare_batch((batch[\"img\"], batch[\"seg\"]), device, non_blocking)\n",
    "\n",
    "trainer = create_supervised_trainer(\n",
    "    net, opt, loss, device, False, prepare_batch=prepare_batch\n",
    ")\n",
    "\n",
    "# adding checkpoint handler to save models (network params and optimizer stats) during training\n",
    "checkpoint_handler = ModelCheckpoint(\n",
    "    \"./runs_dict/\", \"net\", n_saved=10, require_empty=False\n",
    ")\n",
    "trainer.add_event_handler(\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    handler=checkpoint_handler,\n",
    "    to_save={\"net\": net, \"opt\": opt},\n",
    ")\n",
    "\n",
    "# StatsHandler prints loss at every iteration and print metrics at every epoch,\n",
    "# we don't set metrics for trainer here, so just print loss, user can also customize print functions\n",
    "# and can use output_transform to convert engine.state.output if it's not loss value\n",
    "train_stats_handler = StatsHandler(name=\"trainer\", output_transform=lambda x: x)\n",
    "train_stats_handler.attach(trainer)\n",
    "\n",
    "# TensorBoardStatsHandler plots loss at every iteration and plots metrics at every epoch, same as StatsHandler\n",
    "train_tensorboard_stats_handler = TensorBoardStatsHandler(output_transform=lambda x: x)\n",
    "train_tensorboard_stats_handler.attach(trainer)\n",
    "\n",
    "validation_every_n_iters = 5\n",
    "# set parameters for validation\n",
    "metric_name = \"Mean_Dice\"\n",
    "# add evaluation metric to the evaluator engine\n",
    "val_metrics = {metric_name: MeanDice()}\n",
    "\n",
    "post_pred = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(threshold=0.5)])\n",
    "\n",
    "# Ignite evaluator expects batch=(img, seg) and returns output=(y_pred, y) at every iteration,\n",
    "# user can add output_transform to return other values\n",
    "evaluator = create_supervised_evaluator(\n",
    "    net,\n",
    "    val_metrics,\n",
    "    device,\n",
    "    True,\n",
    "    output_transform=lambda x, y, y_pred: ([post_pred(i) for i in decollate_batch(y_pred)], [post_label(i) for i in decollate_batch(y)]),\n",
    "    prepare_batch=prepare_batch,\n",
    ")\n",
    "\n",
    "\n",
    "# validation은 training의 5 iter마다 진행\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=validation_every_n_iters))\n",
    "def run_validation(engine):\n",
    "    evaluator.run(val_loader)\n",
    "\n",
    "# add early stopping handler to evaluator\n",
    "early_stopper = EarlyStopping(\n",
    "    patience=4, score_function=stopping_fn_from_metric(metric_name), trainer=trainer\n",
    ")\n",
    "evaluator.add_event_handler(\n",
    "    event_name=Events.EPOCH_COMPLETED, handler=early_stopper\n",
    ")\n",
    "\n",
    "# add stats event handler to print validation stats via evaluator\n",
    "val_stats_handler = StatsHandler(\n",
    "    name=\"evaluator\",\n",
    "    output_transform=lambda x: None,  # no need to print loss value, so disable per iteration output\n",
    "    global_epoch_transform=lambda x: trainer.state.iteration,\n",
    ")  # fetch global epoch number from trainer\n",
    "val_stats_handler.attach(evaluator)\n",
    "\n",
    "# add handler to record metrics to TensorBoard at every validation epoch\n",
    "val_tensorboard_stats_handler = TensorBoardStatsHandler(\n",
    "    output_transform=lambda x: None,  # no need to plot loss value, so disable per iteration output\n",
    "    global_epoch_transform=lambda x: trainer.state.iteration,\n",
    ")  # fetch global iteration number from trainer\n",
    "val_tensorboard_stats_handler.attach(evaluator)\n",
    "\n",
    "# add handler to draw the first image and the corresponding label and model output in the last batch\n",
    "# here we draw the 3D output as GIF format along the depth axis, every 2 validation iterations.\n",
    "val_tensorboard_image_handler = TensorBoardImageHandler(\n",
    "    batch_transform=lambda batch: (batch[\"img\"], batch[\"seg\"]),\n",
    "    output_transform=lambda output: output[0],\n",
    "    global_iter_transform=lambda x: trainer.state.epoch,\n",
    ")\n",
    "# 그림 그리는 이벤트는 iter 2마다 일어나지만 그림은 tensorboard의 그림은 epoch마다 확인가능\n",
    "evaluator.add_event_handler(\n",
    "    event_name=Events.ITERATION_COMPLETED(every=2),\n",
    "    handler=val_tensorboard_image_handler,\n",
    ")\n",
    "\n",
    "train_epochs = 5\n",
    "state = trainer.run(train_loader, train_epochs)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf7322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
