{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4458cef1",
   "metadata": {},
   "source": [
    "다음을 리뷰 :\n",
    "https://github.com/Project-MONAI/tutorials/blob/master/3d_segmentation/ignite/unet_training_dict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9003715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import monai\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib    # nifti 포맷 파일 생성때만 이용\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import monai\n",
    "## decollate_batch : 배치 텐서를 리스트의 텐서로 변환\n",
    "from monai.data import ImageDataset, create_test_image_3d, decollate_batch\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsChannelFirstd,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    RandCropByPosNegLabeld,  # randomly crop patch samples from big image based on pos / neg ratio.\n",
    "    RandRotate90d,\n",
    "    ScaleIntensityd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.data import Dataset   # dict에선 ImageDataset대신 이용\n",
    "from monai.data import list_data_collate\n",
    "\n",
    "\n",
    "# Events : process point를 지정 Events.EPOCH_COMPETED\n",
    "from ignite.engine import (\n",
    "    Events,  \n",
    "    _prepare_batch,                    ### 새롭게 들어옴\n",
    "    create_supervised_evaluator, \n",
    "    create_supervised_trainer\n",
    ")\n",
    "# ModelCheckpoint : training 동안 모델 계속 저장\n",
    "from ignite.handlers import EarlyStopping, ModelCheckpoint\n",
    "from monai.handlers import (\n",
    "    MeanDice,          # val_metric {}를 정의시 넣음\n",
    "    StatsHandler,      # 각 epoch마다 loss, metric 출력\n",
    "    TensorBoardImageHandler,\n",
    "    TensorBoardStatsHandler,    # 각 epoch마다 loss, metric plot\n",
    "    stopping_fn_from_metric,    # ignite EarlyStopping 과 연결, metric기준 stopping\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b517e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.9.dev2152\n",
      "Numpy version: 1.21.2\n",
      "Pytorch version: 1.10.0a0+0aef44c\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: c5bd8aff8ba461d7b349eb92427d452481a7eb72\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.6\n",
      "Nibabel version: 3.2.1\n",
      "scikit-image version: 0.18.3\n",
      "Pillow version: 8.4.0\n",
      "Tensorboard version: 2.6.0\n",
      "gdown version: 4.2.0\n",
      "TorchVision version: 0.11.0a0\n",
      "tqdm version: 4.62.3\n",
      "lmdb version: 1.2.1\n",
      "psutil version: 5.8.0\n",
      "pandas version: 1.3.4\n",
      "einops version: 0.3.2\n",
      "transformers version: 4.12.5\n",
      "mlflow version: 1.21.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "generating synthetic data to ./data/unet_ignite (this may take a while)\n"
     ]
    }
   ],
   "source": [
    "tempdir = './data/unet_ignite'\n",
    "monai.config.print_config()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "## 디렉토리에 40개 랜덤이미지, 마스크 생성\n",
    "print(f\"generating synthetic data to {tempdir} (this may take a while)\")\n",
    "for i in range(40):\n",
    "    # np image 생성\n",
    "    im, seg = create_test_image_3d(128, 128, 128, num_seg_classes=1, channel_dim=-1)  \n",
    "#     print(type(im), type(seg))  # np.array, (128, 128, 128, 1)\n",
    "#     print(im.shape, seg.shape)  # (128, 128, 128) (128, 128, 128) 3d 라서 img, seg가 같은 dim인 듯?\n",
    "\n",
    "    n = nib.Nifti1Image(im, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, f\"img{i:d}.nii.gz\"))\n",
    "\n",
    "    n = nib.Nifti1Image(seg, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, f\"seg{i:d}.nii.gz\"))\n",
    "\n",
    "## 파일이름들 가져오기\n",
    "images = sorted(glob(os.path.join(tempdir, \"img*.nii.gz\")))    # 40개 nifti file 리스트\n",
    "segs = sorted(glob(os.path.join(tempdir, \"seg*.nii.gz\")))\n",
    "\n",
    "train_files = [{\"img\": img, \"seg\": seg}for img, seg in zip(images[:20], segs[:20])]\n",
    "val_files = [{\"img\": img, \"seg\": seg}for img, seg in zip(images[-20:], segs[-20:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f070f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 96, 96, 96]) torch.Size([8, 1, 96, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "## transform 정의\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),   # list에선 ImageDataset을 대신썻기 때문에 LoadImage가 포함되어있었음\n",
    "        AsChannelFirstd(keys=[\"img\", \"seg\"], channel_dim=-1),\n",
    "        ScaleIntensityd(keys=\"img\"),   # scaling은 img에만.\n",
    "        # aug\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"img\", \"seg\"],\n",
    "            label_key=\"seg\",\n",
    "            spatial_size=[96, 96, 96],\n",
    "            pos=1,   # foreground voxel as a center rather than a background voxel. ``pos / (pos + neg)``\n",
    "            neg=1,\n",
    "            num_samples=4    # 1개 이미지당 4개 결과생성. 즉 4배로 뻥튀기\n",
    "        ),\n",
    "        RandRotate90d(keys=[\"img\", \"seg\"], prob=0.5, spatial_axes=[0, 2]),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"])\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),  \n",
    "        AsChannelFirstd(keys=[\"img\", \"seg\"], channel_dim=-1),\n",
    "        ScaleIntensityd(keys=\"img\"), \n",
    "        EnsureTyped(keys=[\"img\", \"seg\"])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 잘 되는지 프로세스 검증\n",
    "check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "# RandCrop에서 samples 4개 만들면, 이게 리스트로 만들어짐. 이걸 풀어서 tensor 하나에 8개(2x4)를 넣어주는게 list_data_collate임\n",
    "check_loader = DataLoader(check_ds, batch_size=2, num_workers=4, collate_fn=list_data_collate)\n",
    "# check_loader = DataLoader(check_ds, batch_size=2, num_workers=4)\n",
    "check_data = monai.utils.misc.first(check_loader)\n",
    "print(check_data[\"img\"].shape, check_data[\"seg\"].shape)\n",
    "\n",
    "\n",
    "train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "# create a validation data loader\n",
    "val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(\n",
    "    val_ds, \n",
    "    batch_size=5, num_workers=8, \n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f5d8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = monai.networks.nets.UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)\n",
    "loss = monai.losses.DiceLoss(sigmoid=True)\n",
    "opt = torch.optim.Adam(net.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03565fe8",
   "metadata": {},
   "source": [
    "### Ignite -training 관련 정의\n",
    "dict form일때 prepare_batch 만 달라짐, trainer 만들때 넣어줌\n",
    "\n",
    "handler는 monai + ignite껄 혼용해서 사용 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36c04200",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### !! prepare_batch : dictform + ignite 일때 꼭 해줘야 하는듯\n",
    "# ignite trainer는 batch=(img, seg)라 생각하고(즉, 리스트폼이라 생각) 매 iteration end 마다 output=loss를 return 함\n",
    "# 만약 필요하다면 output_transform을 붙여서 loss 대신 다른 값을 return가능 ex) y_pred, y 등등\n",
    "# Ignite trainer expects batch=(img, seg) and returns output=loss at every iteration,\n",
    "# user can add output_transform to return other values, like: y_pred, y, etc.\n",
    "\n",
    "\"\"\"예시(https://pytorch.org/ignite/quickstart.html)\n",
    "def custom_output_transform(x, y, y_pred, loss):\n",
    "    return {\n",
    "        \"y\": y,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"loss\": loss.item()\n",
    "    }\n",
    "\n",
    "trainer = create_supervised_trainer(\n",
    "    model, optimizer, criterion, device, output_transform=custom_output_transform\n",
    ")\n",
    "\"\"\"\n",
    "def prepare_batch(batch, device=None, non_blocking=False):\n",
    "    return _prepare_batch((batch[\"img\"], batch[\"seg\"]), device, non_blocking)\n",
    "\n",
    "\n",
    "## Ignite - create_supervised_trainer\n",
    "trainer = create_supervised_trainer(\n",
    "    net, opt, loss, device, False, prepare_batch=prepare_batch\n",
    ")\n",
    "\n",
    "###### !! Ignite - Check Point!! : 모델 저장\n",
    "checkpoint_handler = ModelCheckpoint(\n",
    "    dirname=\"./runs_dict/\",\n",
    "    filename_prefix=\"net\",\n",
    "    n_saved=5,    # 딱 5개만 저장, 더 업데이트 되면 덮어쓰기\n",
    "    require_empty=False  # True: 기존 모델이 dir에 있다면 덮어쓰지 않고 오류\n",
    ")\n",
    "trainer.add_event_handler(\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    handler=checkpoint_handler,\n",
    "    to_save={\"net\": net, \"opt\": opt}    # opt는 위에서 정의한 optimization method\n",
    ")\n",
    "\n",
    "###### !! Monai - StatsHandler!! : 각 iter와 각 epoch 마다 loss와 metrics를 출력\n",
    "# StatsHandler prints loss at every iteration and print metrics at every epoch,\n",
    "# we don't set metrics for trainer here, so just print loss, user can also customize print functions\n",
    "# and can use output_transform to convert engine.state.output if it's not a loss value\n",
    "# trainer에 metrics만 설정 해뒀다면 loss뿐 아니라 프린트를 커스터 마이징 가능(여기엔 안되어 있음)\n",
    "train_stats_handler = StatsHandler(name=\"trainer\", output_transform=lambda x: x)\n",
    "train_stats_handler.attach(trainer)\n",
    "\n",
    "###### !! Monai - TensorBoardStatsHandler!! : 각 iter, epoch마다 loss와 metric을 plot. statshandler와 같음\n",
    "# TensorBoardStatsHandler plots loss at every iteration and plots metrics at every epoch, same as StatsHandler\n",
    "train_tensorboard_stats_handler = TensorBoardStatsHandler(output_transform=lambda x:x)\n",
    "train_tensorboard_stats_handler.attach(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b1391",
   "metadata": {},
   "source": [
    "### Ignite - valid 관련 정의\n",
    "달라진점. \n",
    "* dict-form이라 달라진게 아니라 validation도 iter마다 볼수있게 코드 수정\n",
    "* prepare_batch를 evaluator 만들때 넣어줌\n",
    "* post_transform은 evaluator에 붙인다.!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85bed355",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=10.\n",
      "INFO:trainer:Epoch: 1/10, Iter: 1/10 -- Loss: 0.6278 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[1] Metrics -- Mean_Dice: 0.4878 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:02\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:03\n",
      "INFO:trainer:Epoch: 1/10, Iter: 2/10 -- Loss: 0.5839 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[1] Metrics -- Mean_Dice: 0.5753 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 1/10, Iter: 3/10 -- Loss: 0.5477 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[1] Metrics -- Mean_Dice: 0.6843 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 1/10, Iter: 4/10 -- Loss: 0.5428 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[1] Metrics -- Mean_Dice: 0.7503 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 1/10, Iter: 5/10 -- Loss: 0.5047 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[1] Metrics -- Mean_Dice: 0.8256 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 1/10, Iter: 6/10 -- Loss: 0.5137 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[1] Metrics -- Mean_Dice: 0.8665 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 1/10, Iter: 7/10 -- Loss: 0.5594 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[1] Metrics -- Mean_Dice: 0.8771 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 1/10, Iter: 8/10 -- Loss: 0.4862 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[1] Metrics -- Mean_Dice: 0.8804 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 1/10, Iter: 9/10 -- Loss: 0.5051 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[1] Metrics -- Mean_Dice: 0.8767 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 1/10, Iter: 10/10 -- Loss: 0.5344 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[1] Metrics -- Mean_Dice: 0.8752 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:49\n",
      "INFO:trainer:Epoch: 2/10, Iter: 1/10 -- Loss: 0.4900 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[2] Metrics -- Mean_Dice: 0.8752 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 2/10, Iter: 2/10 -- Loss: 0.5002 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[2] Metrics -- Mean_Dice: 0.8806 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 2/10, Iter: 3/10 -- Loss: 0.4880 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[2] Metrics -- Mean_Dice: 0.8835 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 2/10, Iter: 4/10 -- Loss: 0.4783 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[2] Metrics -- Mean_Dice: 0.8842 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 2/10, Iter: 5/10 -- Loss: 0.4225 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[2] Metrics -- Mean_Dice: 0.8893 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 2/10, Iter: 6/10 -- Loss: 0.4395 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[2] Metrics -- Mean_Dice: 0.8847 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 2/10, Iter: 7/10 -- Loss: 0.5512 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[2] Metrics -- Mean_Dice: 0.8907 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 2/10, Iter: 8/10 -- Loss: 0.5007 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[2] Metrics -- Mean_Dice: 0.8928 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 2/10, Iter: 9/10 -- Loss: 0.4230 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[2] Metrics -- Mean_Dice: 0.8925 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 2/10, Iter: 10/10 -- Loss: 0.4191 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[2] Metrics -- Mean_Dice: 0.8888 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:ignite.engine.engine.Engine:Epoch[2] Complete. Time taken: 00:00:46\n",
      "INFO:trainer:Epoch: 3/10, Iter: 1/10 -- Loss: 0.4312 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[3] Metrics -- Mean_Dice: 0.8767 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 3/10, Iter: 2/10 -- Loss: 0.5127 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[3] Metrics -- Mean_Dice: 0.8803 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:05\n",
      "INFO:trainer:Epoch: 3/10, Iter: 3/10 -- Loss: 0.4029 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[3] Metrics -- Mean_Dice: 0.8843 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 3/10, Iter: 4/10 -- Loss: 0.4340 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[3] Metrics -- Mean_Dice: 0.8858 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 3/10, Iter: 5/10 -- Loss: 0.3995 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:evaluator:Epoch[3] Metrics -- Mean_Dice: 0.8858 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 3/10, Iter: 6/10 -- Loss: 0.4632 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[3] Metrics -- Mean_Dice: 0.8871 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 3/10, Iter: 7/10 -- Loss: 0.4269 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[3] Metrics -- Mean_Dice: 0.8869 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 3/10, Iter: 8/10 -- Loss: 0.4150 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[3] Metrics -- Mean_Dice: 0.8850 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 3/10, Iter: 9/10 -- Loss: 0.4276 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[3] Metrics -- Mean_Dice: 0.8816 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 3/10, Iter: 10/10 -- Loss: 0.4867 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[3] Metrics -- Mean_Dice: 0.8763 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:05\n",
      "INFO:ignite.engine.engine.Engine:Epoch[3] Complete. Time taken: 00:00:49\n",
      "INFO:trainer:Epoch: 4/10, Iter: 1/10 -- Loss: 0.4947 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[4] Metrics -- Mean_Dice: 0.8737 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 4/10, Iter: 2/10 -- Loss: 0.3918 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[4] Metrics -- Mean_Dice: 0.8744 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 4/10, Iter: 3/10 -- Loss: 0.4355 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[4] Metrics -- Mean_Dice: 0.8781 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 4/10, Iter: 4/10 -- Loss: 0.4433 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[4] Metrics -- Mean_Dice: 0.8821 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 4/10, Iter: 5/10 -- Loss: 0.4039 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[4] Metrics -- Mean_Dice: 0.8842 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 4/10, Iter: 6/10 -- Loss: 0.3821 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[4] Metrics -- Mean_Dice: 0.8840 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 4/10, Iter: 7/10 -- Loss: 0.4342 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[4] Metrics -- Mean_Dice: 0.8838 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 4/10, Iter: 8/10 -- Loss: 0.4090 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[4] Metrics -- Mean_Dice: 0.8832 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 4/10, Iter: 9/10 -- Loss: 0.4838 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[4] Metrics -- Mean_Dice: 0.8847 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 4/10, Iter: 10/10 -- Loss: 0.3333 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[4] Metrics -- Mean_Dice: 0.8865 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:ignite.engine.engine.Engine:Epoch[4] Complete. Time taken: 00:00:49\n",
      "INFO:trainer:Epoch: 5/10, Iter: 1/10 -- Loss: 0.3896 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[5] Metrics -- Mean_Dice: 0.8896 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 5/10, Iter: 2/10 -- Loss: 0.3475 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[5] Metrics -- Mean_Dice: 0.8911 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 5/10, Iter: 3/10 -- Loss: 0.4322 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[5] Metrics -- Mean_Dice: 0.8913 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 5/10, Iter: 4/10 -- Loss: 0.4392 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[5] Metrics -- Mean_Dice: 0.8883 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 5/10, Iter: 5/10 -- Loss: 0.3634 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[5] Metrics -- Mean_Dice: 0.8801 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 5/10, Iter: 6/10 -- Loss: 0.4700 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[5] Metrics -- Mean_Dice: 0.8782 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 5/10, Iter: 7/10 -- Loss: 0.4372 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n",
      "INFO:evaluator:Epoch[5] Metrics -- Mean_Dice: 0.8801 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:trainer:Epoch: 5/10, Iter: 8/10 -- Loss: 0.3823 \n",
      "INFO:ignite.engine.engine.Engine:Engine run starting with max_epochs=1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 08:35:15,048 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ignite.engine.engine.Engine:Terminate signaled. Engine will stop after current iteration is finished.\n",
      "INFO:evaluator:Epoch[5] Metrics -- Mean_Dice: 0.8798 \n",
      "INFO:ignite.engine.engine.Engine:Epoch[1] Complete. Time taken: 00:00:03\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:00:04\n",
      "INFO:ignite.engine.engine.Engine:Epoch[5] Complete. Time taken: 00:00:39\n",
      "INFO:ignite.engine.engine.Engine:Engine run complete. Time taken: 00:03:53\n",
      "State:\n",
      "\titeration: 48\n",
      "\tepoch: 5\n",
      "\tepoch_length: 10\n",
      "\tmax_epochs: 10\n",
      "\toutput: 0.3823434114456177\n",
      "\tbatch: <class 'dict'>\n",
      "\tmetrics: <class 'dict'>\n",
      "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "\tseed: <class 'NoneType'>\n",
      "\ttimes: <class 'dict'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric_name = \"Mean_Dice\"\n",
    "val_metrics = {metric_name: MeanDice()}\n",
    "validation_every_n_iters = 1    # listform일때, validation_every_n_epochs = 1\n",
    "post_pred = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(threshold=0.5)])   # 정답(label)에 대한 post-proc\n",
    "\n",
    "## post-processing과정이 까다롭다..\n",
    "## Ignite - create_supervised_trainer\n",
    "# 참고 : non_blocking: if True and this copy is between CPU and GPU, the copy may occur asynchronously\n",
    "evaluator = create_supervised_evaluator(\n",
    "    net,\n",
    "    val_metrics,\n",
    "    device,\n",
    "    True,\n",
    "    # 순서 바꿔도 되야하지 않나\n",
    "    output_transform=lambda x, y, y_pred: ([post_pred(i) for i in decollate_batch(y_pred)], [post_label(i) for i in decollate_batch(y)]),\n",
    "    prepare_batch=prepare_batch,\n",
    ")\n",
    "\n",
    "###### !! evaluator proc run 시점 정의 !!\n",
    "### Q?!! : 실제 결과를 보면 patience가 epoch이 아닌 interation으로 들어감.\n",
    "### !! 아.. validation이 iteration 끝날때 마다 실행되도록 했기 때문이다.\n",
    "### 둘다 epoch 끝날때 마다로 맞춰야 할듯하다.\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=validation_every_n_iters))  ## 각 iter끝날때 마다로 변경\n",
    "# @trainer.on(Events.EPOCH_COMPLETED(every=validation_every_n_iters))  ## 각 epoch 끝날때 마다\n",
    "def run_validation(engine):\n",
    "    evaluator.run(val_loader)\n",
    "    \n",
    "###### !! Ignite - EarlyStopping !!\n",
    "early_stopper = EarlyStopping(\n",
    "    patience=30,    # validation 10 iter = 1 epoch으로 현재 설정되어있음\n",
    "    score_function=stopping_fn_from_metric(metric_name),  # # ignite EarlyStopping 과 연결, metric기준 stopping\n",
    "    trainer=trainer\n",
    ")\n",
    "evaluator.add_event_handler(\n",
    "    event_name=Events.EPOCH_COMPLETED, \n",
    "    handler=early_stopper\n",
    ")\n",
    "\n",
    "###### !! MONAI handler - StatsHandler!! : 각 iter와 각 epoch 마다 loss와 metrics를 출력 for validation\n",
    "val_stats_handler = StatsHandler(\n",
    "    name=\"evaluator\",\n",
    "    output_transform=lambda x: None,   # no need to print loss value, so disable per iteration output\n",
    "    global_epoch_transform=lambda x: trainer.state.epoch,    # trainer에서 global epoch number 가져오기\n",
    ")\n",
    "val_stats_handler.attach(evaluator)\n",
    "\n",
    "###### !! MONAI handler - TensorBoardStatsHandler!! : 각 iter, epoch마다 loss와 metric을 plot. statshandler와 같음\n",
    "val_tensorboard_stats_handler = TensorBoardStatsHandler(\n",
    "    output_transform=lambda x: None,  # no need to plot loss value, so disable per iteration output\n",
    "    global_epoch_transform=lambda x: trainer.state.iteration,   # ?? epoch?? iteration????????????????????\n",
    ")\n",
    "val_tensorboard_stats_handler.attach(evaluator)\n",
    "\n",
    "###### !! MONAI handler - TensorBoardImageHandler!! : 마지막 배치(?)에서 첫 번째 이미지와 해당 레이블 및 모델 출력을 그리는 핸들러 추가.\n",
    "# 매 validation spoch에서 그림그리기\n",
    "# add handler to draw the first image and the corresponding label and model output in the last batch\n",
    "# here we draw the 3D output as GIF format along Depth axis, at every validation epoch\n",
    "\n",
    "# batch_transform : ignite.engine.state.batch 에서 이미지와 레이블 가져올 수 있음\n",
    "# output_transform : ignite.engine.state.output 에서 prediction 결과 이미지 가져옴, output[index] index는 몇번째 element인지\n",
    "val_tensorboard_image_handler = TensorBoardImageHandler(\n",
    "    batch_transform=lambda batch: (batch[\"img\"], batch[\"seg\"]),\n",
    "    output_transform=lambda output: output[0],\n",
    "    global_iter_transform=lambda x: trainer.state.epoch,\n",
    ")\n",
    "evaluator.add_event_handler(\n",
    "    event_name=Events.ITERATION_COMPLETED(every=2), handler=val_tensorboard_image_handler\n",
    ")\n",
    "\n",
    "train_epochs = 10\n",
    "state = trainer.run(train_loader, train_epochs)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f59aaa39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 48\n",
       "\tepoch: 5\n",
       "\tepoch_length: 10\n",
       "\tmax_epochs: 10\n",
       "\toutput: 0.3823434114456177\n",
       "\tbatch: <class 'dict'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
       "\tseed: <class 'NoneType'>\n",
       "\ttimes: <class 'dict'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39adbea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9540ccf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1a6ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f655bd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b193fee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20850b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f016ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba23d6e7",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aff2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from ignite.engine import (\n",
    "    Events,\n",
    "    _prepare_batch,\n",
    "    create_supervised_evaluator,\n",
    "    create_supervised_trainer,\n",
    ")\n",
    "from ignite.handlers import EarlyStopping, ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import monai\n",
    "from monai.data import create_test_image_3d, list_data_collate, decollate_batch\n",
    "from monai.handlers import (\n",
    "    MeanDice,\n",
    "    StatsHandler,\n",
    "    TensorBoardImageHandler,\n",
    "    TensorBoardStatsHandler,\n",
    "    stopping_fn_from_metric,\n",
    ")\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsChannelFirstd,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandRotate90d,\n",
    "    ScaleIntensityd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    ")\n",
    "\n",
    "tempdir = './dataset'\n",
    "monai.config.print_config()\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '5,6,7,8'\n",
    "\n",
    "# create a temporary directory and 40 random image, mask pairs\n",
    "print(f\"generating synthetic data to {tempdir} (this may take a while)\")\n",
    "for i in range(40):\n",
    "    im, seg = create_test_image_3d(128, 128, 128, num_seg_classes=1, channel_dim=-1)\n",
    "\n",
    "    n = nib.Nifti1Image(im, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, f\"img{i:d}.nii.gz\"))\n",
    "\n",
    "    n = nib.Nifti1Image(seg, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, f\"seg{i:d}.nii.gz\"))\n",
    "\n",
    "images = sorted(glob(os.path.join(tempdir, \"img*.nii.gz\")))\n",
    "segs = sorted(glob(os.path.join(tempdir, \"seg*.nii.gz\")))\n",
    "train_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images[:20], segs[:20])]\n",
    "val_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(images[-20:], segs[-20:])]\n",
    "\n",
    "# define transforms for image and segmentation\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "        AsChannelFirstd(keys=[\"img\", \"seg\"], channel_dim=-1),\n",
    "        ScaleIntensityd(keys=\"img\"),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"img\", \"seg\"],\n",
    "            label_key=\"seg\",\n",
    "            spatial_size=[96, 96, 96],\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "        ),\n",
    "        RandRotate90d(keys=[\"img\", \"seg\"], prob=0.5, spatial_axes=[0, 2]),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "        AsChannelFirstd(keys=[\"img\", \"seg\"], channel_dim=-1),\n",
    "        ScaleIntensityd(keys=\"img\"),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# define dataset, data loader\n",
    "check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "check_loader = DataLoader(\n",
    "    check_ds,\n",
    "    batch_size=2,\n",
    "    num_workers=4,\n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "check_data = monai.utils.misc.first(check_loader)\n",
    "print(check_data[\"img\"].shape, check_data[\"seg\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c73834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a training data loader\n",
    "train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "# create a validation data loader\n",
    "val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=5,\n",
    "    num_workers=8,\n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "# create UNet, DiceLoss and Adam optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = monai.networks.nets.UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)\n",
    "loss = monai.losses.DiceLoss(sigmoid=True)\n",
    "lr = 1e-3\n",
    "opt = torch.optim.Adam(net.parameters(), lr)\n",
    "\n",
    "# Ignite trainer expects batch=(img, seg) and returns output=loss at every iteration,\n",
    "# user can add output_transform to return other values, like: y_pred, y, etc.\n",
    "def prepare_batch(batch, device=None, non_blocking=False):\n",
    "    return _prepare_batch((batch[\"img\"], batch[\"seg\"]), device, non_blocking)\n",
    "\n",
    "trainer = create_supervised_trainer(\n",
    "    net, opt, loss, device, False, prepare_batch=prepare_batch\n",
    ")\n",
    "\n",
    "# adding checkpoint handler to save models (network params and optimizer stats) during training\n",
    "checkpoint_handler = ModelCheckpoint(\n",
    "    \"./runs_dict/\", \"net\", n_saved=10, require_empty=False\n",
    ")\n",
    "trainer.add_event_handler(\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    handler=checkpoint_handler,\n",
    "    to_save={\"net\": net, \"opt\": opt},\n",
    ")\n",
    "\n",
    "# StatsHandler prints loss at every iteration and print metrics at every epoch,\n",
    "# we don't set metrics for trainer here, so just print loss, user can also customize print functions\n",
    "# and can use output_transform to convert engine.state.output if it's not loss value\n",
    "train_stats_handler = StatsHandler(name=\"trainer\", output_transform=lambda x: x)\n",
    "train_stats_handler.attach(trainer)\n",
    "\n",
    "# TensorBoardStatsHandler plots loss at every iteration and plots metrics at every epoch, same as StatsHandler\n",
    "train_tensorboard_stats_handler = TensorBoardStatsHandler(output_transform=lambda x: x)\n",
    "train_tensorboard_stats_handler.attach(trainer)\n",
    "\n",
    "validation_every_n_iters = 5\n",
    "# set parameters for validation\n",
    "metric_name = \"Mean_Dice\"\n",
    "# add evaluation metric to the evaluator engine\n",
    "val_metrics = {metric_name: MeanDice()}\n",
    "\n",
    "post_pred = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(threshold=0.5)])\n",
    "\n",
    "# Ignite evaluator expects batch=(img, seg) and returns output=(y_pred, y) at every iteration,\n",
    "# user can add output_transform to return other values\n",
    "evaluator = create_supervised_evaluator(\n",
    "    net,\n",
    "    val_metrics,\n",
    "    device,\n",
    "    True,\n",
    "    output_transform=lambda x, y, y_pred: ([post_pred(i) for i in decollate_batch(y_pred)], [post_label(i) for i in decollate_batch(y)]),\n",
    "    prepare_batch=prepare_batch,\n",
    ")\n",
    "\n",
    "\n",
    "# validation은 training의 5 iter마다 진행\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=validation_every_n_iters))\n",
    "def run_validation(engine):\n",
    "    evaluator.run(val_loader)\n",
    "\n",
    "# add early stopping handler to evaluator\n",
    "early_stopper = EarlyStopping(\n",
    "    patience=4, score_function=stopping_fn_from_metric(metric_name), trainer=trainer\n",
    ")\n",
    "evaluator.add_event_handler(\n",
    "    event_name=Events.EPOCH_COMPLETED, handler=early_stopper\n",
    ")\n",
    "\n",
    "# add stats event handler to print validation stats via evaluator\n",
    "val_stats_handler = StatsHandler(\n",
    "    name=\"evaluator\",\n",
    "    output_transform=lambda x: None,  # no need to print loss value, so disable per iteration output\n",
    "    global_epoch_transform=lambda x: trainer.state.iteration,\n",
    ")  # fetch global epoch number from trainer\n",
    "val_stats_handler.attach(evaluator)\n",
    "\n",
    "# add handler to record metrics to TensorBoard at every validation epoch\n",
    "val_tensorboard_stats_handler = TensorBoardStatsHandler(\n",
    "    output_transform=lambda x: None,  # no need to plot loss value, so disable per iteration output\n",
    "    global_epoch_transform=lambda x: trainer.state.iteration,\n",
    ")  # fetch global iteration number from trainer\n",
    "val_tensorboard_stats_handler.attach(evaluator)\n",
    "\n",
    "# add handler to draw the first image and the corresponding label and model output in the last batch\n",
    "# here we draw the 3D output as GIF format along the depth axis, every 2 validation iterations.\n",
    "val_tensorboard_image_handler = TensorBoardImageHandler(\n",
    "    batch_transform=lambda batch: (batch[\"img\"], batch[\"seg\"]),\n",
    "    output_transform=lambda output: output[0],\n",
    "    global_iter_transform=lambda x: trainer.state.epoch,\n",
    ")\n",
    "# 그림 그리는 이벤트는 iter 2마다 일어나지만 그림은 tensorboard의 그림은 epoch마다 확인가능\n",
    "evaluator.add_event_handler(\n",
    "    event_name=Events.ITERATION_COMPLETED(every=2),\n",
    "    handler=val_tensorboard_image_handler,\n",
    ")\n",
    "\n",
    "train_epochs = 5\n",
    "state = trainer.run(train_loader, train_epochs)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf7322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
