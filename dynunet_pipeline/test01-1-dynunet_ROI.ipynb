{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a105b425",
   "metadata": {},
   "source": [
    "## dynunet pipeline with NeuroI ROI dataset\n",
    "* medicaldecathlon 을 이용한 4D multi classes segmentation. -> 동작함.\n",
    "* 아래 파이프라인을 바탕으로 현재 NEUROI ROI 데이터셋을 태워서 뭐가 문제가 있는지 확인해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cf9fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from monai.config import print_config\n",
    "from monai.handlers import (\n",
    "    CheckpointSaver,\n",
    "    LrScheduleHandler,\n",
    "    MeanDice,\n",
    "    StatsHandler,\n",
    "    ValidationHandler,\n",
    "    from_engine,\n",
    ")\n",
    "from monai.inferers import SimpleInferer, SlidingWindowInferer\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.utils import set_determinism\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "from create_dataset import get_data_ke\n",
    "from create_network import get_network_ke\n",
    "from evaluator import DynUNetEvaluator\n",
    "# from task_params import data_loader_params, patch_size\n",
    "from trainer import DynUNetTrainer\n",
    "\n",
    "from monai.utils import first\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4190dfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \ttrain.py -fold $fold -train_num_workers 4 -interval 10 -num_samples 2 \\\n",
    "# \t-learning_rate $lr -max_epochs 3000 -task_id 01 -pos_sample_num 1 \\\n",
    "# \t-expr_name baseline -tta_val True -multi_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af9f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_id = \"01\"\n",
    "# fold = 0\n",
    "# root_dir = \"/data/kehyeong/project/MONAI_examples/data/brats/\"\n",
    "# datalist_path =\"config/\"\n",
    "\n",
    "config = \"/work/NeuroI-models/ke-monai/config_gpu/config_roi_earlystop_toy_220209.yaml\"\n",
    "train_dataset = \"/work/NeuroI-models/ke-monai/data/roi/dataset_train_roi_toy2.csv\"\n",
    "val_dataset = \"/work/NeuroI-models/ke-monai/data/roi/dataset_val_roi_toy2.csv\"\n",
    "log_file = \"/data/train/running/l/model_roi_toy_220210/train.log\"\n",
    "checkpoint = None\n",
    "\n",
    "## [아래 config에서 불러 오는 params]\n",
    "# max_epochs = 1500\n",
    "# num_samples = 4\n",
    "# train_num_workers = 4\n",
    "# val_num_workers = 2\n",
    "\n",
    "patch_size = [64, 64, 64] # [128, 128, 128]    #[96, 96, 96]\n",
    "learning_rate = 1.0e-3    # working: 1e-1\n",
    "interval = 2\n",
    "multi_gpu = False  # True\n",
    "local_rank = 0\n",
    "\n",
    "## [Dafault setting] - 변경 필요 없음\n",
    "window_mode = \"gaussian\"  # \"constant\", \"gaussian\"\n",
    "eval_overlap = 0.5\n",
    "tta_val = True\n",
    "batch_dice = False\n",
    "lr_decay_flag = False\n",
    "spacing = [1.0, 1.0, 1.0]\n",
    "deep_supr_num = 3\n",
    "expr_name = \"baseline\"\n",
    "####################################\n",
    "\n",
    "\n",
    "# pos_sample_num = 1\n",
    "# neg_sample_num = 1\n",
    "# cache_rate = 1.0\n",
    "\n",
    "\n",
    "# mode = \"train\"\n",
    "# checkpoint = None\n",
    "# amp = False\n",
    "# lr_decay = False\n",
    "# tta_val = True\n",
    "# batch_dice = False\n",
    "# determinism_flag = False\n",
    "# determinism_seed = 0\n",
    "# expr_name = \"baseline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf83b130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0217 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0217 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0217 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0217 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0005 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0005 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0005 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0005 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0419 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0419 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0419 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0419 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0400 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0400 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0400 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0400 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0172 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0172 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0172 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0172 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0244 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0244 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0244 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0244 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0088 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0088 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0088 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0088 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0125 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0125 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0125 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0125 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0459 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0459 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0459 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0459 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0210 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0210 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0210 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0210 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0312 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0312 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0312 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0312 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0360 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0360 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0360 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0360 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0493 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0493 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0493 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0493 03_d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|█████████████████████████████████████████████████████████████████████████| 52/52 [00:28<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0454 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0454 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0303 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0303 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0197 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0197 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0350 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0350 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0317 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0317 01_d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|█████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from config import get_config\n",
    "from dataset_roi import get_train_loader, get_val_loader\n",
    "import monai\n",
    "\n",
    "local_rank = local_rank\n",
    "log_file = log_file\n",
    "train_dataset = train_dataset\n",
    "val_dataset = val_dataset\n",
    "checkpoint = checkpoint\n",
    "\n",
    "multi_gpu_flag = multi_gpu\n",
    "config = get_config(config)\n",
    "data_dir = config[\"data_dir\"]\n",
    "image_file_path = config[\"image_file_path\"]\n",
    "label_file_path = config[\"label_file_path\"]\n",
    "# brain_file_path = config[\"brain_file_path\"]\n",
    "mask_file_path = config[\"mask_file_path\"]\n",
    "random_seed = config[\"random_seed\"]\n",
    "max_epochs = config[\"train\"][\"max_epoches\"]\n",
    "num_classes = config[\"num_classes\"]\n",
    "\n",
    "# patch_size = tuple(config[\"patch_size\"])\n",
    "lr = config[\"train\"][\"lr\"]\n",
    "train_batch_size = config[\"train\"][\"batch_size\"]\n",
    "train_num_samples = config[\"train\"][\"num_samples\"]\n",
    "train_num_workers = config[\"train\"][\"num_workers\"]\n",
    "# val_interval = config[\"train\"][\"val_interval\"]\n",
    "val_batch_size = config[\"val\"][\"batch_size\"]\n",
    "sw_batch_size = val_batch_size    # for evaluator\n",
    "val_num_workers = config[\"val\"][\"num_workers\"]\n",
    "log_dir = config[\"log_dir\"]\n",
    "model_dir = config[\"model_dir\"]\n",
    "mlflow_dir = os.path.join(log_dir, \"mlruns\")\n",
    "\n",
    "amp_flag = (True if monai.utils.get_torch_version_tuple() >= (1, 6) else False,)\n",
    "\n",
    "monai.utils.set_determinism(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5,6\"\n",
    "\n",
    "if multi_gpu_flag:\n",
    "    dist.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "    device = torch.device(f\"cuda:{local_rank}\")\n",
    "    torch.cuda.set_device(device)\n",
    "else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "#\n",
    "# data loader\n",
    "#\n",
    "train_loader = get_train_loader(\n",
    "    data_dir=data_dir,\n",
    "    id_file=train_dataset,\n",
    "    image_file_pattern=image_file_path,\n",
    "    label_file_pattern=label_file_path,\n",
    "    # brain_file_pattern=brain_file_path,\n",
    "    mask_file_pattern=mask_file_path,\n",
    "    batch_size=train_batch_size,\n",
    "    patch_size=patch_size,\n",
    "    num_samples=train_num_samples,\n",
    "    num_workers=train_num_workers,\n",
    "    multi_gpu_flag=multi_gpu_flag\n",
    ")\n",
    "val_loader = get_val_loader(\n",
    "    data_dir=data_dir,\n",
    "    id_file=val_dataset,\n",
    "    image_file_pattern=image_file_path,\n",
    "    label_file_pattern=label_file_path,\n",
    "    # brain_file_pattern=brain_file_path,\n",
    "    mask_file_pattern=mask_file_path,\n",
    "    batch_size=val_batch_size,\n",
    "    num_workers=val_num_workers,\n",
    "    multi_gpu_flag=multi_gpu_flag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f73edccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be28fc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['image', 'label', 'image_meta_dict', 'label_meta_dict', 'image_transforms', 'label_transforms', 'resample_flag', 'anisotrophy_flag'])\n",
      "image, label shape\n",
      "torch.Size([12, 1, 64, 64, 64])\n",
      "torch.Size([12, 1, 64, 64, 64])\n",
      "torch.float32\n",
      "torch.uint8\n",
      "[  0   1   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  20  21  23  24  25  26  27  28  29  30  31  32  33  34  36  37  39  40\n",
      "  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
      "  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76\n",
      "  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94\n",
      "  95  96  97  98  99 100 101 102 103 104 105 106 107 108]\n",
      "class 수 104\n"
     ]
    }
   ],
   "source": [
    "test_data = first(train_loader)\n",
    "print(test_data.keys())\n",
    "print('image, label shape')\n",
    "print(test_data['image'].shape)\n",
    "print(test_data['label'].shape)\n",
    "print(test_data['image'].dtype)\n",
    "print(test_data['label'].dtype)\n",
    "print(np.unique(test_data['label']))\n",
    "total_labels = np.unique(test_data['label'])\n",
    "print(f'class 수 {len(total_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df1a7942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 32\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 54\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 50\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 48\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 52\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 31\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 52\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 28\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 63\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 70\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 42\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 38\n"
     ]
    }
   ],
   "source": [
    "for each in test_data['label']:\n",
    "    print(each.shape)\n",
    "    total_labels = np.unique(each)\n",
    "    print(f'class 수 {len(total_labels)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf0ef96",
   "metadata": {},
   "source": [
    "**modicaldecatholon 파이프라인 참고**\n",
    "\n",
    "```python\n",
    "task_id = task_id\n",
    "fold = fold\n",
    "val_output_dir = \"./runs_{}_fold{}_{}/\".format(task_id, fold, expr_name)\n",
    "log_filename = \"nnunet_task{}_fold{}.log\".format(task_id, fold)\n",
    "log_filename = os.path.join(val_output_dir, log_filename)\n",
    "interval = interval\n",
    "learning_rate = learning_rate\n",
    "max_epochs = max_epochs\n",
    "multi_gpu_flag = multi_gpu\n",
    "amp_flag = amp\n",
    "lr_decay_flag = lr_decay\n",
    "sw_batch_size = sw_batch_size\n",
    "tta_val = tta_val\n",
    "batch_dice = batch_dice\n",
    "window_mode = window_mode\n",
    "eval_overlap = eval_overlap\n",
    "local_rank = local_rank\n",
    "determinism_flag = determinism_flag\n",
    "determinism_seed = determinism_seed\n",
    "if determinism_flag:\n",
    "    set_determinism(seed=determinism_seed)\n",
    "    if local_rank == 0:\n",
    "        print(\"Using deterministic training.\")\n",
    "\n",
    "# transforms\n",
    "train_batch_size = data_loader_params[task_id][\"batch_size\"]\n",
    "if multi_gpu_flag:\n",
    "    dist.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "\n",
    "    device = torch.device(f\"cuda:{local_rank}\")\n",
    "    torch.cuda.set_device(device)\n",
    "else:\n",
    "    device = torch.device(\"cuda:3\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "properties, val_loader = get_data_ke(fold, task_id, root_dir, datalist_path, pos_sample_num,\n",
    "                                     neg_sample_num, num_samples, multi_gpu, val_num_workers,\n",
    "                                     cache_rate, train_num_workers, mode=\"validation\")\n",
    "_, train_loader = get_data_ke(fold, task_id, root_dir, datalist_path, pos_sample_num,\n",
    "                              neg_sample_num, num_samples, multi_gpu, val_num_workers,\n",
    "                              cache_rate, train_num_workers, \n",
    "                              batch_size=train_batch_size, mode=\"train\")\n",
    "\n",
    "## ke\n",
    "test_data = first(train_loader)\n",
    "print(test_data.keys())\n",
    "print('image, label shape')\n",
    "print(test_data['image'].shape)\n",
    "print(test_data['label'].shape)\n",
    "print(test_data['image'].dtype)\n",
    "print(test_data['label'].dtype)\n",
    "print(np.unique(test_data['label']))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0396624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 109)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties = {\n",
    "    'modality': [0],\n",
    "    'labels': np.arange(num_classes)\n",
    "}\n",
    "n_class = len(properties[\"labels\"])\n",
    "in_channels = len(properties[\"modality\"])\n",
    "in_channels, n_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2f1d38e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 05:35:46,665 - ignite.engine.engine.DynUNetTrainer - INFO - Engine run resuming from iteration 0, epoch 0 until 1500 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynUNet(\n",
      "  (input_block): UnetBasicBlock(\n",
      "    (conv1): Convolution(\n",
      "      (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "    (conv2): Convolution(\n",
      "      (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "    (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  )\n",
      "  (downsamples): ModuleList(\n",
      "    (0): UnetBasicBlock(\n",
      "      (conv1): Convolution(\n",
      "        (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (conv2): Convolution(\n",
      "        (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (1): UnetBasicBlock(\n",
      "      (conv1): Convolution(\n",
      "        (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (conv2): Convolution(\n",
      "        (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (2): UnetBasicBlock(\n",
      "      (conv1): Convolution(\n",
      "        (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (conv2): Convolution(\n",
      "        (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "  )\n",
      "  (bottleneck): UnetBasicBlock(\n",
      "    (conv1): Convolution(\n",
      "      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "    (conv2): Convolution(\n",
      "      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "    (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (norm1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (norm2): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  )\n",
      "  (upsamples): ModuleList(\n",
      "    (0): UnetUpBlock(\n",
      "      (transp_conv): Convolution(\n",
      "        (conv): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "      )\n",
      "      (conv_block): UnetBasicBlock(\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (1): UnetUpBlock(\n",
      "      (transp_conv): Convolution(\n",
      "        (conv): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "      )\n",
      "      (conv_block): UnetBasicBlock(\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (2): UnetUpBlock(\n",
      "      (transp_conv): Convolution(\n",
      "        (conv): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "      )\n",
      "      (conv_block): UnetBasicBlock(\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (3): UnetUpBlock(\n",
      "      (transp_conv): Convolution(\n",
      "        (conv): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "      )\n",
      "      (conv_block): UnetBasicBlock(\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output_block): UnetOutBlock(\n",
      "    (conv): Convolution(\n",
      "      (conv): Conv3d(32, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "    )\n",
      "  )\n",
      "  (deep_supervision_heads): ModuleList(\n",
      "    (0): UnetOutBlock(\n",
      "      (conv): Convolution(\n",
      "        (conv): Conv3d(64, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): UnetOutBlock(\n",
      "      (conv): Convolution(\n",
      "        (conv): Conv3d(128, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): UnetOutBlock(\n",
      "      (conv): Convolution(\n",
      "        (conv): Conv3d(256, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (skip_layers): DynUNetSkipLayer(\n",
      "    (downsample): UnetBasicBlock(\n",
      "      (conv1): Convolution(\n",
      "        (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (conv2): Convolution(\n",
      "        (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (next_layer): DynUNetSkipLayer(\n",
      "      (downsample): UnetBasicBlock(\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "      (next_layer): DynUNetSkipLayer(\n",
      "        (downsample): UnetBasicBlock(\n",
      "          (conv1): Convolution(\n",
      "            (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "          )\n",
      "          (conv2): Convolution(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          )\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (next_layer): DynUNetSkipLayer(\n",
      "          (downsample): UnetBasicBlock(\n",
      "            (conv1): Convolution(\n",
      "              (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "            )\n",
      "            (conv2): Convolution(\n",
      "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            )\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          )\n",
      "          (next_layer): UnetBasicBlock(\n",
      "            (conv1): Convolution(\n",
      "              (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "            )\n",
      "            (conv2): Convolution(\n",
      "              (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            )\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (norm1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (norm2): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          )\n",
      "          (upsample): UnetUpBlock(\n",
      "            (transp_conv): Convolution(\n",
      "              (conv): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "            )\n",
      "            (conv_block): UnetBasicBlock(\n",
      "              (conv1): Convolution(\n",
      "                (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              )\n",
      "              (conv2): Convolution(\n",
      "                (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              )\n",
      "              (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "              (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (super_head): UnetOutBlock(\n",
      "            (conv): Convolution(\n",
      "              (conv): Conv3d(256, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (upsample): UnetUpBlock(\n",
      "          (transp_conv): Convolution(\n",
      "            (conv): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "          )\n",
      "          (conv_block): UnetBasicBlock(\n",
      "            (conv1): Convolution(\n",
      "              (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            )\n",
      "            (conv2): Convolution(\n",
      "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            )\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          )\n",
      "        )\n",
      "        (super_head): UnetOutBlock(\n",
      "          (conv): Convolution(\n",
      "            (conv): Conv3d(128, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (upsample): UnetUpBlock(\n",
      "        (transp_conv): Convolution(\n",
      "          (conv): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "        )\n",
      "        (conv_block): UnetBasicBlock(\n",
      "          (conv1): Convolution(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          )\n",
      "          (conv2): Convolution(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          )\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (super_head): UnetOutBlock(\n",
      "        (conv): Convolution(\n",
      "          (conv): Conv3d(64, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (upsample): UnetUpBlock(\n",
      "      (transp_conv): Convolution(\n",
      "        (conv): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "      )\n",
      "      (conv_block): UnetBasicBlock(\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 05:35:56,973 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 1/17 -- train_loss: 11.4669 \n",
      "2022-02-16 05:35:57,280 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 2/17 -- train_loss: 9.7904 \n",
      "2022-02-16 05:35:57,572 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 3/17 -- train_loss: 8.3554 \n",
      "2022-02-16 05:35:57,905 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 4/17 -- train_loss: 6.9775 \n",
      "2022-02-16 05:35:58,284 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 5/17 -- train_loss: 7.1816 \n",
      "2022-02-16 05:35:58,576 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 6/17 -- train_loss: 6.2885 \n",
      "2022-02-16 05:35:58,868 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 7/17 -- train_loss: 6.5609 \n",
      "2022-02-16 05:35:59,414 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 8/17 -- train_loss: 5.7142 \n",
      "2022-02-16 05:35:59,759 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 9/17 -- train_loss: 5.5518 \n",
      "2022-02-16 05:36:00,096 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 10/17 -- train_loss: 6.5249 \n",
      "2022-02-16 05:36:00,426 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 11/17 -- train_loss: 6.9737 \n",
      "2022-02-16 05:36:00,764 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 12/17 -- train_loss: 6.2910 \n",
      "2022-02-16 05:36:01,097 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 13/17 -- train_loss: 5.7672 \n",
      "2022-02-16 05:36:01,437 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 14/17 -- train_loss: 6.1738 \n",
      "2022-02-16 05:36:01,764 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 15/17 -- train_loss: 5.6421 \n",
      "2022-02-16 05:36:02,105 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 16/17 -- train_loss: 6.3578 \n",
      "2022-02-16 05:36:02,438 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 17/17 -- train_loss: 6.5547 \n",
      "2022-02-16 05:36:02,440 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-16 05:36:02,442 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[1] Complete. Time taken: 00:00:15\n",
      "2022-02-16 05:36:03,799 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 1/17 -- train_loss: 5.8791 \n",
      "2022-02-16 05:36:04,094 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 2/17 -- train_loss: 5.7244 \n",
      "2022-02-16 05:36:04,387 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 3/17 -- train_loss: 6.1795 \n",
      "2022-02-16 05:36:04,724 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 4/17 -- train_loss: 5.8834 \n",
      "2022-02-16 05:36:05,159 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 5/17 -- train_loss: 5.8792 \n",
      "2022-02-16 05:36:05,454 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 6/17 -- train_loss: 6.8360 \n",
      "2022-02-16 05:36:05,748 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 7/17 -- train_loss: 5.8641 \n",
      "2022-02-16 05:36:06,084 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 8/17 -- train_loss: 6.1688 \n",
      "2022-02-16 05:36:06,422 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 9/17 -- train_loss: 6.0120 \n",
      "2022-02-16 05:36:06,758 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 10/17 -- train_loss: 5.7039 \n",
      "2022-02-16 05:36:07,096 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 11/17 -- train_loss: 5.6310 \n",
      "2022-02-16 05:36:07,432 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 12/17 -- train_loss: 5.9223 \n",
      "2022-02-16 05:36:07,780 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 13/17 -- train_loss: 5.1134 \n",
      "2022-02-16 05:36:08,113 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 14/17 -- train_loss: 6.0851 \n",
      "2022-02-16 05:36:08,450 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 15/17 -- train_loss: 5.9809 \n",
      "2022-02-16 05:36:08,786 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 16/17 -- train_loss: 6.0087 \n",
      "2022-02-16 05:36:09,126 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 17/17 -- train_loss: 5.7550 \n",
      "2022-02-16 05:36:09,128 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run resuming from iteration 0, epoch 1 until 2 epochs\n",
      "2022-02-16 05:40:08,336 - ignite.engine.engine.DynUNetEvaluator - INFO - Got new best metric of val_mean_dice: 0.012682793661952019\n",
      "2022-02-16 05:40:08,347 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[2] Metrics -- val_mean_dice: 0.0127 \n",
      "2022-02-16 05:40:08,348 - ignite.engine.engine.DynUNetEvaluator - INFO - Key metric: val_mean_dice best value: 0.012682793661952019 at epoch: 2\n",
      "2022-02-16 05:40:08,689 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[2] Complete. Time taken: 00:03:59\n",
      "2022-02-16 05:40:08,690 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run complete. Time taken: 00:03:60\n",
      "2022-02-16 05:40:08,903 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-16 05:40:08,905 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[2] Complete. Time taken: 00:04:06\n",
      "2022-02-16 05:40:11,203 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 1/17 -- train_loss: 5.5870 \n",
      "2022-02-16 05:40:11,492 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 2/17 -- train_loss: 6.1434 \n",
      "2022-02-16 05:40:11,835 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 3/17 -- train_loss: 5.4489 \n",
      "2022-02-16 05:40:12,163 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 4/17 -- train_loss: 5.6464 \n",
      "2022-02-16 05:40:12,497 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 5/17 -- train_loss: 5.2642 \n",
      "2022-02-16 05:40:12,877 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 6/17 -- train_loss: 5.2990 \n",
      "2022-02-16 05:40:13,170 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 7/17 -- train_loss: 6.0352 \n",
      "2022-02-16 05:40:13,501 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 8/17 -- train_loss: 5.7113 \n",
      "2022-02-16 05:40:13,831 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 9/17 -- train_loss: 5.1906 \n",
      "2022-02-16 05:40:14,170 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 10/17 -- train_loss: 5.4612 \n",
      "2022-02-16 05:40:14,502 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 11/17 -- train_loss: 5.2564 \n",
      "2022-02-16 05:40:14,831 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 12/17 -- train_loss: 5.5147 \n",
      "2022-02-16 05:40:15,158 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 13/17 -- train_loss: 5.1979 \n",
      "2022-02-16 05:40:15,499 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 14/17 -- train_loss: 5.4697 \n",
      "2022-02-16 05:40:15,868 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 15/17 -- train_loss: 5.3667 \n",
      "2022-02-16 05:40:16,208 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 16/17 -- train_loss: 5.3020 \n",
      "2022-02-16 05:40:16,542 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 17/17 -- train_loss: 5.8544 \n",
      "2022-02-16 05:40:16,543 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-16 05:40:16,544 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[3] Complete. Time taken: 00:00:08\n",
      "2022-02-16 05:40:18,932 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 1/17 -- train_loss: 5.3807 \n",
      "2022-02-16 05:40:19,223 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 2/17 -- train_loss: 5.4036 \n",
      "2022-02-16 05:40:19,514 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 3/17 -- train_loss: 5.5003 \n",
      "2022-02-16 05:40:19,939 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 4/17 -- train_loss: 5.4951 \n",
      "2022-02-16 05:40:20,315 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 5/17 -- train_loss: 5.6670 \n",
      "2022-02-16 05:40:20,608 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 6/17 -- train_loss: 5.2603 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 05:40:20,907 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 7/17 -- train_loss: 5.3351 \n",
      "2022-02-16 05:40:21,200 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 8/17 -- train_loss: 5.2552 \n",
      "2022-02-16 05:40:21,543 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 9/17 -- train_loss: 5.1195 \n",
      "2022-02-16 05:40:21,883 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 10/17 -- train_loss: 5.6687 \n",
      "2022-02-16 05:40:22,223 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 11/17 -- train_loss: 5.2802 \n",
      "2022-02-16 05:40:22,559 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 12/17 -- train_loss: 5.2207 \n",
      "2022-02-16 05:40:22,896 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 13/17 -- train_loss: 5.6938 \n",
      "2022-02-16 05:40:23,236 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 14/17 -- train_loss: 5.2398 \n",
      "2022-02-16 05:40:23,576 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 15/17 -- train_loss: 5.4778 \n",
      "2022-02-16 05:40:23,911 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 16/17 -- train_loss: 5.1687 \n",
      "2022-02-16 05:40:24,253 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 17/17 -- train_loss: 5.4509 \n",
      "2022-02-16 05:40:24,255 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run resuming from iteration 0, epoch 3 until 4 epochs\n",
      "2022-02-16 05:43:46,208 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[4] Metrics -- val_mean_dice: 0.0113 \n",
      "2022-02-16 05:43:46,256 - ignite.engine.engine.DynUNetEvaluator - INFO - Key metric: val_mean_dice best value: 0.012682793661952019 at epoch: 2\n",
      "2022-02-16 05:43:46,261 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[4] Complete. Time taken: 00:03:20\n",
      "2022-02-16 05:43:46,262 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run complete. Time taken: 00:03:22\n",
      "2022-02-16 05:43:46,682 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-16 05:43:46,684 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[4] Complete. Time taken: 00:03:30\n",
      "2022-02-16 05:43:49,987 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 1/17 -- train_loss: 4.9432 \n",
      "2022-02-16 05:43:50,281 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 2/17 -- train_loss: 4.7799 \n",
      "2022-02-16 05:43:50,574 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 3/17 -- train_loss: 5.7802 \n",
      "2022-02-16 05:43:50,920 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 4/17 -- train_loss: 4.6457 \n",
      "2022-02-16 05:43:51,346 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 5/17 -- train_loss: 4.9953 \n",
      "2022-02-16 05:43:51,683 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 6/17 -- train_loss: 5.3820 \n",
      "2022-02-16 05:43:51,978 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 7/17 -- train_loss: 5.4198 \n",
      "2022-02-16 05:43:52,271 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 8/17 -- train_loss: 5.4054 \n",
      "2022-02-16 05:43:52,654 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 9/17 -- train_loss: 5.2817 \n",
      "2022-02-16 05:43:52,948 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 10/17 -- train_loss: 5.0149 \n",
      "2022-02-16 05:43:53,291 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 11/17 -- train_loss: 5.1456 \n",
      "2022-02-16 05:43:53,646 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 12/17 -- train_loss: 5.4812 \n",
      "2022-02-16 05:43:53,983 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 13/17 -- train_loss: 5.6350 \n",
      "2022-02-16 05:43:54,321 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 14/17 -- train_loss: 5.7634 \n",
      "2022-02-16 05:43:54,664 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 15/17 -- train_loss: 5.2701 \n",
      "2022-02-16 05:43:55,016 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 16/17 -- train_loss: 5.5171 \n",
      "2022-02-16 05:43:55,345 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 17/17 -- train_loss: 5.7541 \n",
      "2022-02-16 05:43:55,346 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-16 05:43:55,347 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[5] Complete. Time taken: 00:00:09\n",
      "2022-02-16 05:43:57,483 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 1/17 -- train_loss: 5.6909 \n",
      "2022-02-16 05:43:57,779 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 2/17 -- train_loss: 5.2753 \n",
      "2022-02-16 05:43:58,074 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 3/17 -- train_loss: 5.2506 \n",
      "2022-02-16 05:43:58,411 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 4/17 -- train_loss: 5.3404 \n",
      "2022-02-16 05:43:58,834 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 5/17 -- train_loss: 5.2657 \n",
      "2022-02-16 05:43:59,133 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 6/17 -- train_loss: 5.1346 \n",
      "2022-02-16 05:43:59,427 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 7/17 -- train_loss: 5.6188 \n",
      "2022-02-16 05:43:59,765 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 8/17 -- train_loss: 5.2035 \n",
      "2022-02-16 05:44:00,103 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 9/17 -- train_loss: 5.3511 \n",
      "2022-02-16 05:44:00,441 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 10/17 -- train_loss: 4.9303 \n",
      "2022-02-16 05:44:00,782 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 11/17 -- train_loss: 5.5148 \n",
      "2022-02-16 05:44:01,120 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 12/17 -- train_loss: 4.7762 \n",
      "2022-02-16 05:44:01,463 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 13/17 -- train_loss: 5.3500 \n",
      "2022-02-16 05:44:01,807 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 14/17 -- train_loss: 5.3331 \n",
      "2022-02-16 05:44:02,149 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 15/17 -- train_loss: 5.3262 \n",
      "2022-02-16 05:44:02,486 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 16/17 -- train_loss: 4.7722 \n",
      "2022-02-16 05:44:02,818 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 17/17 -- train_loss: 4.9459 \n",
      "2022-02-16 05:44:02,820 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run resuming from iteration 0, epoch 5 until 6 epochs\n",
      "2022-02-16 05:47:06,061 - ignite.engine.engine.DynUNetEvaluator - INFO - Got new best metric of val_mean_dice: 0.015126219019293785\n",
      "2022-02-16 05:47:06,165 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[6] Metrics -- val_mean_dice: 0.0151 \n",
      "2022-02-16 05:47:06,168 - ignite.engine.engine.DynUNetEvaluator - INFO - Key metric: val_mean_dice best value: 0.015126219019293785 at epoch: 6\n",
      "2022-02-16 05:47:06,681 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[6] Complete. Time taken: 00:03:03\n",
      "2022-02-16 05:47:06,682 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run complete. Time taken: 00:03:04\n",
      "2022-02-16 05:47:07,083 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-16 05:47:07,085 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[6] Complete. Time taken: 00:03:12\n",
      "2022-02-16 05:47:09,475 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 1/17 -- train_loss: 5.2042 \n",
      "2022-02-16 05:47:09,769 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 2/17 -- train_loss: 4.9381 \n",
      "2022-02-16 05:47:10,062 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 3/17 -- train_loss: 5.0529 \n",
      "2022-02-16 05:47:10,400 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 4/17 -- train_loss: 4.9933 \n",
      "2022-02-16 05:47:10,751 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 5/17 -- train_loss: 5.1542 \n",
      "2022-02-16 05:47:11,132 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 6/17 -- train_loss: 5.2652 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 05:47:11,424 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 7/17 -- train_loss: 4.8212 \n",
      "2022-02-16 05:47:11,766 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 8/17 -- train_loss: 5.0833 \n",
      "2022-02-16 05:47:12,115 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 9/17 -- train_loss: 5.2953 \n",
      "2022-02-16 05:47:12,456 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 10/17 -- train_loss: 4.9202 \n",
      "2022-02-16 05:47:12,797 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 11/17 -- train_loss: 5.1325 \n",
      "2022-02-16 05:47:13,138 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 12/17 -- train_loss: 4.9771 \n",
      "2022-02-16 05:47:13,482 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 13/17 -- train_loss: 4.7850 \n",
      "2022-02-16 05:47:13,821 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 14/17 -- train_loss: 5.5079 \n",
      "2022-02-16 05:47:14,163 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 15/17 -- train_loss: 5.4126 \n",
      "2022-02-16 05:47:14,522 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 16/17 -- train_loss: 5.3799 \n",
      "2022-02-16 05:47:14,868 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 17/17 -- train_loss: 5.1323 \n",
      "2022-02-16 05:47:14,869 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-16 05:47:14,870 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[7] Complete. Time taken: 00:00:08\n",
      "2022-02-16 05:47:17,049 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 1/17 -- train_loss: 4.9789 \n",
      "2022-02-16 05:47:17,379 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 2/17 -- train_loss: 5.0882 \n",
      "2022-02-16 05:47:17,727 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 3/17 -- train_loss: 5.3753 \n",
      "2022-02-16 05:47:18,058 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 4/17 -- train_loss: 4.9196 \n",
      "2022-02-16 05:47:18,407 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 5/17 -- train_loss: 4.8331 \n",
      "2022-02-16 05:47:18,835 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 6/17 -- train_loss: 4.9265 \n",
      "2022-02-16 05:47:19,127 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 7/17 -- train_loss: 4.9962 \n",
      "2022-02-16 05:47:19,418 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 8/17 -- train_loss: 4.6388 \n",
      "2022-02-16 05:47:19,757 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 9/17 -- train_loss: 4.9034 \n",
      "2022-02-16 05:47:20,095 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 10/17 -- train_loss: 5.0534 \n",
      "2022-02-16 05:47:20,427 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 11/17 -- train_loss: 5.1586 \n",
      "2022-02-16 05:47:20,776 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 12/17 -- train_loss: 5.0169 \n",
      "2022-02-16 05:47:21,123 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 13/17 -- train_loss: 4.7707 \n",
      "2022-02-16 05:47:21,475 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 14/17 -- train_loss: 4.6761 \n",
      "2022-02-16 05:47:21,813 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 15/17 -- train_loss: 5.0983 \n",
      "2022-02-16 05:47:22,150 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 16/17 -- train_loss: 5.2121 \n",
      "2022-02-16 05:47:22,503 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 17/17 -- train_loss: 4.5617 \n",
      "2022-02-16 05:47:22,505 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run resuming from iteration 0, epoch 7 until 8 epochs\n",
      "2022-02-16 05:50:29,231 - ignite.engine.engine.DynUNetEvaluator - INFO - Got new best metric of val_mean_dice: 0.016296565532684326\n",
      "2022-02-16 05:50:29,251 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[8] Metrics -- val_mean_dice: 0.0163 \n",
      "2022-02-16 05:50:29,253 - ignite.engine.engine.DynUNetEvaluator - INFO - Key metric: val_mean_dice best value: 0.016296565532684326 at epoch: 8\n",
      "2022-02-16 05:50:29,726 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[8] Complete. Time taken: 00:03:06\n",
      "2022-02-16 05:50:29,727 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run complete. Time taken: 00:03:07\n",
      "2022-02-16 05:50:34,059 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-16 05:50:34,061 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[8] Complete. Time taken: 00:03:19\n",
      "2022-02-16 05:50:36,759 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 9/1500, Iter: 1/17 -- train_loss: 4.8343 \n",
      "2022-02-16 05:50:37,052 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 9/1500, Iter: 2/17 -- train_loss: 5.1186 \n",
      "2022-02-16 05:50:37,343 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 9/1500, Iter: 3/17 -- train_loss: 5.1259 \n",
      "2022-02-16 05:50:37,685 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 9/1500, Iter: 4/17 -- train_loss: 4.7107 \n",
      "2022-02-16 05:50:38,108 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 9/1500, Iter: 5/17 -- train_loss: 4.9724 \n",
      "2022-02-16 05:50:38,401 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 9/1500, Iter: 6/17 -- train_loss: 5.0811 \n",
      "2022-02-16 05:50:38,699 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 9/1500, Iter: 7/17 -- train_loss: 4.9855 \n",
      "2022-02-16 05:50:39,046 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 9/1500, Iter: 8/17 -- train_loss: 4.9598 \n",
      "2022-02-16 05:50:39,383 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 9/1500, Iter: 9/17 -- train_loss: 4.4835 \n",
      "2022-02-16 05:50:39,723 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 9/1500, Iter: 10/17 -- train_loss: 4.8906 \n",
      "2022-02-16 05:50:40,059 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 9/1500, Iter: 11/17 -- train_loss: 5.5719 \n",
      "2022-02-16 05:50:40,406 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 9/1500, Iter: 12/17 -- train_loss: 4.9972 \n",
      "2022-02-16 05:50:40,740 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 9/1500, Iter: 13/17 -- train_loss: 5.0326 \n",
      "2022-02-16 05:50:41,083 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 9/1500, Iter: 14/17 -- train_loss: 4.6364 \n",
      "2022-02-16 05:50:41,418 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 9/1500, Iter: 15/17 -- train_loss: 5.1151 \n",
      "2022-02-16 05:50:41,767 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 9/1500, Iter: 16/17 -- train_loss: 4.9137 \n",
      "2022-02-16 05:50:42,101 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 9/1500, Iter: 17/17 -- train_loss: 5.0094 \n",
      "2022-02-16 05:50:42,102 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-16 05:50:42,103 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[9] Complete. Time taken: 00:00:08\n",
      "2022-02-16 05:50:43,916 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 10/1500, Iter: 1/17 -- train_loss: 5.0864 \n",
      "2022-02-16 05:50:44,296 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 10/1500, Iter: 2/17 -- train_loss: 4.8808 \n",
      "2022-02-16 05:50:44,592 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 10/1500, Iter: 3/17 -- train_loss: 4.9424 \n",
      "2022-02-16 05:50:45,065 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 10/1500, Iter: 4/17 -- train_loss: 4.7399 \n",
      "2022-02-16 05:50:45,360 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 10/1500, Iter: 5/17 -- train_loss: 5.0984 \n",
      "2022-02-16 05:50:45,654 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 10/1500, Iter: 6/17 -- train_loss: 4.7686 \n",
      "2022-02-16 05:50:45,948 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 10/1500, Iter: 7/17 -- train_loss: 5.1336 \n",
      "2022-02-16 05:50:46,305 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 10/1500, Iter: 8/17 -- train_loss: 5.1485 \n",
      "2022-02-16 05:50:46,641 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 10/1500, Iter: 9/17 -- train_loss: 4.5619 \n",
      "2022-02-16 05:50:46,976 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 10/1500, Iter: 10/17 -- train_loss: 5.0063 \n",
      "2022-02-16 05:50:47,312 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 10/1500, Iter: 11/17 -- train_loss: 5.1094 \n",
      "2022-02-16 05:50:47,661 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 10/1500, Iter: 12/17 -- train_loss: 4.9108 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 05:50:48,020 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 10/1500, Iter: 13/17 -- train_loss: 4.5861 \n",
      "2022-02-16 05:50:48,357 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 10/1500, Iter: 14/17 -- train_loss: 5.0723 \n",
      "2022-02-16 05:50:48,693 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 10/1500, Iter: 15/17 -- train_loss: 4.7356 \n",
      "2022-02-16 05:50:49,044 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 10/1500, Iter: 16/17 -- train_loss: 4.1773 \n",
      "2022-02-16 05:50:49,399 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 10/1500, Iter: 17/17 -- train_loss: 4.4306 \n",
      "2022-02-16 05:50:49,400 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run resuming from iteration 0, epoch 9 until 10 epochs\n",
      "2022-02-16 05:54:03,311 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[10] Metrics -- val_mean_dice: 0.0135 \n",
      "2022-02-16 05:54:03,324 - ignite.engine.engine.DynUNetEvaluator - INFO - Key metric: val_mean_dice best value: 0.016296565532684326 at epoch: 8\n",
      "2022-02-16 05:54:03,325 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[10] Complete. Time taken: 00:03:13\n",
      "2022-02-16 05:54:03,326 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run complete. Time taken: 00:03:14\n",
      "2022-02-16 05:54:03,713 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-16 05:54:03,716 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[10] Complete. Time taken: 00:03:22\n",
      "2022-02-16 05:54:06,438 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 11/1500, Iter: 1/17 -- train_loss: 5.1243 \n",
      "2022-02-16 05:54:06,730 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 11/1500, Iter: 2/17 -- train_loss: 5.0668 \n",
      "2022-02-16 05:54:07,081 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 11/1500, Iter: 3/17 -- train_loss: 5.0779 \n",
      "2022-02-16 05:54:07,513 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 11/1500, Iter: 4/17 -- train_loss: 4.5678 \n",
      "2022-02-16 05:54:07,849 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 11/1500, Iter: 5/17 -- train_loss: 4.8895 \n",
      "2022-02-16 05:54:08,141 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 11/1500, Iter: 6/17 -- train_loss: 4.8446 \n",
      "2022-02-16 05:54:08,475 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 11/1500, Iter: 7/17 -- train_loss: 4.6814 \n",
      "2022-02-16 05:54:08,811 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 11/1500, Iter: 8/17 -- train_loss: 4.6612 \n",
      "2022-02-16 05:54:09,157 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 11/1500, Iter: 9/17 -- train_loss: 5.1375 \n",
      "2022-02-16 05:54:09,498 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 11/1500, Iter: 10/17 -- train_loss: 4.6682 \n",
      "2022-02-16 05:54:09,837 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 11/1500, Iter: 11/17 -- train_loss: 5.1083 \n",
      "2022-02-16 05:54:10,191 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 11/1500, Iter: 12/17 -- train_loss: 4.7167 \n",
      "2022-02-16 05:54:10,555 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 11/1500, Iter: 13/17 -- train_loss: 4.7474 \n",
      "2022-02-16 05:54:10,903 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 11/1500, Iter: 14/17 -- train_loss: 4.5300 \n",
      "2022-02-16 05:54:11,257 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 11/1500, Iter: 15/17 -- train_loss: 4.8324 \n",
      "2022-02-16 05:54:11,621 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 11/1500, Iter: 16/17 -- train_loss: 4.4709 \n",
      "2022-02-16 05:54:11,971 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 11/1500, Iter: 17/17 -- train_loss: 4.4259 \n",
      "2022-02-16 05:54:11,972 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-16 05:54:11,973 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[11] Complete. Time taken: 00:00:08\n",
      "2022-02-16 05:54:14,391 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 12/1500, Iter: 1/17 -- train_loss: 4.8311 \n",
      "2022-02-16 05:54:14,685 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 12/1500, Iter: 2/17 -- train_loss: 4.3878 \n",
      "2022-02-16 05:54:14,978 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 12/1500, Iter: 3/17 -- train_loss: 4.4174 \n",
      "2022-02-16 05:54:15,361 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 12/1500, Iter: 4/17 -- train_loss: 4.4811 \n",
      "2022-02-16 05:54:15,737 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 12/1500, Iter: 5/17 -- train_loss: 4.4149 \n",
      "2022-02-16 05:54:16,032 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 12/1500, Iter: 6/17 -- train_loss: 4.6014 \n",
      "2022-02-16 05:54:16,328 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 12/1500, Iter: 7/17 -- train_loss: 4.7189 \n",
      "2022-02-16 05:54:16,670 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 12/1500, Iter: 8/17 -- train_loss: 4.7151 \n",
      "2022-02-16 05:54:17,007 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 12/1500, Iter: 9/17 -- train_loss: 4.5943 \n",
      "2022-02-16 05:54:17,357 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 12/1500, Iter: 10/17 -- train_loss: 4.8188 \n",
      "2022-02-16 05:54:17,707 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 12/1500, Iter: 11/17 -- train_loss: 4.7598 \n",
      "2022-02-16 05:54:18,047 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 12/1500, Iter: 12/17 -- train_loss: 5.0162 \n",
      "2022-02-16 05:54:18,398 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 12/1500, Iter: 13/17 -- train_loss: 4.9428 \n",
      "2022-02-16 05:54:18,733 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 12/1500, Iter: 14/17 -- train_loss: 4.3114 \n",
      "2022-02-16 05:54:19,083 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 12/1500, Iter: 15/17 -- train_loss: 4.3869 \n",
      "2022-02-16 05:54:19,426 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 12/1500, Iter: 16/17 -- train_loss: 4.4334 \n",
      "2022-02-16 05:54:19,778 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 12/1500, Iter: 17/17 -- train_loss: 5.2322 \n",
      "2022-02-16 05:54:19,780 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run resuming from iteration 0, epoch 11 until 12 epochs\n",
      "2022-02-16 05:57:30,547 - ignite.engine.engine.DynUNetEvaluator - INFO - Got new best metric of val_mean_dice: 0.020269041880965233\n",
      "2022-02-16 05:57:30,580 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[12] Metrics -- val_mean_dice: 0.0203 \n",
      "2022-02-16 05:57:30,582 - ignite.engine.engine.DynUNetEvaluator - INFO - Key metric: val_mean_dice best value: 0.020269041880965233 at epoch: 12\n",
      "2022-02-16 05:57:31,037 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[12] Complete. Time taken: 00:03:10\n",
      "2022-02-16 05:57:31,039 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run complete. Time taken: 00:03:11\n",
      "2022-02-16 05:57:31,491 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-16 05:57:31,493 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[12] Complete. Time taken: 00:03:20\n",
      "2022-02-16 05:57:34,268 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 13/1500, Iter: 1/17 -- train_loss: 4.4483 \n",
      "2022-02-16 05:57:34,698 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 13/1500, Iter: 2/17 -- train_loss: 4.8973 \n",
      "2022-02-16 05:57:34,991 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 13/1500, Iter: 3/17 -- train_loss: 4.5862 \n",
      "2022-02-16 05:57:35,327 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 13/1500, Iter: 4/17 -- train_loss: 4.2660 \n",
      "2022-02-16 05:57:35,709 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 13/1500, Iter: 5/17 -- train_loss: 4.8455 \n",
      "2022-02-16 05:57:36,116 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 13/1500, Iter: 6/17 -- train_loss: 4.6807 \n",
      "2022-02-16 05:57:36,410 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 13/1500, Iter: 7/17 -- train_loss: 4.9586 \n",
      "2022-02-16 05:57:36,704 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 13/1500, Iter: 8/17 -- train_loss: 4.5697 \n",
      "2022-02-16 05:57:37,041 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 13/1500, Iter: 9/17 -- train_loss: 4.6696 \n",
      "2022-02-16 05:57:37,393 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 13/1500, Iter: 10/17 -- train_loss: 4.7991 \n",
      "2022-02-16 05:57:37,742 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 13/1500, Iter: 11/17 -- train_loss: 4.7260 \n",
      "2022-02-16 05:57:38,092 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 13/1500, Iter: 12/17 -- train_loss: 4.6330 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 05:57:38,435 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 13/1500, Iter: 13/17 -- train_loss: 4.3633 \n",
      "2022-02-16 05:57:38,779 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 13/1500, Iter: 14/17 -- train_loss: 4.2389 \n",
      "2022-02-16 05:57:39,122 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 13/1500, Iter: 15/17 -- train_loss: 4.4075 \n",
      "2022-02-16 05:57:39,467 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 13/1500, Iter: 16/17 -- train_loss: 4.3400 \n",
      "2022-02-16 05:57:39,807 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 13/1500, Iter: 17/17 -- train_loss: 4.6156 \n",
      "2022-02-16 05:57:39,808 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-16 05:57:39,809 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[13] Complete. Time taken: 00:00:08\n",
      "2022-02-16 05:57:41,732 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 14/1500, Iter: 1/17 -- train_loss: 4.3844 \n",
      "2022-02-16 05:57:42,100 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 14/1500, Iter: 2/17 -- train_loss: 4.1975 \n",
      "2022-02-16 05:57:42,396 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 14/1500, Iter: 3/17 -- train_loss: 4.3583 \n",
      "2022-02-16 05:57:42,775 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 14/1500, Iter: 4/17 -- train_loss: 4.5232 \n",
      "2022-02-16 05:57:43,069 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 14/1500, Iter: 5/17 -- train_loss: 4.4565 \n",
      "2022-02-16 05:57:43,406 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 14/1500, Iter: 6/17 -- train_loss: 4.4038 \n",
      "2022-02-16 05:57:43,747 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 14/1500, Iter: 7/17 -- train_loss: 4.5335 \n",
      "2022-02-16 05:57:44,136 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 14/1500, Iter: 8/17 -- train_loss: 4.3905 \n",
      "2022-02-16 05:57:44,438 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 14/1500, Iter: 9/17 -- train_loss: 4.1956 \n",
      "2022-02-16 05:57:44,777 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 14/1500, Iter: 10/17 -- train_loss: 4.4315 \n",
      "2022-02-16 05:57:45,129 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 14/1500, Iter: 11/17 -- train_loss: 4.4114 \n",
      "2022-02-16 05:57:45,468 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 14/1500, Iter: 12/17 -- train_loss: 4.7748 \n",
      "2022-02-16 05:57:45,802 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 14/1500, Iter: 13/17 -- train_loss: 4.6910 \n",
      "2022-02-16 05:57:46,238 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 14/1500, Iter: 14/17 -- train_loss: 4.3106 \n",
      "2022-02-16 05:57:46,584 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 14/1500, Iter: 15/17 -- train_loss: 4.5382 \n",
      "2022-02-16 05:57:46,936 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 14/1500, Iter: 16/17 -- train_loss: 5.1777 \n",
      "2022-02-16 05:57:47,285 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 14/1500, Iter: 17/17 -- train_loss: 4.5428 \n",
      "2022-02-16 05:57:47,287 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run resuming from iteration 0, epoch 13 until 14 epochs\n",
      "2022-02-16 06:01:00,580 - ignite.engine.engine.DynUNetEvaluator - INFO - Got new best metric of val_mean_dice: 0.021014172583818436\n",
      "2022-02-16 06:01:00,649 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[14] Metrics -- val_mean_dice: 0.0210 \n",
      "2022-02-16 06:01:00,650 - ignite.engine.engine.DynUNetEvaluator - INFO - Key metric: val_mean_dice best value: 0.021014172583818436 at epoch: 14\n",
      "2022-02-16 06:01:01,414 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[14] Complete. Time taken: 00:03:13\n",
      "2022-02-16 06:01:01,415 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run complete. Time taken: 00:03:14\n",
      "2022-02-16 06:01:02,010 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-16 06:01:02,012 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[14] Complete. Time taken: 00:03:22\n",
      "2022-02-16 06:01:05,306 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 15/1500, Iter: 1/17 -- train_loss: 4.4283 \n",
      "2022-02-16 06:01:05,644 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 15/1500, Iter: 2/17 -- train_loss: 4.4543 \n",
      "2022-02-16 06:01:05,935 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 15/1500, Iter: 3/17 -- train_loss: 4.5923 \n",
      "2022-02-16 06:01:06,301 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 15/1500, Iter: 4/17 -- train_loss: 4.3223 \n",
      "2022-02-16 06:01:06,721 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 15/1500, Iter: 5/17 -- train_loss: 4.5815 \n",
      "2022-02-16 06:01:07,058 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 15/1500, Iter: 6/17 -- train_loss: 4.7834 \n",
      "2022-02-16 06:01:07,350 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 15/1500, Iter: 7/17 -- train_loss: 4.8018 \n",
      "2022-02-16 06:01:07,712 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 15/1500, Iter: 8/17 -- train_loss: 4.4441 \n",
      "2022-02-16 06:01:08,052 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 15/1500, Iter: 9/17 -- train_loss: 4.4642 \n",
      "2022-02-16 06:01:08,401 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 15/1500, Iter: 10/17 -- train_loss: 4.4346 \n",
      "2022-02-16 06:01:08,747 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 15/1500, Iter: 11/17 -- train_loss: 3.7900 \n",
      "2022-02-16 06:01:09,087 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 15/1500, Iter: 12/17 -- train_loss: 4.2575 \n",
      "2022-02-16 06:01:09,427 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 15/1500, Iter: 13/17 -- train_loss: 4.0364 \n",
      "2022-02-16 06:01:09,768 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 15/1500, Iter: 14/17 -- train_loss: 4.3915 \n",
      "2022-02-16 06:01:10,112 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 15/1500, Iter: 15/17 -- train_loss: 4.7054 \n",
      "2022-02-16 06:01:10,453 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 15/1500, Iter: 16/17 -- train_loss: 4.2811 \n",
      "2022-02-16 06:01:10,786 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 15/1500, Iter: 17/17 -- train_loss: 4.4123 \n",
      "2022-02-16 06:01:10,790 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-16 06:01:10,790 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[15] Complete. Time taken: 00:00:09\n",
      "2022-02-16 06:01:18,322 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 16/1500, Iter: 1/17 -- train_loss: 4.2469 \n",
      "2022-02-16 06:01:18,703 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 16/1500, Iter: 2/17 -- train_loss: 4.3110 \n",
      "2022-02-16 06:01:18,995 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 16/1500, Iter: 3/17 -- train_loss: 4.1775 \n",
      "2022-02-16 06:01:19,334 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 16/1500, Iter: 4/17 -- train_loss: 4.5934 \n",
      "2022-02-16 06:01:19,667 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 16/1500, Iter: 5/17 -- train_loss: 4.1316 \n",
      "2022-02-16 06:01:20,086 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 16/1500, Iter: 6/17 -- train_loss: 4.2408 \n",
      "2022-02-16 06:01:20,376 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 16/1500, Iter: 7/17 -- train_loss: 4.4840 \n",
      "2022-02-16 06:01:20,666 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 16/1500, Iter: 8/17 -- train_loss: 4.2033 \n",
      "2022-02-16 06:01:21,000 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 16/1500, Iter: 9/17 -- train_loss: 4.5282 \n",
      "2022-02-16 06:01:21,335 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 16/1500, Iter: 10/17 -- train_loss: 4.5092 \n",
      "2022-02-16 06:01:21,676 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 16/1500, Iter: 11/17 -- train_loss: 4.3168 \n",
      "2022-02-16 06:01:22,026 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 16/1500, Iter: 12/17 -- train_loss: 4.0406 \n",
      "2022-02-16 06:01:22,355 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 16/1500, Iter: 13/17 -- train_loss: 4.3049 \n",
      "2022-02-16 06:01:22,689 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 16/1500, Iter: 14/17 -- train_loss: 4.3570 \n",
      "2022-02-16 06:01:23,038 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 16/1500, Iter: 15/17 -- train_loss: 4.2307 \n",
      "2022-02-16 06:01:23,385 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 16/1500, Iter: 16/17 -- train_loss: 4.5287 \n",
      "2022-02-16 06:01:23,721 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 16/1500, Iter: 17/17 -- train_loss: 4.6259 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 06:01:23,723 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run resuming from iteration 0, epoch 15 until 16 epochs\n",
      "2022-02-16 06:04:22,493 - ignite.engine.engine.DynUNetEvaluator - INFO - Got new best metric of val_mean_dice: 0.02229660376906395\n",
      "2022-02-16 06:04:22,613 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[16] Metrics -- val_mean_dice: 0.0223 \n",
      "2022-02-16 06:04:22,618 - ignite.engine.engine.DynUNetEvaluator - INFO - Key metric: val_mean_dice best value: 0.02229660376906395 at epoch: 16\n",
      "2022-02-16 06:04:22,959 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[16] Complete. Time taken: 00:02:58\n",
      "2022-02-16 06:04:22,960 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run complete. Time taken: 00:02:59\n",
      "2022-02-16 06:04:23,378 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-16 06:04:23,380 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[16] Complete. Time taken: 00:03:13\n",
      "2022-02-16 06:04:25,764 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 17/1500, Iter: 1/17 -- train_loss: 4.3573 \n",
      "2022-02-16 06:04:26,060 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 17/1500, Iter: 2/17 -- train_loss: 4.4031 \n",
      "2022-02-16 06:04:26,352 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 17/1500, Iter: 3/17 -- train_loss: 4.2041 \n",
      "2022-02-16 06:04:26,730 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 17/1500, Iter: 4/17 -- train_loss: 3.9362 \n",
      "2022-02-16 06:04:27,110 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 17/1500, Iter: 5/17 -- train_loss: 4.0251 \n",
      "2022-02-16 06:04:27,405 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 17/1500, Iter: 6/17 -- train_loss: 4.4296 \n",
      "2022-02-16 06:04:27,698 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 17/1500, Iter: 7/17 -- train_loss: 4.1512 \n",
      "2022-02-16 06:04:28,036 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 17/1500, Iter: 8/17 -- train_loss: 4.3553 \n",
      "2022-02-16 06:04:28,373 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 17/1500, Iter: 9/17 -- train_loss: 4.2268 \n",
      "2022-02-16 06:04:28,708 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 17/1500, Iter: 10/17 -- train_loss: 4.2863 \n",
      "2022-02-16 06:04:29,050 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 17/1500, Iter: 11/17 -- train_loss: 4.2505 \n",
      "2022-02-16 06:04:29,388 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 17/1500, Iter: 12/17 -- train_loss: 4.2751 \n",
      "2022-02-16 06:04:29,726 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 17/1500, Iter: 13/17 -- train_loss: 4.4139 \n",
      "2022-02-16 06:04:30,068 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 17/1500, Iter: 14/17 -- train_loss: 4.3673 \n",
      "2022-02-16 06:04:30,408 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 17/1500, Iter: 15/17 -- train_loss: 4.4793 \n",
      "2022-02-16 06:04:30,747 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 17/1500, Iter: 16/17 -- train_loss: 4.1209 \n",
      "2022-02-16 06:04:31,081 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 17/1500, Iter: 17/17 -- train_loss: 4.1496 \n",
      "2022-02-16 06:04:31,082 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-16 06:04:31,083 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[17] Complete. Time taken: 00:00:08\n",
      "2022-02-16 06:04:33,035 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 18/1500, Iter: 1/17 -- train_loss: 4.1619 \n",
      "2022-02-16 06:04:33,417 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 18/1500, Iter: 2/17 -- train_loss: 4.1769 \n",
      "2022-02-16 06:04:33,711 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 18/1500, Iter: 3/17 -- train_loss: 4.1738 \n",
      "2022-02-16 06:04:34,089 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 18/1500, Iter: 4/17 -- train_loss: 4.3778 \n",
      "2022-02-16 06:04:34,383 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 18/1500, Iter: 5/17 -- train_loss: 4.1714 \n",
      "2022-02-16 06:04:34,813 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 18/1500, Iter: 6/17 -- train_loss: 4.1844 \n",
      "2022-02-16 06:04:35,107 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 18/1500, Iter: 7/17 -- train_loss: 4.2564 \n",
      "2022-02-16 06:04:35,403 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 18/1500, Iter: 8/17 -- train_loss: 4.3180 \n",
      "2022-02-16 06:04:35,743 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 18/1500, Iter: 9/17 -- train_loss: 4.3112 \n",
      "2022-02-16 06:04:36,084 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 18/1500, Iter: 10/17 -- train_loss: 4.3864 \n",
      "2022-02-16 06:04:36,417 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 18/1500, Iter: 11/17 -- train_loss: 4.1733 \n",
      "2022-02-16 06:04:36,759 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 18/1500, Iter: 12/17 -- train_loss: 4.2341 \n",
      "2022-02-16 06:04:37,109 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 18/1500, Iter: 13/17 -- train_loss: 4.0403 \n",
      "2022-02-16 06:04:37,443 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 18/1500, Iter: 14/17 -- train_loss: 3.8233 \n",
      "2022-02-16 06:04:37,789 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 18/1500, Iter: 15/17 -- train_loss: 4.2965 \n",
      "2022-02-16 06:04:38,129 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 18/1500, Iter: 16/17 -- train_loss: 4.5119 \n",
      "2022-02-16 06:04:38,467 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 18/1500, Iter: 17/17 -- train_loss: 4.1373 \n",
      "2022-02-16 06:04:38,468 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run resuming from iteration 0, epoch 17 until 18 epochs\n",
      "2022-02-16 06:07:52,065 - ignite.engine.engine.DynUNetEvaluator - INFO - Got new best metric of val_mean_dice: 0.023228636011481285\n",
      "2022-02-16 06:07:52,167 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[18] Metrics -- val_mean_dice: 0.0232 \n",
      "2022-02-16 06:07:52,174 - ignite.engine.engine.DynUNetEvaluator - INFO - Key metric: val_mean_dice best value: 0.023228636011481285 at epoch: 18\n",
      "2022-02-16 06:07:52,609 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[18] Complete. Time taken: 00:03:13\n",
      "2022-02-16 06:07:52,610 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run complete. Time taken: 00:03:14\n",
      "2022-02-16 06:07:53,039 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-16 06:07:53,040 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[18] Complete. Time taken: 00:03:22\n",
      "2022-02-16 06:07:56,266 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 19/1500, Iter: 1/17 -- train_loss: 4.0539 \n",
      "2022-02-16 06:07:56,602 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 19/1500, Iter: 2/17 -- train_loss: 4.3846 \n",
      "2022-02-16 06:07:56,990 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 19/1500, Iter: 3/17 -- train_loss: 4.0712 \n",
      "2022-02-16 06:07:57,341 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 19/1500, Iter: 4/17 -- train_loss: 3.9643 \n",
      "2022-02-16 06:07:57,740 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 19/1500, Iter: 5/17 -- train_loss: 3.9784 \n",
      "2022-02-16 06:07:58,078 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 19/1500, Iter: 6/17 -- train_loss: 4.2720 \n",
      "2022-02-16 06:07:58,425 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 19/1500, Iter: 7/17 -- train_loss: 4.1475 \n",
      "2022-02-16 06:07:58,723 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 19/1500, Iter: 8/17 -- train_loss: 4.6261 \n",
      "2022-02-16 06:07:59,067 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 19/1500, Iter: 9/17 -- train_loss: 3.9405 \n",
      "2022-02-16 06:07:59,404 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 19/1500, Iter: 10/17 -- train_loss: 4.1781 \n",
      "2022-02-16 06:07:59,750 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 19/1500, Iter: 11/17 -- train_loss: 4.1300 \n",
      "2022-02-16 06:08:00,089 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 19/1500, Iter: 12/17 -- train_loss: 4.3808 \n",
      "2022-02-16 06:08:00,428 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 19/1500, Iter: 13/17 -- train_loss: 4.4237 \n",
      "2022-02-16 06:08:00,766 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 19/1500, Iter: 14/17 -- train_loss: 4.0985 \n",
      "2022-02-16 06:08:01,100 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 19/1500, Iter: 15/17 -- train_loss: 3.9503 \n",
      "2022-02-16 06:08:01,447 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 19/1500, Iter: 16/17 -- train_loss: 4.1109 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 06:08:01,790 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 19/1500, Iter: 17/17 -- train_loss: 3.9278 \n",
      "2022-02-16 06:08:01,792 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-16 06:08:01,793 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[19] Complete. Time taken: 00:00:09\n",
      "2022-02-16 06:08:04,057 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 20/1500, Iter: 1/17 -- train_loss: 3.8868 \n",
      "2022-02-16 06:08:04,353 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 20/1500, Iter: 2/17 -- train_loss: 4.1255 \n",
      "2022-02-16 06:08:04,688 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 20/1500, Iter: 3/17 -- train_loss: 3.8831 \n",
      "2022-02-16 06:08:05,069 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 20/1500, Iter: 4/17 -- train_loss: 4.0888 \n",
      "2022-02-16 06:08:05,404 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 20/1500, Iter: 5/17 -- train_loss: 4.0090 \n",
      "2022-02-16 06:08:05,696 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 20/1500, Iter: 6/17 -- train_loss: 4.0399 \n",
      "2022-02-16 06:08:06,032 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 20/1500, Iter: 7/17 -- train_loss: 3.8368 \n",
      "2022-02-16 06:08:06,369 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 20/1500, Iter: 8/17 -- train_loss: 4.3616 \n",
      "2022-02-16 06:08:06,714 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 20/1500, Iter: 9/17 -- train_loss: 4.2610 \n",
      "2022-02-16 06:08:07,065 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 20/1500, Iter: 10/17 -- train_loss: 3.9250 \n",
      "2022-02-16 06:08:07,402 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 20/1500, Iter: 11/17 -- train_loss: 3.9772 \n",
      "2022-02-16 06:08:07,739 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 20/1500, Iter: 12/17 -- train_loss: 3.6515 \n",
      "2022-02-16 06:08:08,081 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 20/1500, Iter: 13/17 -- train_loss: 4.0294 \n",
      "2022-02-16 06:08:08,444 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 20/1500, Iter: 14/17 -- train_loss: 3.8265 \n",
      "2022-02-16 06:08:08,779 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 20/1500, Iter: 15/17 -- train_loss: 3.8449 \n",
      "2022-02-16 06:08:09,119 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 20/1500, Iter: 16/17 -- train_loss: 3.9803 \n",
      "2022-02-16 06:08:09,461 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 20/1500, Iter: 17/17 -- train_loss: 4.0023 \n",
      "2022-02-16 06:08:09,462 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run resuming from iteration 0, epoch 19 until 20 epochs\n",
      "2022-02-16 06:11:16,667 - ignite.engine.engine.DynUNetEvaluator - ERROR - Engine run is terminating due to exception: \n",
      "2022-02-16 06:11:16,670 - ignite.engine.engine.DynUNetEvaluator - ERROR - Exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 744, in _internal_run\n",
      "    time_taken = self._run_once_on_dataset()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 835, in _run_once_on_dataset\n",
      "    self._fire_event(Events.ITERATION_COMPLETED)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 424, in _fire_event\n",
      "    func(*first, *(event_args + others), **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/metrics/metric.py\", line 320, in iteration_completed\n",
      "    self.update((tensor_o1, tensor_o2))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/metrics/metric.py\", line 608, in wrapper\n",
      "    func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/handlers/ignite_metric.py\", line 82, in update\n",
      "    self.metric_fn(y_pred, y)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/metrics/metric.py\", line 328, in __call__\n",
      "    ret = super().__call__(y_pred=y_pred, y=y)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/metrics/metric.py\", line 72, in __call__\n",
      "    return self._compute_tensor(y_pred.detach(), y_)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/metrics/meandice.py\", line 74, in _compute_tensor\n",
      "    if not torch.all(y.byte() == y):\n",
      "KeyboardInterrupt\n",
      "2022-02-16 06:11:16,690 - ignite.engine.engine.DynUNetTrainer - ERROR - Engine run is terminating due to exception: \n",
      "2022-02-16 06:11:16,691 - ignite.engine.engine.DynUNetTrainer - ERROR - Exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 751, in _internal_run\n",
      "    self._fire_event(Events.EPOCH_COMPLETED)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 424, in _fire_event\n",
      "    func(*first, *(event_args + others), **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 237, in wrapper\n",
      "    return handler(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/handlers/validation_handler.py\", line 76, in __call__\n",
      "    self.validator.run(engine.state.epoch)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/engines/evaluator.py\", line 137, in run\n",
      "    super().run()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/engines/workflow.py\", line 275, in run\n",
      "    super().run(data=self.data_loader, max_epochs=self.state.max_epochs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 701, in run\n",
      "    return self._internal_run()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 774, in _internal_run\n",
      "    self._handle_exception(e)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 467, in _handle_exception\n",
      "    self._fire_event(Events.EXCEPTION_RAISED, e)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 424, in _fire_event\n",
      "    func(*first, *(event_args + others), **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/handlers/stats_handler.py\", line 158, in exception_raised\n",
      "    raise e\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 744, in _internal_run\n",
      "    time_taken = self._run_once_on_dataset()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 835, in _run_once_on_dataset\n",
      "    self._fire_event(Events.ITERATION_COMPLETED)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 424, in _fire_event\n",
      "    func(*first, *(event_args + others), **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/metrics/metric.py\", line 320, in iteration_completed\n",
      "    self.update((tensor_o1, tensor_o2))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/metrics/metric.py\", line 608, in wrapper\n",
      "    func(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/handlers/ignite_metric.py\", line 82, in update\n",
      "    self.metric_fn(y_pred, y)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/metrics/metric.py\", line 328, in __call__\n",
      "    ret = super().__call__(y_pred=y_pred, y=y)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/metrics/metric.py\", line 72, in __call__\n",
      "    return self._compute_tensor(y_pred.detach(), y_)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/metrics/meandice.py\", line 74, in _compute_tensor\n",
      "    if not torch.all(y.byte() == y):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28118/3254222111.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/engines/trainer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \"\"\"\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_train_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/engines/workflow.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \"\"\"\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_handlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_fire_event\u001b[0;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mothers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/handlers/stats_handler.py\u001b[0m in \u001b[0;36mexception_raised\u001b[0;34m(self, _engine, e)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \"\"\"\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_default_epoch_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    749\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTERMINATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mhandlers_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0;31m# update time wrt handlers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_fire_event\u001b[0;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mothers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_attrib_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# setup input handler as parent to make has_event_handler work\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/handlers/validation_handler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"please set validator in __init__() or call `set_validator()` before training.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/engines/evaluator.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, global_epoch)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_epoch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_validation_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/engines/workflow.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \"\"\"\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_handlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_fire_event\u001b[0;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mothers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/handlers/stats_handler.py\u001b[0m in \u001b[0;36mexception_raised\u001b[0;34m(self, _engine, e)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \"\"\"\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_default_epoch_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate_single_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_fire_event\u001b[0;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mothers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/metrics/metric.py\u001b[0m in \u001b[0;36miteration_completed\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0mtensor_o1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_batched_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                 \u001b[0mtensor_o2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_batched_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_o1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_o1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_o2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/metrics/metric.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/handlers/ignite_metric.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/metrics/metric.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_pred, y)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcomputed\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0miteration\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \"\"\"\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/metrics/metric.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_pred, y)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y_pred or y must be a list/tuple of `channel-first` Tensors or a `batch-first` Tensor.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/metrics/meandice.py\u001b[0m in \u001b[0;36m_compute_tensor\u001b[0;34m(self, y_pred, y)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y_pred should be a binarized tensor.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y should be a binarized tensor.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# produce the network\n",
    "val_output_dir = \"./runs_fold{}_{}/\".format(1, expr_name)\n",
    "checkpoint = checkpoint\n",
    "net = get_network_ke(properties, patch_size, spacing, deep_supr_num, \n",
    "                     val_output_dir, checkpoint)\n",
    "net = net.to(device)\n",
    "print(net)\n",
    "\n",
    "if multi_gpu_flag:\n",
    "    net = DistributedDataParallel(module=net, device_ids=[device])\n",
    "# net = DistributedDataParallel(module=net, device_ids=[device])\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    net.parameters(),\n",
    "    lr=learning_rate,\n",
    "    momentum=0.99,\n",
    "    weight_decay=3e-5,\n",
    "    nesterov=True,\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer, lr_lambda=lambda epoch: (1 - epoch / max_epochs) ** 0.9\n",
    ")\n",
    "# produce evaluator\n",
    "val_handlers = [\n",
    "    StatsHandler(output_transform=lambda x: None),\n",
    "    CheckpointSaver(\n",
    "        save_dir=val_output_dir, save_dict={\"net\": net}, save_key_metric=True\n",
    "    ),\n",
    "]\n",
    "\n",
    "evaluator = DynUNetEvaluator(\n",
    "    device=device,\n",
    "    val_data_loader=val_loader,\n",
    "    network=net,\n",
    "    num_classes=len(properties[\"labels\"]),\n",
    "    inferer=SlidingWindowInferer(\n",
    "        roi_size=patch_size,\n",
    "        sw_batch_size=sw_batch_size,\n",
    "        overlap=eval_overlap,\n",
    "        mode=window_mode,\n",
    "    ),\n",
    "    postprocessing=None,\n",
    "    key_val_metric={\n",
    "        \"val_mean_dice\": MeanDice(\n",
    "            include_background=False,\n",
    "            output_transform=from_engine([\"pred\", \"label\"]),\n",
    "        )\n",
    "    },\n",
    "    val_handlers=val_handlers,\n",
    "    amp=amp_flag,\n",
    "    tta_val=tta_val,\n",
    ")\n",
    "\n",
    "# produce trainer\n",
    "loss = DiceCELoss(to_onehot_y=True, softmax=True, batch=batch_dice)\n",
    "train_handlers = []\n",
    "if lr_decay_flag:\n",
    "    train_handlers += [LrScheduleHandler(lr_scheduler=scheduler, print_lr=True)]\n",
    "\n",
    "train_handlers += [\n",
    "    ValidationHandler(validator=evaluator, interval=interval, epoch_level=True),\n",
    "    StatsHandler(\n",
    "#         tag_name=\"train_loss\", output_transform=from_engine([\"loss\"], first=True)\n",
    "        tag_name=\"train_loss\", output_transform=lambda x: x[\"loss\"]\n",
    "    ),\n",
    "]\n",
    "\n",
    "trainer = DynUNetTrainer(\n",
    "    device=device,\n",
    "    max_epochs=max_epochs,\n",
    "    train_data_loader=train_loader,\n",
    "    network=net,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss,\n",
    "    inferer=SimpleInferer(),\n",
    "    postprocessing=None,\n",
    "    key_train_metric=None,\n",
    "    train_handlers=train_handlers,\n",
    "    amp=amp_flag,\n",
    ")\n",
    "\n",
    "if local_rank > 0:\n",
    "    evaluator.logger.setLevel(logging.WARNING)\n",
    "    trainer.logger.setLevel(logging.WARNING)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "formatter = logging.Formatter(\n",
    "    \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Setup file handler\n",
    "fhandler = logging.FileHandler(log_file)\n",
    "fhandler.setLevel(logging.INFO)\n",
    "fhandler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(fhandler)\n",
    "\n",
    "chandler = logging.StreamHandler()\n",
    "chandler.setLevel(logging.INFO)\n",
    "chandler.setFormatter(formatter)\n",
    "logger.addHandler(chandler)\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53973f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['image', 'label', 'image_meta_dict', 'label_meta_dict', 'image_transforms', 'label_transforms', 'resample_flag', 'anisotrophy_flag'])\n",
      "image, label shape\n",
      "torch.Size([12, 1, 64, 64, 64])\n",
      "torch.Size([12, 1, 64, 64, 64])\n",
      "torch.float32\n",
      "torch.uint8\n",
      "[  0   1   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  20  21  23  25  26  27  28  29  30  31  32  33  34  36  37  39  40  41\n",
      "  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59\n",
      "  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77\n",
      "  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 107 108]\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "test_data = first(train_loader)\n",
    "print(test_data.keys())\n",
    "print('image, label shape')\n",
    "print(test_data['image'].shape)\n",
    "print(test_data['label'].shape)\n",
    "print(test_data['image'].dtype)\n",
    "print(test_data['label'].dtype)\n",
    "print(np.unique(test_data['label']))\n",
    "print(len(np.unique(test_data['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7ed7ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3145728, 21233664)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['label'].numel(), 24*96*96*96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc3f2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d098d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 1, 64, 64, 64]) torch.Size([12, 1, 64, 64, 64])\n",
      "image shape: torch.Size([64, 64, 64]), label shape: torch.Size([64, 64, 64])\n",
      "image dtype: torch.float32, label dtype: torch.uint8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  4  5  6 11 12 13 14 15 18 21 25 26 27 34 45 49 50 52 54 56 59 73\n",
      " 76 88]\n"
     ]
    }
   ],
   "source": [
    "H=60\n",
    "\n",
    "test_data = first(train_loader)\n",
    "image, label = (test_data[\"image\"][0][0], test_data[\"label\"][0][0])\n",
    "print(test_data['image'].shape, test_data['label'].shape)\n",
    "print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
    "print(f\"image dtype: {image.dtype}, label dtype: {label.dtype}\")\n",
    "# plot the slice [:, :, 80]\n",
    "plt.figure(\"check\", (15, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"image\")\n",
    "plt.imshow(image[:, :, H], cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"label\")\n",
    "plt.imshow(label[:, :, H])\n",
    "# plt.subplot(1, 4, 3)\n",
    "# plt.title(\"brain\")\n",
    "# plt.imshow(brain[:, :, H], cmap=\"gray\")\n",
    "# plt.subplot(1, 4, 4)\n",
    "# plt.title(\"mask\")\n",
    "# plt.imshow(mask[:, :, H])\n",
    "plt.show()\n",
    "\n",
    "print(np.unique(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eb19a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  4,  5,  6, 11, 12, 13, 14, 15, 18, 21, 25, 26, 27, 34, 45,\n",
       "        49, 50, 52, 54, 56, 59, 73, 76, 88], dtype=uint8),\n",
       " tensor([[[ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          ...,\n",
       "          [ 0,  0,  0,  ...,  1,  1,  1],\n",
       "          [ 0,  0,  0,  ...,  1,  1,  1],\n",
       "          [ 0,  0,  0,  ...,  1,  1,  1]],\n",
       " \n",
       "         [[ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          ...,\n",
       "          [ 0,  0,  0,  ...,  1,  1,  1],\n",
       "          [ 0,  0,  0,  ...,  1,  1,  1],\n",
       "          [ 0,  0,  0,  ...,  1,  1, 73]],\n",
       " \n",
       "         [[ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "          ...,\n",
       "          [ 0,  0,  0,  ...,  1,  1, 73],\n",
       "          [ 0,  0,  0,  ..., 73, 73, 73],\n",
       "          [ 0,  0,  0,  ..., 73, 73, 73]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0,  0,  0,  ..., 88, 88, 88],\n",
       "          [ 0,  0,  0,  ..., 88, 88, 88],\n",
       "          [ 0,  0,  0,  ..., 88, 88, 88],\n",
       "          ...,\n",
       "          [ 0,  0,  0,  ..., 34, 21, 21],\n",
       "          [ 0,  0,  0,  ..., 34, 21, 21],\n",
       "          [ 0,  0,  0,  ..., 21, 21, 21]],\n",
       " \n",
       "         [[ 0,  0,  0,  ..., 88, 88, 88],\n",
       "          [ 0,  0,  0,  ..., 88, 88, 88],\n",
       "          [ 0,  0,  0,  ..., 88, 88, 88],\n",
       "          ...,\n",
       "          [ 0,  0,  0,  ..., 21, 21, 21],\n",
       "          [ 0,  0,  0,  ..., 21, 21, 21],\n",
       "          [ 0,  0,  0,  ..., 21, 21, 21]],\n",
       " \n",
       "         [[ 0,  0,  0,  ..., 88, 88, 88],\n",
       "          [ 0,  0,  0,  ..., 88, 88, 88],\n",
       "          [ 0,  0,  0,  ..., 88, 88, 88],\n",
       "          ...,\n",
       "          [ 0,  0,  0,  ..., 21, 21, 21],\n",
       "          [ 0,  0,  0,  ..., 21, 21, 21],\n",
       "          [ 0,  0,  0,  ..., 21, 21, 21]]], dtype=torch.uint8))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(label), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b861dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.9966,  0.9461,  0.8111],\n",
       "         [-0.0000,  0.0000,  0.0000,  ...,  0.8535,  0.7385,  0.5542],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.5697,  0.5543,  0.4211]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  1.0849,  0.8519,  0.4598],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.7768,  0.3907,  0.0475],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.3884,  0.0697, -0.2468]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
       "         ...,\n",
       "         [ 0.0000, -0.0000, -0.0000,  ...,  0.7512,  0.3998, -0.0177],\n",
       "         [ 0.0000,  0.0000, -0.0000,  ...,  0.2609, -0.1143, -0.4839],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.1971, -0.5487, -0.9865]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0000, -0.0000, -0.0000,  ..., -0.1409,  0.1797,  0.3026],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.4411, -0.5534, -0.6991],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -1.3047, -1.3458, -1.1354],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.9802,  0.9753,  0.9399],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.8254,  0.8649,  0.8545],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.7121,  0.7910,  0.7859]],\n",
       "\n",
       "        [[-0.0000, -0.0000, -0.0000,  ...,  0.3119,  0.3688,  0.2623],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.3961, -0.5657, -0.7075],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -1.0800, -0.8909, -0.7125],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  1.1262,  1.1753,  1.1980],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  1.0126,  1.1051,  1.1525],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  0.9173,  1.0066,  1.0870]],\n",
       "\n",
       "        [[ 0.0000, -0.0000, -0.0000,  ...,  0.5041,  0.3428,  0.1512],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.3275, -0.5007, -0.6138],\n",
       "         [-0.0000, -0.0000, -0.0000,  ..., -0.7144, -0.5192, -0.4256],\n",
       "         ...,\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  1.2183,  1.2545,  1.2660],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  1.2238,  1.2980,  1.2854],\n",
       "         [-0.0000, -0.0000, -0.0000,  ...,  1.1852,  1.2542,  1.2432]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d642d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.9864370822906494 1.9250527620315552\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEWCAYAAACqitpwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAozElEQVR4nO3de5xdZX3v8c9377nkRi6YiJBgQU2tyEGFEfBSRbEQ1Bo8oge1JSrHiKj1nNpjQVuhXHr0WAWpikaJBC9cpLakbWxMEUq9hBLuF6WMKCYpkEBCAoQkM7N/54/17MmaYWayk9l71mTN9/167des9axnrfWsncn+zXPdigjMzMyaqVJ0AczMrHwcXMzMrOkcXMzMrOkcXMzMrOkcXMzMrOkcXMzMrOkcXMzGkKTLJV3Qwus/JekFrbq+WaMcXGyfIulUSTdLelrShrR9piQVXbZWkxSSXjQo7VxJ36nvR8S0iHhwN9c5TtK6VpXTDBxcbB8i6RPAl4DPA88DDgDOAF4DdAxzTnXMCmiA33PLOLjYPkHSDOA84MyIuDYinozM7RHx3ojYkfJdLulSSSskPQ28QdJbJN0uaauktZLOzV33nyV9bNC97pL0dmUuSjWkrZLulnR4yjNZ0hckPSRpi6SfSJqcjn1f0iMp/SZJLx3hud4q6Q5JT0j6maQjRvk+9dduJL1Z0n2SnpS0XtKfSZoK/BA4KDWhPSXpIEmdki6W9F/pdbGkztx1Pynp4XTsfw66z56+54ek89+fjm2WdIakV6b3/glJXx7N+2DjQET45de4fwELgF6gbTf5Lge2kNVmKsAk4Djgv6X9I4BHgZNT/ncBN+fOfxnwOFlN6ETgVmAmIOAlwIEp31eAG4G5QBV4NdCZjn0A2A/oBC4G7hhUvgvS9iuADcAx6RqLgN/UrzPEswXwokFp5wLfGSoP8DDw+2l7FnBk2j4OWDfoOucBq4HnAnOAnwHn5977R4CXAlOA7wy6z56+54ek87+W8p4AbAf+Id1/bnpfXl/0751fe/9yzcX2FbOBxyKit56Q/tJ/QtIzkl6Xy3tdRPw0ImoRsT0iboyIu9P+XcCVwOtT3uXA70qan/b/GLg6InYCPWRB4vcARcQvIuJhSRWyAPLxiFgfEX0R8bNItaeIWBpZzWoH2Yf/y1LNa7DFwNcj4uZ0jWXADuDYEd6H29IzPyHpCeCsEfL2AIdJmh4RmyPithHyvhc4LyI2RMRG4K/SewFZAP5WRNwbEdvSMw22J+953fkp74+Ap4Er0/3XA/9OFnxtH+XgYvuKx4HZktrqCRHx6oiYmY7lf5fX5k+UdIykGyRtlLSFrJ9mdrrGduBq4I9S0Hg38O107MfAl8lqKRskLZE0PZ07CfjV4EJKqkr6rKRfSdpKVhOhfr9Bfgf4xKBgcTBw0Ajvw5ERMbP+Aj47Qt53AG8GHpL0b5JeNULeg4CHcvsP5cpxEAPf0wHv71BpI73nOY/mtp8ZYn/aCOW1cc7BxfYVPyf7q35hA3kHL/X9PbIaysERMYOsOSY/umwZ2V/uxwPbIuLn/ReKuCQijgIOA34X+D/AY2TNOC8c4t7vSWV8EzCDrAmIQferWwtcmA8WETElIq5s4Bl3KyJuiYiFZE1N/wBcUz80RPb/Igt2dc9PaZA1r83LHTt4qNsN2t/de24l5+Bi+4SIeIKsqearkk6RtJ+kiqSXA1N3c/p+wKaI2C7paLIAkL/2z4Ea8AVSrQUgdTAfI6mdrNlmO1CLiBqwFPhi6gyvSnpV6gDfjywIPk7WP/HXI5TrG8AZ6R6SNDV1hO/X4NsyLEkdkt4raUZE9ABb0zNCVkN4zqCmuiuBv5A0R9Js4DNkfSuQBaX3S3qJpCnAXzZQhBHfcys/BxfbZ0TE/wP+FPgk2Qfko8DXgT8n64AezpnAeZKeJPvQvGaIPFeQdUB/J5c2nSwAbCZrJnqcbBg0wJ8BdwO3AJuAz5H9f7oi5V0P3EfWST7c86wBPkjW9LYZ6AbeN8Jz7Kk/Bn6TmufOIKudERG/JAsmD6bmuIOAC4A1wF3puW5LaUTED4FLgBtSGevPtGOEezfynluJKcJfFmYm6TRgcUS8tuiyjHeSXgLcQzaqrXd3+W1ics3FJrzU1HMmsKTosoxXyub9dEqaRVZL+0cHFhuJg4tNaJJOBDaSNbF9r+DijGcfIpt78iugD/hwscWx8a5lwUXSUmUzm+8Z4tgn0gzd2Wlfki6R1J1m6B6Zy7tI0gPptSiXfpSyGdPd6Vyl9P0lrUr5V6W/tMyGFBErI2JqRCz0X+LDi4gFETEjIvaPiLdHxMNFl8nGt1bWXC4nm9k7gKSDyWbk/jaXfBIwP70WA5emvPsD55DNYD4aOCcXLC4l6wytn1e/11nA9RExH7iekSeZmZlZC7TtPsveiYibJB0yxKGLyEb7XJdLWwhcEdnogtWSZko6kGwJiVURsQlA0ipggaQbgekRsTqlXwGcTLZm0sJ0HmTzF24kG000otmzZ8chhwxVXDMzG86tt976WETMGZzesuAyFEkLgfURcacGrpA+l4EzfNeltJHS1w2RDnBArsr+CNnKucOVZzFZTYnnP//5rFmzZk8fycxsQpP00FDpY9ahn0bkfIpszPuYSDWhYcdaR8SSiOiKiK45c54VeM3MbC+N5WixFwKHAndK+g3ZchK3SXoe2YSz/JIS81LaSOnzhkgHeDQ1qZF+bmj6k5iZ2YjGLLikFVKfGxGHRMQhZE1ZR0bEI2RrEJ2WRo0dC2xJTVsrgRMkzUod+ScAK9OxrZKOTaPETmNXH85ysqXLST/zfTtmZjYGWjkU+UqyxQZfLGmdpNNHyL4CeJBsaYlvkE1oI3Xkn0+2xMYtZEuCb0rnnAl8M53zK7LOfMhWif0DSQ+QLR440qqxZmbWAl7+Jenq6gp36JuZ7RlJt0ZE1+B0z9A3M7Omc3AxM7Omc3Axs8KtfvBxujc8WXQxrIkcXMyscJ/6+7v56g3P+tZo24c5uJhZ4Xr6avTUPLioTBxczKxwtRrUPHK1VBxczGx8cGwpFQcXMytcLcI1l5JxcDGzwjm4lI+Di5kVLiJ7WXk4uJhZ4WqRvaw8HFzMrHARgdc5LBcHFzMrXC3Cg8VKxsHFzAoXeJ5L2Ti4mFnharVwn0vJOLiYWeGy0WKOLmXi4GJmhQs8FLlsHFzMrHCeRFk+Di5mVjgHl/JxcDGzwtU8Q790WhZcJC2VtEHSPbm0z0v6paS7JP29pJm5Y2dL6pZ0v6QTc+kLUlq3pLNy6YdKujmlXy2pI6V3pv3udPyQVj2jmTWJg0vptLLmcjmwYFDaKuDwiDgC+E/gbABJhwGnAi9N53xVUlVSFfgKcBJwGPDulBfgc8BFEfEiYDNweko/Hdic0i9K+cxsHHOzWPm0LLhExE3ApkFpP4qI3rS7GpiXthcCV0XEjoj4NdANHJ1e3RHxYETsBK4CFkoS8Ebg2nT+MuDk3LWWpe1rgeNTfjMbpxxcyqfIPpcPAD9M23OBtblj61LacOnPAZ7IBap6+oBrpeNbUv5nkbRY0hpJazZu3DjqBzKzvRP4u8LKppDgIunTQC/w3SLuXxcRSyKiKyK65syZU2RRzCasbNFKr4pcNm1jfUNJ7wPeChwfu6bkrgcOzmWbl9IYJv1xYKaktlQ7yeevX2udpDZgRspvZuNQ/VPAM/TLZUxrLpIWAJ8E3hYR23KHlgOnppFehwLzgf8AbgHmp5FhHWSd/stTULoBOCWdvwi4LnetRWn7FODH4d9as3Gr3tfi/6Xl0rKai6QrgeOA2ZLWAeeQjQ7rBFalPvbVEXFGRNwr6RrgPrLmso9ERF+6zkeBlUAVWBoR96Zb/DlwlaQLgNuBy1L6ZcC3JXWTDSg4tVXPaGajV48p7tAvl5YFl4h49xDJlw2RVs9/IXDhEOkrgBVDpD9INppscPp24J17VFgzK0w9qLjPpVw8Q9/MCuU+l3JycDGzQu0KLsWWw5rLwcXMCrWrWczRpUwcXMysUA4u5eTgYmaFqnfkO7SUi4OLmRXLfS6l5OBiZoVys1g5ObiYWaEcXMrJwcXMClUPKY4t5eLgYmaF8tpi5eTgYmaFqgcVN4uVi4OLmRXKNZdycnAxs0K55lJODi5mViivilxODi5mViivilxODi5mVqjw8i+l5OBiZoXyJMpycnAxs0L1Bxd3upSKg4uZFcqrIpeTg4uZFczzXMrIwcXMClXzPJdSallwkbRU0gZJ9+TS9pe0StID6eeslC5Jl0jqlnSXpCNz5yxK+R+QtCiXfpSku9M5l0jSSPcws/HJM/TLqZU1l8uBBYPSzgKuj4j5wPVpH+AkYH56LQYuhSxQAOcAxwBHA+fkgsWlwAdz5y3YzT3MbBzyDP1yallwiYibgE2DkhcCy9L2MuDkXPoVkVkNzJR0IHAisCoiNkXEZmAVsCAdmx4RqyObeXXFoGsNdQ8zG4dccymnse5zOSAiHk7bjwAHpO25wNpcvnUpbaT0dUOkj3SPZ5G0WNIaSWs2bty4F49jZqPlmks5Fdahn2ocLf1t2t09ImJJRHRFRNecOXNaWRQzG0Z/zaXgclhzjXVweTQ1aZF+bkjp64GDc/nmpbSR0ucNkT7SPcxsHHLNpZzGOrgsB+ojvhYB1+XST0ujxo4FtqSmrZXACZJmpY78E4CV6dhWScemUWKnDbrWUPcws3HIfS7l1NaqC0u6EjgOmC1pHdmor88C10g6HXgIeFfKvgJ4M9ANbAPeDxARmySdD9yS8p0XEfVBAmeSjUibDPwwvRjhHmY2DuVXfYkI0qwC28e1LLhExLuHOXT8EHkD+Mgw11kKLB0ifQ1w+BDpjw91DzMbr3ZFl1pA1bGlFDxD38wKla+5uN+lPBxczKxQ+dWQHVzKw8HFzAo1sM+luHJYczm4mFmhItfn4uBSHg4uZlaocJ9LKTm4mFmh8gHFoaU8HFzMrFCuuZSTg4uZFWpAzaVWYEGsqRxczKxQrrmUk4OLmRXKfS7l5OBiZoVyzaWcHFzMrFD5gOLgUh4OLmZWqPwMfbeLlYeDi5kVbOCqyFYODi5mViivilxODi5mVij3uZSTg4uZFcqrIpfTboOLpG83kmZmtjcivCpyGTVSc3lpfkdSFTiqNcUxs4nG81zKadjgIulsSU8CR0jaml5PAhuA68ashGZWap6hX07DBpeI+L8RsR/w+YiYnl77RcRzIuLs0dxU0v+WdK+keyRdKWmSpEMl3SypW9LVkjpS3s60352OH5K7ztkp/X5JJ+bSF6S0bklnjaasZtZarrmU026bxSLibElzJb1a0uvqr729oaS5wJ8AXRFxOFAFTgU+B1wUES8CNgOnp1NOBzan9ItSPiQdls57KbAA+Kqkamq2+wpwEnAY8O6U18zGoQE1FweX0mjbXQZJnyX7EL8P6EvJAdw0yvtOltQDTAEeBt4IvCcdXwacC1wKLEzbANcCX5aklH5VROwAfi2pGzg65euOiAdT+a9Kee8bRXnNrEXCo8VKabfBBXg78OL0IT5qEbFe0t8AvwWeAX4E3Ao8ERG9Kds6YG7angusTef2StoCPCelr85dOn/O2kHpxzSj7GbWfAPnuRRYEGuqRkaLPQi0N+uGkmaR1SQOBQ4CppI1a405SYslrZG0ZuPGjUUUwWzCy8cT97mURyM1l23AHZKuB/prLxHxJ3t5zzcBv46IjQCSfgC8BpgpqS3VXuYB61P+9cDBwDpJbcAM4PFcel3+nOHSB4iIJcASgK6uLv9WmxXAM/TLqZHgsjy9muW3wLGSppA1ix0PrAFuAE4BrgIWsWu48/K0//N0/McREZKWA9+T9EWyGtB84D8AAfMlHUoWVE5lV1+OmY0znqFfTrsNLhGxrJk3jIibJV0L3Ab0AreT1R7+GbhK0gUp7bJ0ymXAt1OH/SayYEFE3CvpGrKO+l7gIxHRByDpo8BKspFoSyPi3mY+g5k1kWfol1Ijo8V+zRBzmyLiBXt704g4BzhnUPKD7Brtlc+7HXjnMNe5ELhwiPQVwIq9LZ+ZjR2vilxOjTSLdeW2J5F90O/fmuKY2UTjGfrl1Mgkysdzr/URcTHwltYXzcwmAtdcyqmRZrEjc7sVsppMIzUeM7PdCs/QL6VGgsQXctu9wG+Ad7WkNGY24QxcW6y4clhzNTJa7A1jURAzm5hqHi1WSo18WdgMSV+sz2SX9AVJM8aicGZWfp6hX06NLP+yFHiSrCnsXcBW4FutLJSZTRyeoV9OjfS5vDAi3pHb/ytJd7SoPGY2wQyIJ44tpdFIzeUZSa+t70h6DdmyLWZmo1ar5WsuBRbEmqqRmsuHgWW5fpbNwPtaViIzm1Dc51JOjYwWuwN4maTpaX9rqwtlZhOH+1zKqZHRYn8taWZEbI2IrZJmpcUlzcxGbcCqyMUVw5qskT6XkyLiifpORGwG3tyyEpnZxOIZ+qXUSHCpSuqs70iaDHSOkN/MrGED1harFVcOa65GOvS/C1wvqT635f1AU7/jxcwmLq+KXE6NdOh/TtKdZF9PDHB+RKxsbbHMbKLwqsjl1NDqxhHxL8C/tLgsZjYBBe5zKaNG+lzMzFrGqyKXk4OLmRUqP0PfFZfycHAxs0J5hn45DdvnIuluhh68ISAi4oiWlcrMJgzP0C+nkTr039qqm0qaCXwTOJwsgH0AuB+4GjiE9G2XEbFZkoAvkU3c3Aa8LyJuS9dZBPxFuuwFEbEspR8FXA5MBlYAHw/3FJqNS/6fWU7DNotFxEP1V0qan7Y3AJtGed8vAf8SEb8HvAz4BXAWcH1EzAeuT/sAJwHz02sxcCmApP2Bc4BjgKOBcyTNSudcCnwwd96CUZbXzFrENZdyamRtsQ8C1wJfT0nzgH/Y2xum1ZVfB1wGEBE70/IyC9k1OXMZcHLaXghcEZnVwExJBwInAqsiYlNakmYVsCAdmx4Rq1Nt5YrctcxsnAnP0C+lRjr0PwK8huwbKImIB4DnjuKehwIbgW9Jul3SNyVNBQ6IiIdTnkeAA9L2XGBt7vx1KW2k9HVDpD+LpMX1r2/euHHjKB7JzPaWay7l1Ehw2RERO+s7ktoY3SoNbcCRwKUR8QrgaXY1gQHZaIFR3qMhEbEkIroiomvOnDmtvp2ZDcGrIpdTI8Hl3yR9Cpgs6Q+A7wP/OIp7rgPWRcTNaf9asmDzaGrSIv3ckI6vBw7OnT8vpY2UPm+IdDMblzxDv4waCS5nkTVj3Q18CFgREZ/e2xtGxCPAWkkvTknHA/cBy4FFKW0RcF3aXg6cpsyxwJbUfLYSOCF9v8ws4ARgZTq2VdKxaaTZablrmdk4k+9n8Qz98mhkbbE3RsQ3gG/UEyQtqg/73UsfA74rqQN4kGyl5QpwjaTTgYeAd6W8K8iGIXeTDUV+P0BEbJJ0PnBLyndeRNRHsZ3JrqHIP0wvMxuHahFUK6KvFh6WXCKNBJfPSHoH8AlgP7L5KTsYxbL76auTu4Y4dPwQeYNsUMFQ11kKLB0ifQ3ZHBozG+dqAVWJPsId+iXSSLPY64FfAXcCPwG+FxGntLRUZjZhBFnNBdznUiaNBJdZZJMUf0VWY/md1JdhZjZqEdBWDy4Fl8Wap5HgsppsNv0C4JXAQcBPW1oqM5swahFUUnCpuUe/NBrpc3lTRPwWICKeAf5E0utaWywzmyhqQX+zmGNLeYy0KvLvRcQvgdmSZg86/FRri2VmE0VE5IKLo0tZjFRz+VOyhSK/MMSxAN7YkhKZ2YQSabSYlcuwwSUiFqefbxi74pjZRFNzzaWUdtvnImkS2aTE15LVWP4d+FpEbG9x2cxsAgj3uZRSIx36VwBPAn+b9t8DfBt4Z6sKZWYTRy1i11BkB5fSaCS4HB4Rh+X2b5B0X6sKZGYTSy3YNRTZ0aU0GpnncltaMBIASccAa1pXJDObSCKiv0PfM/TLo5Gay1HAzyT9Nu0/H7hf0t1kS38d0bLSmVnpBe5zKaNGgou/f97MWiY/WswVl/LYbXCJiIfGoiBmNjHVAlJscZ9LiTTS52Jm1jKR1haT3OdSJg4uZlaoCKhIVCSvilwiDi5mVqhaBAKEm8XKxMHFzApVi+ivuXi0WHk4uJhZoSJAyl6uuZSHg4uZFSofXNzpUh4OLmZWqIHNYo4uZVFYcJFUlXS7pH9K+4dKullSt6SrJXWk9M60352OH5K7xtkp/X5JJ+bSF6S0bklnjfnDmVnDAtznUkJF1lw+Dvwit/854KKIeBGwGTg9pZ8ObE7pF6V8SDoMOBV4KdkqAl9NAasKfAU4CTgMeHfKa2bjUC2iv1nMFZfyKCS4SJoHvAX4ZtoX2TdbXpuyLANOTtsL0z7p+PEp/0LgqojYERG/BrqBo9OrOyIejIidwFUpr5mNQ7UASR6KXDJF1VwuBj4J1NL+c4AnIqI37a8D5qbtucBagHR8S8rfnz7onOHSn0XSYklrJK3ZuHHjKB/JzPZGRFBRtuy+Z+iXx5gHF0lvBTZExK1jfe/BImJJRHRFRNecOXOKLo7ZhJSfoe8+l/JoZFXkZnsN8DZJbwYmAdOBLwEzJbWl2sk8YH3Kvx44GFgnqQ2YATyeS6/LnzNcupmNM/kZ+uGxyKUx5jWXiDg7IuZFxCFkHfI/joj3AjcAp6Rsi4Dr0vbytE86/uPI6s7LgVPTaLJDgfnAfwC3APPT6LOOdI/lY/BoZrYX+vtcXHMplSJqLsP5c+AqSRcAtwOXpfTLgG9L6gY2kQULIuJeSdcA9wG9wEciog9A0keBlUAVWBoR947pk5hZw/r7XLwqcqkUGlwi4kbgxrT9INlIr8F5tgPvHOb8C4ELh0hfAaxoYlHNrEUGrIrs2FIanqFvZoXKz3PxUOTycHAxs0J5VeRycnAxs0IFXhW5jBxczKxQ0T9aDK+KXCIOLmZWqFr/aDGvilwmDi5mVijP0C8nBxczK9SAVZGLLow1jYOLmRUqAoRXRS4bBxczK1S+z8Uz9MvDwcXMCuUZ+uXk4GJmhfIM/XJycDGzQnlV5HJycDGzgnlV5DJycDGzQtXc51JKDi5mVij3uZSTg4uZFapWy1ZFdp9LuTi4mFmh6qsiVzxDv1QcXMysUPkZ+u7QLw8HFzMrlFdFLicHFzMrVARUKmlV5FrRpbFmGfPgIulgSTdIuk/SvZI+ntL3l7RK0gPp56yULkmXSOqWdJekI3PXWpTyPyBpUS79KEl3p3MukaSxfk4za8zAVZFdcymLImouvcAnIuIw4FjgI5IOA84Cro+I+cD1aR/gJGB+ei0GLoUsGAHnAMcARwPn1ANSyvPB3HkLxuC5zGwv9Pe5CI8WK5ExDy4R8XBE3Ja2nwR+AcwFFgLLUrZlwMlpeyFwRWRWAzMlHQicCKyKiE0RsRlYBSxIx6ZHxOrIegevyF3LzMYZr4pcToX2uUg6BHgFcDNwQEQ8nA49AhyQtucCa3OnrUtpI6WvGyJ9qPsvlrRG0pqNGzeO7mHMbK8EnqFfRoUFF0nTgL8D/ldEbM0fSzWOlv+aRcSSiOiKiK45c+a0+nZmNgTP0C+nQoKLpHaywPLdiPhBSn40NWmRfm5I6euBg3Onz0tpI6XPGyLdzMah8KrIpVTEaDEBlwG/iIgv5g4tB+ojvhYB1+XST0ujxo4FtqTms5XACZJmpY78E4CV6dhWSceme52Wu5aZjSP1Phavilw+bQXc8zXAHwN3S7ojpX0K+CxwjaTTgYeAd6VjK4A3A93ANuD9ABGxSdL5wC0p33kRsSltnwlcDkwGfpheZjbO1Gsq/X0uxRbHmmjMg0tE/AQYbt7J8UPkD+Ajw1xrKbB0iPQ1wOGjKKaZjYF6H4vSy30u5eEZ+mZWmHowqVRSn4tn6JeGg4uZFaZeUfGqyOXj4GJmhekPLmmGvjv0y8PBxcwKUxswWsyrIpeJg4uZFaYeSuqjxTzPpTwcXMysMP2jxeqrIrvmUhoOLmZWmEijw+oz9B1bysPBxcwKUxs0Q999LuXh4GJmhRnc5+LQUh4OLmZWmAF9LrjmUiYOLmZWmF3BxTP0y8bBxcyK079wZfay8nBwMbPCDF4V2c1i5eHgYmaFGbAqskeLlYqDi5kVZtdQZH8TZdk4uJhZYZ61KrKDS2k4uJhZYXYFF6+KXDYOLmZWGK+KXF4OLmZWGM/QLy8HFzMrzOBVkWvu0S+NtqILYGYTR0Swo7dGe7VCRbC9pw9IfS5ko8We2tHb30ym9LOtko0ms31HaYOLpAXAl4Aq8M2I+GzBRTIrXF8teKanj57eGj19NXb21ejpC3rTz56+Gr21Gjt6ajy5o5en06u+vW1nH9M626hW1L+/I12rp6/Gzt7sGu1VsaO3xsNbtrO9J8uzs7fGMzv72Nn37DVeOqoVOtoqPLWjl8PPWfms4xJ0tlXobKvS0Vaho1qhp6/GjMntHDp7Ku1tFaoSUzurzJjcwfTJbbRXKkhQrWRNbpWKqAiqEtWKaKuKp7b3sunpHjZv28mmp3eyedtOHn9qJ9t7+uhoqzCpvUq1IrY808OjW7dz4IxJVCSe3N5LLYLn7z+FWVM6mNxRZVJ7lcntVSZ3VNLPtmftT+usAtnk0b5aIGBKRxtTO6tM62xjamd2TqUEyxWUMrhIqgJfAf4AWAfcIml5RNxXbMlsOMONEqr/J6xF0FcL+iLo64tB8yNIf/VGejFwuxZELi2oj1LKjkdAkOUZaru3lt27ty+IdH792vlyR5A+rGv0peadWmTnZeWHvghq6Xr9z1NLaelYb267r0b/s1crYntPH09u76W3Vuu/Rm8qW7ZdG3a/p6/Gpqd30ruXTU/VipjSXuXpnb3UAia3V5nSUaWzrUJ7+sBvr1Zor4qevqC9KuY/dxqTO6p0tmX5OtsrTJ/Uzo7eGkQwuaONGZPbOe7Fc3j5wTOZs18ntdqgf8dasLOv1h+gdvRmwaqjWuGxp3bw0OPb+t+Pp3f28cS2nfT07dkzTp/Uxv5TO5g1tYODZk5iUnuVHb01tvf0EQGzp3Xwqhc8h0e2bkfAtM42EDz0+DZ+/djTPNPTxzM9fWzf2ce2nr7+f/+9IcGU9ipTO9uY1tnGlM4qUzva+oPP1LSfPz6ts42pHW1Mas+Cb3tVtKeAXf83qf/75NNaWRssZXABjga6I+JBAElXAQuBYYPLfz76JG/8wo3ZTuzqaKx/mGTb9cOxazv3O1T/oInh8g64zt7+8g38ZRj8uzHcr8rgZxiYOug58jlyz5TPG5H/wB6mpMMUJvvAGBgAbJe2SvZXdv0v7Er667uvFnS0VZkxuY22SoVKRbRX01/hFdFWqdDZ3jZgv1rNtqsV0V6pMGe/TqZPbss+aNoqtFcqtLdleesfSG3VCp1tFaZ17vpAm9bZxqT2SlpcMvs/UW3yX9fPm1Hl9NceOurrRATbe2r9gTtyf5hE+mOlr5YF22mT2pg1pYP2anO7n3v6aruCzc4s8Dy9o5end/Yh6gMYsv9X9RrgU/Wa4s6+/hpjffupHb08snX7gHzbdvaNupz1f/P6q6MqOtoqVBtshvzaHx057LGyBpe5wNrc/jrgmMGZJC0GFgNMP+gFvOTA6f0fzlkbcH2bAemQ9lOiUP8H6cBztGu7/98pl7aHDzX4M/jZf+zHs44P/P3Yde+BKQyRrmelD8yr/v8g2fMNfJrhaiIR9P/iViu7ZmbXl/8YnLdSz5f7sK03c9TvU0t/DFSV5VMqV0XZOfV2+/xPGFjrqf97KP3DVrTrd6BazT6YK5Vdo5r6jw96L+t/Febz5INFpZI1y7Sl69Wfpdp/fPw3h4z3Mkpicke10DLUP6ynT2pv2T1qtWBbTy4Q7ehje2/W5Flv7tw5oPmzlppDs5rgzlxz5uC03gZrfp1tw7/PZQ0uDYmIJcASgK6urvjKe4aPwmZm40mlov7a5XhU1qHI64GDc/vzUpqZmY2BsgaXW4D5kg6V1AGcCiwvuExmZhPG+KxPjVJE9Er6KLCSbCjy0oi4t+BimZlNGKUMLgARsQJYUXQ5zMwmorI2i5mZWYEcXMzMrOkcXMzMrOkcXMzMrOnkb37LSNoIPFR0OVpoNvBY0YVoobI/H/gZy6CMz/c7ETFncKKDywQhaU1EdBVdjlYp+/OBn7EMyv58eW4WMzOzpnNwMTOzpnNwmTiWFF2AFiv784GfsQzK/nz93OdiZmZN55qLmZk1nYOLmZk1nYPLBCLpfEl3SbpD0o8kHVR0mZpJ0ucl/TI9499Lmll0mZpN0jsl3SupJqk0Q1olLZB0v6RuSWcVXZ5mk7RU0gZJ9xRdlrHi4DKxfD4ijoiIlwP/BHym4PI02yrg8Ig4AvhP4OyCy9MK9wD/Hbip6II0i6Qq8BXgJOAw4N2SDiu2VE13ObCg6EKMJQeXCSQituZ2p5J99XxpRMSPIqI37a4m+wbSUomIX0TE/UWXo8mOBroj4sGI2AlcBSwsuExNFRE3AZuKLsdYKu33udjQJF0InAZsAd5QcHFa6QPA1UUXwhoyF1ib218HHFNQWaxJHFxKRtK/As8b4tCnI+K6iPg08GlJZwMfBc4Z0wKO0u6eL+X5NNALfHcsy9YsjTyj2Xjn4FIyEfGmBrN+l+ybOvep4LK755P0PuCtwPGxj07i2oN/w7JYDxyc25+X0mwf5j6XCUTS/NzuQuCXRZWlFSQtAD4JvC0ithVdHmvYLcB8SYdK6gBOBZYXXCYbJc/Qn0Ak/R3wYqBG9vUCZ0REaf5ClNQNdAKPp6TVEXFGgUVqOklvB/4WmAM8AdwREScWWqgmkPRm4GKgCiyNiAuLLVFzSboSOI5syf1HgXMi4rJCC9ViDi5mZtZ0bhYzM7Omc3AxM7Omc3AxM7Omc3AxM7Omc3AxM7Omc3Ax2wdIulzSKS28/rmS/qxV17eJx8HFbA9I8qoWZg1wcDFLJP1l+k6Rn0i6sv6XvKQbJV0saQ3wcUl/KOlmSbdL+ldJB0iqSHpA0px0TiV9N8mc9B0s90i6U9JN6XhV0t+k9LskfSylf0bSLSl9iSQNUc6jJP2bpFslrZR04KDjMyQ9JKmS9qdKWiupXdIH0/XvlPR3kqYMcf0b698VI2m2pN/kyvz5dP5dkj7UzPffysXBxQyQ9ErgHcDLyL5XZPAXcXVERFdEfAH4CXBsRLyCbHn4T0ZEDfgO8N6U/03AnRGxkex7c06MiJcBb0vHFwOHAC9P3z9TX2TzyxHxyog4HJhMtk5avpztZDP0T4mIo4ClwIDZ7BGxBbgDeH1KeiuwMiJ6gB+k678M+AVw+h68TacDWyLilcArgQ9KOnQPzrcJxFV8s8xrgOsiYjuwXdI/DjqeX75/HnB1qjF0AL9O6UuB68iWMfkA8K2U/lPgcknXAD9IaW8Cvlb//pmIqH/XxxskfRKYAuwP3Avky/Ji4HBgVarUVIGHh3ieq4H/AdxAtlbXV1P64ZIuAGYC04CVw74jz3YCcESu72cGMD/3/Gb9HFzMGvN0bvtvgS9GxHJJxwHnAkTEWkmPSnoj2RdgvTelnyHpGOAtwK2SjhrqBpImkQWBrnStc4FJg7MB90bEq3ZT3uXAX0vaHzgK+HFKvxw4OSLuTCtIHzfEub3satXI31/AxyJiTwKSTVBuFjPL/BT4Q0mTJE1jUHPUIDPYtST8okHHvknWPPb9iOgDkPTCiLg5Ij4DbCRbXn4V8KH6AIEUBOof5I+lMgw1Oux+YI6kV6Xz2iW9dHCmiHiKbLXhLwH/VC8LsB/wcGpee+/g85LfkAUkBpVhJfDhdC6SflfS1GGuYROcg4sZEBG3kP21fxfwQ+Busm/rHMq5wPcl3Qo8NujYcrLmpm/l0j4v6W5J9wA/A+4kC0K/Be6SdCfwnoh4AvgGcA/ZB/ktQ5RzJ9kH/ufSeXcArx6mnFcDf8TAJr2/BG4mC6bDfeXC35AFkdvJVvGt+yZwH3Bbepav49YPG4ZXRTZLJE2LiKfSCKqbgMURcdseXqMLuCgifr8lhTTbR/ivDrNdlkg6jKx5atleBJazgA8zfHOT2YThmouZmTWd+1zMzKzpHFzMzKzpHFzMzKzpHFzMzKzpHFzMzKzp/j/UanHRB14dtwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixel_min, pixel_max = image.min().item(), image.max().item()\n",
    "print(pixel_min, pixel_max)\n",
    "histogram, bin_edges = np.histogram(image, bins=256, range=(pixel_min, pixel_max))\n",
    "plt.figure()\n",
    "plt.title(\"Grayscale Histogram\")\n",
    "plt.xlabel(\"grayscale value\")\n",
    "plt.ylabel(\"pixel count\")\n",
    "plt.xlim([pixel_min, pixel_max])  # <- named arguments do not work here\n",
    "\n",
    "plt.plot(bin_edges[0:-1], histogram)  # <- or here\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba77b7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7417c447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f98a801b760>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_img = np.where(image < 0, 2, image)\n",
    "new_img.shape\n",
    "plt.figure(\"check\", (15, 10))\n",
    "plt.title(\"image\")\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(new_img[:, :, H], cmap=\"gray\")\n",
    "# plt.imshow(new_img[:, :, H])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(image[:, :, H], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f28996d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.        , -0.        , -0.        , ...,  0.9503681 ,\n",
       "         0.8475017 ,  0.6121518 ],\n",
       "       [-0.        , -0.        , -0.        , ...,  1.1128862 ,\n",
       "         0.97549444,  0.68231505],\n",
       "       [-0.        , -0.        , -0.        , ...,  0.98591965,\n",
       "         0.65584195,  0.24865425],\n",
       "       ...,\n",
       "       [ 2.        ,  2.        ,  2.        , ...,  0.8932964 ,\n",
       "         0.7096675 ,  0.5807393 ],\n",
       "       [ 0.08681662,  2.        ,  2.        , ...,  1.0102619 ,\n",
       "         0.90664905,  0.8261692 ],\n",
       "       [ 0.5103806 ,  2.        ,  2.        , ...,  1.1441758 ,\n",
       "         1.1188741 ,  1.0724839 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_img[:, :, H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fadfc490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1, 64, 64, 64])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e0c5688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  ...,  1,  1,  1],\n",
       "        [ 0,  0,  0,  ...,  1,  1,  1],\n",
       "        [ 0,  0,  0,  ...,  1,  1,  1],\n",
       "        ...,\n",
       "        [88, 88, 88,  ..., 34, 34, 34],\n",
       "        [88, 88, 88,  ..., 21, 21, 21],\n",
       "        [88, 88, 88,  ..., 21, 21, 21]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[:, :, H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4aba0c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, -0.0000, -0.0000,  ...,  0.9504,  0.8475,  0.6122],\n",
       "        [-0.0000, -0.0000, -0.0000,  ...,  1.1129,  0.9755,  0.6823],\n",
       "        [-0.0000, -0.0000, -0.0000,  ...,  0.9859,  0.6558,  0.2487],\n",
       "        ...,\n",
       "        [-0.4757, -0.5259, -1.1418,  ...,  0.8933,  0.7097,  0.5807],\n",
       "        [ 0.0868, -0.3005, -1.1343,  ...,  1.0103,  0.9066,  0.8262],\n",
       "        [ 0.5104, -0.0761, -0.8429,  ...,  1.1442,  1.1189,  1.0725]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[:, :, H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f81d5bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image', 'label', 'image_meta_dict', 'label_meta_dict', 'image_transforms', 'label_transforms', 'resample_flag', 'anisotrophy_flag'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1826a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sizeof_hdr': tensor([348, 348, 348, 348, 348, 348, 348, 348, 348, 348, 348, 348],\n",
       "        dtype=torch.int32),\n",
       " 'extents': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32),\n",
       " 'session_error': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int16),\n",
       " 'dim_info': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.uint8),\n",
       " 'dim': tensor([[  3, 186, 230, 230,   1,   1,   1,   1],\n",
       "         [  3, 186, 230, 230,   1,   1,   1,   1],\n",
       "         [  3, 186, 230, 230,   1,   1,   1,   1],\n",
       "         [  3, 186, 230, 230,   1,   1,   1,   1],\n",
       "         [  3, 186, 230, 230,   1,   1,   1,   1],\n",
       "         [  3, 186, 230, 230,   1,   1,   1,   1],\n",
       "         [  3, 186, 230, 230,   1,   1,   1,   1],\n",
       "         [  3, 186, 230, 230,   1,   1,   1,   1],\n",
       "         [  3, 186, 230, 230,   1,   1,   1,   1],\n",
       "         [  3, 186, 230, 230,   1,   1,   1,   1],\n",
       "         [  3, 186, 230, 230,   1,   1,   1,   1],\n",
       "         [  3, 186, 230, 230,   1,   1,   1,   1]], dtype=torch.int16),\n",
       " 'intent_p1': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'intent_p2': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'intent_p3': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'intent_code': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int16),\n",
       " 'datatype': tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16], dtype=torch.int16),\n",
       " 'bitpix': tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32], dtype=torch.int16),\n",
       " 'slice_start': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int16),\n",
       " 'pixdim': tensor([[1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0.]]),\n",
       " 'vox_offset': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'scl_slope': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]),\n",
       " 'scl_inter': tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]),\n",
       " 'slice_end': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int16),\n",
       " 'slice_code': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.uint8),\n",
       " 'xyzt_units': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=torch.uint8),\n",
       " 'cal_max': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'cal_min': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'slice_duration': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'toffset': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'glmax': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32),\n",
       " 'glmin': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32),\n",
       " 'qform_code': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int16),\n",
       " 'sform_code': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int16),\n",
       " 'quatern_b': tensor([-0.0045, -0.0045, -0.0045, -0.0045, -0.0045, -0.0045, -0.0045, -0.0045,\n",
       "         -0.0045, -0.0045, -0.0045, -0.0045]),\n",
       " 'quatern_c': tensor([0.0119, 0.0119, 0.0119, 0.0119, 0.0119, 0.0119, 0.0119, 0.0119, 0.0119,\n",
       "         0.0119, 0.0119, 0.0119]),\n",
       " 'quatern_d': tensor([0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148,\n",
       "         0.0148, 0.0148, 0.0148]),\n",
       " 'qoffset_x': tensor([-91.3984, -91.3984, -91.3984, -91.3984, -91.3984, -91.3984, -91.3984,\n",
       "         -91.3984, -91.3984, -91.3984, -91.3984, -91.3984]),\n",
       " 'qoffset_y': tensor([-121.7941, -121.7941, -121.7941, -121.7941, -121.7941, -121.7941,\n",
       "         -121.7941, -121.7941, -121.7941, -121.7941, -121.7941, -121.7941]),\n",
       " 'qoffset_z': tensor([-94.6716, -94.6716, -94.6716, -94.6716, -94.6716, -94.6716, -94.6716,\n",
       "         -94.6716, -94.6716, -94.6716, -94.6716, -94.6716]),\n",
       " 'srow_x': tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " 'srow_y': tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " 'srow_z': tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " 'affine': tensor([[[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]]),\n",
       " 'original_affine': tensor([[[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       " \n",
       "         [[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
       "        dtype=torch.float64),\n",
       " 'as_closest_canonical': tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False]),\n",
       " 'spatial_shape': tensor([[186, 230, 230],\n",
       "         [186, 230, 230],\n",
       "         [186, 230, 230],\n",
       "         [186, 230, 230],\n",
       "         [186, 230, 230],\n",
       "         [186, 230, 230],\n",
       "         [186, 230, 230],\n",
       "         [186, 230, 230],\n",
       "         [186, 230, 230],\n",
       "         [186, 230, 230],\n",
       "         [186, 230, 230],\n",
       "         [186, 230, 230]], dtype=torch.int16),\n",
       " 'original_channel_dim': ['no_channel',\n",
       "  'no_channel',\n",
       "  'no_channel',\n",
       "  'no_channel',\n",
       "  'no_channel',\n",
       "  'no_channel',\n",
       "  'no_channel',\n",
       "  'no_channel',\n",
       "  'no_channel',\n",
       "  'no_channel',\n",
       "  'no_channel',\n",
       "  'no_channel'],\n",
       " 'filename_or_obj': ['/data/train/running/l/input_augmented/s_SU0360_03_d_b.nii.gz',\n",
       "  '/data/train/running/l/input_augmented/s_SU0360_03_d_b.nii.gz',\n",
       "  '/data/train/running/l/input_augmented/s_SU0360_03_d_b.nii.gz',\n",
       "  '/data/train/running/l/input_augmented/s_SU0360_03_d_b.nii.gz',\n",
       "  '/data/train/running/l/input_augmented/s_SU0360_01_d_b.nii.gz',\n",
       "  '/data/train/running/l/input_augmented/s_SU0360_01_d_b.nii.gz',\n",
       "  '/data/train/running/l/input_augmented/s_SU0360_01_d_b.nii.gz',\n",
       "  '/data/train/running/l/input_augmented/s_SU0360_01_d_b.nii.gz',\n",
       "  '/data/train/running/l/input_augmented/s_SU0005_00_0_b.nii.gz',\n",
       "  '/data/train/running/l/input_augmented/s_SU0005_00_0_b.nii.gz',\n",
       "  '/data/train/running/l/input_augmented/s_SU0005_00_0_b.nii.gz',\n",
       "  '/data/train/running/l/input_augmented/s_SU0005_00_0_b.nii.gz'],\n",
       " 'patch_index': tensor([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['image_meta_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4157bd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
