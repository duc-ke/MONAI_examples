{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a105b425",
   "metadata": {},
   "source": [
    "## dynunet pipeline with NeuroI ROI dataset\n",
    "* medicaldecathlon 을 이용한 4D multi classes segmentation. -> 동작함.\n",
    "* 아래 파이프라인을 바탕으로 현재 NEUROI ROI 데이터셋을 태워서 뭐가 문제가 있는지 확인해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cf9fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from monai.config import print_config\n",
    "from monai.handlers import (\n",
    "    CheckpointSaver,\n",
    "    LrScheduleHandler,\n",
    "    MeanDice,\n",
    "    StatsHandler,\n",
    "    ValidationHandler,\n",
    "    from_engine,\n",
    ")\n",
    "from monai.inferers import SimpleInferer, SlidingWindowInferer\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.utils import set_determinism\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "from create_dataset import get_data_ke\n",
    "from create_network import get_network_ke\n",
    "from evaluator import DynUNetEvaluator\n",
    "from task_params import data_loader_params, patch_size\n",
    "from trainer import DynUNetTrainer\n",
    "\n",
    "from monai.utils import first\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4190dfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \ttrain.py -fold $fold -train_num_workers 4 -interval 10 -num_samples 2 \\\n",
    "# \t-learning_rate $lr -max_epochs 3000 -task_id 01 -pos_sample_num 1 \\\n",
    "# \t-expr_name baseline -tta_val True -multi_gpu True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af9f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_id = \"01\"\n",
    "# fold = 0\n",
    "# root_dir = \"/data/kehyeong/project/MONAI_examples/data/brats/\"\n",
    "# datalist_path =\"config/\"\n",
    "\n",
    "config = \"/work/NeuroI-models/ke-monai/config_gpu/config_roi_earlystop_toy_220209.yaml\"\n",
    "train_dataset = \"/work/NeuroI-models/ke-monai/data/roi/dataset_train_roi_toy2.csv\"\n",
    "val_dataset = \"/work/NeuroI-models/ke-monai/data/roi/dataset_val_roi_toy2.csv\"\n",
    "log_file = \"/data/train/running/l/model_roi_toy_220210/train.log\"\n",
    "checkpoint = None\n",
    "\n",
    "\n",
    "max_epochs = 3000\n",
    "num_samples = 6\n",
    "train_num_workers = 4\n",
    "learning_rate = 1e-1\n",
    "interval = 2\n",
    "val_num_workers = 2\n",
    "multi_gpu = False  # True\n",
    "local_rank = 0\n",
    "\n",
    "patch_size = [64, 64, 64] # [128, 128, 128]    #[96, 96, 96]\n",
    "window_mode = \"gaussian\"  # \"constant\", \"gaussian\"\n",
    "eval_overlap = 0.5\n",
    "tta_val = True\n",
    "batch_dice = False\n",
    "lr_decay_flag = False\n",
    "spacing = [1.0, 1.0, 1.0]\n",
    "deep_supr_num = 3\n",
    "\n",
    "\n",
    "expr_name = \"baseline\"\n",
    "####################################\n",
    "\n",
    "\n",
    "# eval_overlap = 0.5\n",
    "sw_batch_size = 2   # validation batch_size\n",
    "# window_mode = \"gaussian\"\n",
    "\n",
    "# pos_sample_num = 1\n",
    "# neg_sample_num = 1\n",
    "# cache_rate = 1.0\n",
    "\n",
    "\n",
    "# mode = \"train\"\n",
    "# checkpoint = None\n",
    "# amp = False\n",
    "# lr_decay = False\n",
    "# tta_val = True\n",
    "# batch_dice = False\n",
    "# determinism_flag = False\n",
    "# determinism_seed = 0\n",
    "# expr_name = \"baseline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf83b130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0217 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0217 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0217 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0217 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0005 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0005 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0005 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0005 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0419 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0419 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0419 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0419 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0400 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0400 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0400 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0400 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0172 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0172 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0172 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0172 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0244 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0244 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0244 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0244 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0088 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0088 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0088 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0088 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0125 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0125 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0125 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0125 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0459 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0459 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0459 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0459 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0210 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0210 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0210 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0210 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0312 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0312 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0312 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0312 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0360 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0360 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0360 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0360 03_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0493 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0493 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0493 02_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0493 03_d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|█████████████████████████████████████████████████████████████████████████| 52/52 [00:18<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0454 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0454 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0303 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0303 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0197 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0197 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0350 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0350 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0317 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0317 01_d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|█████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from config import get_config\n",
    "from dataset_roi import get_train_loader, get_val_loader\n",
    "import monai\n",
    "\n",
    "local_rank = local_rank\n",
    "log_file = log_file\n",
    "train_dataset = train_dataset\n",
    "val_dataset = val_dataset\n",
    "checkpoint = checkpoint\n",
    "\n",
    "multi_gpu_flag = multi_gpu\n",
    "config = get_config(config)\n",
    "data_dir = config[\"data_dir\"]\n",
    "image_file_path = config[\"image_file_path\"]\n",
    "label_file_path = config[\"label_file_path\"]\n",
    "# brain_file_path = config[\"brain_file_path\"]\n",
    "mask_file_path = config[\"mask_file_path\"]\n",
    "random_seed = config[\"random_seed\"]\n",
    "max_epochs = config[\"train\"][\"max_epoches\"]\n",
    "num_classes = config[\"num_classes\"]\n",
    "\n",
    "# patch_size = tuple(config[\"patch_size\"])\n",
    "lr = config[\"train\"][\"lr\"]\n",
    "train_batch_size = config[\"train\"][\"batch_size\"]\n",
    "train_num_samples = config[\"train\"][\"num_samples\"]\n",
    "train_num_workers = config[\"train\"][\"num_workers\"]\n",
    "val_interval = config[\"train\"][\"val_interval\"]\n",
    "val_batch_size = config[\"val\"][\"batch_size\"]\n",
    "val_num_workers = config[\"val\"][\"num_workers\"]\n",
    "log_dir = config[\"log_dir\"]\n",
    "model_dir = config[\"model_dir\"]\n",
    "mlflow_dir = os.path.join(log_dir, \"mlruns\")\n",
    "\n",
    "amp_flag = (True if monai.utils.get_torch_version_tuple() >= (1, 6) else False,)\n",
    "\n",
    "monai.utils.set_determinism(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5,6\"\n",
    "\n",
    "if multi_gpu_flag:\n",
    "    dist.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "    device = torch.device(f\"cuda:{local_rank}\")\n",
    "    torch.cuda.set_device(device)\n",
    "else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "#\n",
    "# data loader\n",
    "#\n",
    "train_loader = get_train_loader(\n",
    "    data_dir=data_dir,\n",
    "    id_file=train_dataset,\n",
    "    image_file_pattern=image_file_path,\n",
    "    label_file_pattern=label_file_path,\n",
    "    # brain_file_pattern=brain_file_path,\n",
    "    mask_file_pattern=mask_file_path,\n",
    "    batch_size=train_batch_size,\n",
    "    patch_size=patch_size,\n",
    "    num_samples=train_num_samples,\n",
    "    num_workers=train_num_workers,\n",
    "    multi_gpu_flag=multi_gpu_flag\n",
    ")\n",
    "val_loader = get_val_loader(\n",
    "    data_dir=data_dir,\n",
    "    id_file=val_dataset,\n",
    "    image_file_pattern=image_file_path,\n",
    "    label_file_pattern=label_file_path,\n",
    "    # brain_file_pattern=brain_file_path,\n",
    "    mask_file_pattern=mask_file_path,\n",
    "    batch_size=val_batch_size,\n",
    "    num_workers=val_num_workers,\n",
    "    multi_gpu_flag=multi_gpu_flag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f73edccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be28fc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['image', 'label', 'image_meta_dict', 'label_meta_dict', 'image_transforms', 'label_transforms', 'resample_flag', 'anisotrophy_flag'])\n",
      "image, label shape\n",
      "torch.Size([12, 1, 64, 64, 64])\n",
      "torch.Size([12, 1, 64, 64, 64])\n",
      "torch.float32\n",
      "torch.uint8\n",
      "[  0   1   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  20  21  23  24  25  26  27  28  29  30  31  32  33  34  36  37  39  40\n",
      "  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
      "  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76\n",
      "  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94\n",
      "  95  96  97  98  99 100 101 102 103 104 105 106 107 108]\n",
      "class 수 104\n"
     ]
    }
   ],
   "source": [
    "test_data = first(train_loader)\n",
    "print(test_data.keys())\n",
    "print('image, label shape')\n",
    "print(test_data['image'].shape)\n",
    "print(test_data['label'].shape)\n",
    "print(test_data['image'].dtype)\n",
    "print(test_data['label'].dtype)\n",
    "print(np.unique(test_data['label']))\n",
    "total_labels = np.unique(test_data['label'])\n",
    "print(f'class 수 {len(total_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df1a7942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 32\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 54\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 50\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 48\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 52\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 31\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 52\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 28\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 63\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 70\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 42\n",
      "torch.Size([1, 64, 64, 64])\n",
      "class 수 38\n"
     ]
    }
   ],
   "source": [
    "for each in test_data['label']:\n",
    "    print(each.shape)\n",
    "    total_labels = np.unique(each)\n",
    "    print(f'class 수 {len(total_labels)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf0ef96",
   "metadata": {},
   "source": [
    "**modicaldecatholon 파이프라인 참고**\n",
    "\n",
    "```python\n",
    "task_id = task_id\n",
    "fold = fold\n",
    "val_output_dir = \"./runs_{}_fold{}_{}/\".format(task_id, fold, expr_name)\n",
    "log_filename = \"nnunet_task{}_fold{}.log\".format(task_id, fold)\n",
    "log_filename = os.path.join(val_output_dir, log_filename)\n",
    "interval = interval\n",
    "learning_rate = learning_rate\n",
    "max_epochs = max_epochs\n",
    "multi_gpu_flag = multi_gpu\n",
    "amp_flag = amp\n",
    "lr_decay_flag = lr_decay\n",
    "sw_batch_size = sw_batch_size\n",
    "tta_val = tta_val\n",
    "batch_dice = batch_dice\n",
    "window_mode = window_mode\n",
    "eval_overlap = eval_overlap\n",
    "local_rank = local_rank\n",
    "determinism_flag = determinism_flag\n",
    "determinism_seed = determinism_seed\n",
    "if determinism_flag:\n",
    "    set_determinism(seed=determinism_seed)\n",
    "    if local_rank == 0:\n",
    "        print(\"Using deterministic training.\")\n",
    "\n",
    "# transforms\n",
    "train_batch_size = data_loader_params[task_id][\"batch_size\"]\n",
    "if multi_gpu_flag:\n",
    "    dist.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "\n",
    "    device = torch.device(f\"cuda:{local_rank}\")\n",
    "    torch.cuda.set_device(device)\n",
    "else:\n",
    "    device = torch.device(\"cuda:3\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "properties, val_loader = get_data_ke(fold, task_id, root_dir, datalist_path, pos_sample_num,\n",
    "                                     neg_sample_num, num_samples, multi_gpu, val_num_workers,\n",
    "                                     cache_rate, train_num_workers, mode=\"validation\")\n",
    "_, train_loader = get_data_ke(fold, task_id, root_dir, datalist_path, pos_sample_num,\n",
    "                              neg_sample_num, num_samples, multi_gpu, val_num_workers,\n",
    "                              cache_rate, train_num_workers, \n",
    "                              batch_size=train_batch_size, mode=\"train\")\n",
    "\n",
    "## ke\n",
    "test_data = first(train_loader)\n",
    "print(test_data.keys())\n",
    "print('image, label shape')\n",
    "print(test_data['image'].shape)\n",
    "print(test_data['label'].shape)\n",
    "print(test_data['image'].dtype)\n",
    "print(test_data['label'].dtype)\n",
    "print(np.unique(test_data['label']))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0396624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 109)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties = {\n",
    "    'modality': [0],\n",
    "    'labels': np.arange(num_classes)\n",
    "}\n",
    "n_class = len(properties[\"labels\"])\n",
    "in_channels = len(properties[\"modality\"])\n",
    "in_channels, n_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2f1d38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 10:26:40,588 - ignite.engine.engine.DynUNetTrainer - INFO - Engine run resuming from iteration 0, epoch 0 until 1500 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynUNet(\n",
      "  (input_block): UnetBasicBlock(\n",
      "    (conv1): Convolution(\n",
      "      (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "    (conv2): Convolution(\n",
      "      (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "    (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  )\n",
      "  (downsamples): ModuleList(\n",
      "    (0): UnetBasicBlock(\n",
      "      (conv1): Convolution(\n",
      "        (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (conv2): Convolution(\n",
      "        (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (1): UnetBasicBlock(\n",
      "      (conv1): Convolution(\n",
      "        (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (conv2): Convolution(\n",
      "        (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (2): UnetBasicBlock(\n",
      "      (conv1): Convolution(\n",
      "        (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (conv2): Convolution(\n",
      "        (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "  )\n",
      "  (bottleneck): UnetBasicBlock(\n",
      "    (conv1): Convolution(\n",
      "      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "    (conv2): Convolution(\n",
      "      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "    (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (norm1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (norm2): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  )\n",
      "  (upsamples): ModuleList(\n",
      "    (0): UnetUpBlock(\n",
      "      (transp_conv): Convolution(\n",
      "        (conv): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "      )\n",
      "      (conv_block): UnetBasicBlock(\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (1): UnetUpBlock(\n",
      "      (transp_conv): Convolution(\n",
      "        (conv): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "      )\n",
      "      (conv_block): UnetBasicBlock(\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (2): UnetUpBlock(\n",
      "      (transp_conv): Convolution(\n",
      "        (conv): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "      )\n",
      "      (conv_block): UnetBasicBlock(\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (3): UnetUpBlock(\n",
      "      (transp_conv): Convolution(\n",
      "        (conv): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "      )\n",
      "      (conv_block): UnetBasicBlock(\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output_block): UnetOutBlock(\n",
      "    (conv): Convolution(\n",
      "      (conv): Conv3d(32, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "    )\n",
      "  )\n",
      "  (deep_supervision_heads): ModuleList(\n",
      "    (0): UnetOutBlock(\n",
      "      (conv): Convolution(\n",
      "        (conv): Conv3d(64, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): UnetOutBlock(\n",
      "      (conv): Convolution(\n",
      "        (conv): Conv3d(128, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): UnetOutBlock(\n",
      "      (conv): Convolution(\n",
      "        (conv): Conv3d(256, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (skip_layers): DynUNetSkipLayer(\n",
      "    (downsample): UnetBasicBlock(\n",
      "      (conv1): Convolution(\n",
      "        (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (conv2): Convolution(\n",
      "        (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (next_layer): DynUNetSkipLayer(\n",
      "      (downsample): UnetBasicBlock(\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "      (next_layer): DynUNetSkipLayer(\n",
      "        (downsample): UnetBasicBlock(\n",
      "          (conv1): Convolution(\n",
      "            (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "          )\n",
      "          (conv2): Convolution(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          )\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (next_layer): DynUNetSkipLayer(\n",
      "          (downsample): UnetBasicBlock(\n",
      "            (conv1): Convolution(\n",
      "              (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "            )\n",
      "            (conv2): Convolution(\n",
      "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            )\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          )\n",
      "          (next_layer): UnetBasicBlock(\n",
      "            (conv1): Convolution(\n",
      "              (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "            )\n",
      "            (conv2): Convolution(\n",
      "              (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            )\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (norm1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (norm2): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          )\n",
      "          (upsample): UnetUpBlock(\n",
      "            (transp_conv): Convolution(\n",
      "              (conv): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "            )\n",
      "            (conv_block): UnetBasicBlock(\n",
      "              (conv1): Convolution(\n",
      "                (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              )\n",
      "              (conv2): Convolution(\n",
      "                (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              )\n",
      "              (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "              (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (super_head): UnetOutBlock(\n",
      "            (conv): Convolution(\n",
      "              (conv): Conv3d(256, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (upsample): UnetUpBlock(\n",
      "          (transp_conv): Convolution(\n",
      "            (conv): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "          )\n",
      "          (conv_block): UnetBasicBlock(\n",
      "            (conv1): Convolution(\n",
      "              (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            )\n",
      "            (conv2): Convolution(\n",
      "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            )\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          )\n",
      "        )\n",
      "        (super_head): UnetOutBlock(\n",
      "          (conv): Convolution(\n",
      "            (conv): Conv3d(128, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (upsample): UnetUpBlock(\n",
      "        (transp_conv): Convolution(\n",
      "          (conv): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "        )\n",
      "        (conv_block): UnetBasicBlock(\n",
      "          (conv1): Convolution(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          )\n",
      "          (conv2): Convolution(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          )\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (super_head): UnetOutBlock(\n",
      "        (conv): Convolution(\n",
      "          (conv): Conv3d(64, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (upsample): UnetUpBlock(\n",
      "      (transp_conv): Convolution(\n",
      "        (conv): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "      )\n",
      "      (conv_block): UnetBasicBlock(\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 10:26:47,773 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 1/17 -- train_loss: 11.4669 \n",
      "2022-02-15 10:26:48,075 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 2/17 -- train_loss: 9.7904 \n",
      "2022-02-15 10:26:48,369 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 3/17 -- train_loss: 8.3554 \n",
      "2022-02-15 10:26:48,711 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 4/17 -- train_loss: 6.9775 \n",
      "2022-02-15 10:26:49,501 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 5/17 -- train_loss: 7.1816 \n",
      "2022-02-15 10:26:49,798 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 6/17 -- train_loss: 6.2885 \n",
      "2022-02-15 10:26:50,095 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 7/17 -- train_loss: 6.5609 \n",
      "2022-02-15 10:26:50,426 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 8/17 -- train_loss: 5.7142 \n",
      "2022-02-15 10:26:50,766 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 9/17 -- train_loss: 5.5518 \n",
      "2022-02-15 10:26:51,103 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 10/17 -- train_loss: 6.5249 \n",
      "2022-02-15 10:26:51,441 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 11/17 -- train_loss: 6.9737 \n",
      "2022-02-15 10:26:51,766 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 12/17 -- train_loss: 6.2910 \n",
      "2022-02-15 10:26:52,097 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 13/17 -- train_loss: 5.7672 \n",
      "2022-02-15 10:26:52,432 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 14/17 -- train_loss: 6.1738 \n",
      "2022-02-15 10:26:52,801 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 15/17 -- train_loss: 5.6421 \n",
      "2022-02-15 10:26:53,136 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 16/17 -- train_loss: 6.3578 \n",
      "2022-02-15 10:26:53,482 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 1/1500, Iter: 17/17 -- train_loss: 6.5547 \n",
      "2022-02-15 10:26:53,484 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-15 10:26:53,486 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[1] Complete. Time taken: 00:00:12\n",
      "2022-02-15 10:26:54,815 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 1/17 -- train_loss: 5.8791 \n",
      "2022-02-15 10:26:55,109 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 2/17 -- train_loss: 5.7244 \n",
      "2022-02-15 10:26:55,446 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 3/17 -- train_loss: 6.1795 \n",
      "2022-02-15 10:26:55,794 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 4/17 -- train_loss: 5.8834 \n",
      "2022-02-15 10:26:56,187 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 5/17 -- train_loss: 5.8792 \n",
      "2022-02-15 10:26:56,483 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 6/17 -- train_loss: 6.8360 \n",
      "2022-02-15 10:26:56,840 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 7/17 -- train_loss: 5.8641 \n",
      "2022-02-15 10:26:57,227 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 8/17 -- train_loss: 6.1688 \n",
      "2022-02-15 10:26:57,522 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 9/17 -- train_loss: 6.0120 \n",
      "2022-02-15 10:26:57,857 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 10/17 -- train_loss: 5.7039 \n",
      "2022-02-15 10:26:58,192 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 11/17 -- train_loss: 5.6310 \n",
      "2022-02-15 10:26:58,542 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 12/17 -- train_loss: 5.9223 \n",
      "2022-02-15 10:26:58,880 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 13/17 -- train_loss: 5.1134 \n",
      "2022-02-15 10:26:59,207 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 14/17 -- train_loss: 6.0851 \n",
      "2022-02-15 10:26:59,558 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 15/17 -- train_loss: 5.9809 \n",
      "2022-02-15 10:26:59,913 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 16/17 -- train_loss: 6.0087 \n",
      "2022-02-15 10:27:00,252 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 2/1500, Iter: 17/17 -- train_loss: 5.7550 \n",
      "2022-02-15 10:27:00,254 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run resuming from iteration 0, epoch 1 until 2 epochs\n",
      "2022-02-15 10:30:39,052 - ignite.engine.engine.DynUNetEvaluator - INFO - Got new best metric of val_mean_dice: 0.012682793661952019\n",
      "2022-02-15 10:30:39,142 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[2] Metrics -- val_mean_dice: 0.0127 \n",
      "2022-02-15 10:30:39,144 - ignite.engine.engine.DynUNetEvaluator - INFO - Key metric: val_mean_dice best value: 0.012682793661952019 at epoch: 2\n",
      "2022-02-15 10:30:39,498 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[2] Complete. Time taken: 00:03:38\n",
      "2022-02-15 10:30:39,499 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run complete. Time taken: 00:03:39\n",
      "2022-02-15 10:30:41,979 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-15 10:30:41,980 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[2] Complete. Time taken: 00:03:48\n",
      "2022-02-15 10:30:44,058 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 1/17 -- train_loss: 5.5870 \n",
      "2022-02-15 10:30:44,351 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 2/17 -- train_loss: 6.1434 \n",
      "2022-02-15 10:30:44,641 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 3/17 -- train_loss: 5.4489 \n",
      "2022-02-15 10:30:45,038 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 4/17 -- train_loss: 5.6464 \n",
      "2022-02-15 10:30:45,422 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 5/17 -- train_loss: 5.2642 \n",
      "2022-02-15 10:30:45,713 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 6/17 -- train_loss: 5.2990 \n",
      "2022-02-15 10:30:46,008 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 7/17 -- train_loss: 6.0352 \n",
      "2022-02-15 10:30:46,304 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 8/17 -- train_loss: 5.7113 \n",
      "2022-02-15 10:30:46,641 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 9/17 -- train_loss: 5.1906 \n",
      "2022-02-15 10:30:46,980 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 10/17 -- train_loss: 5.4612 \n",
      "2022-02-15 10:30:47,318 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 11/17 -- train_loss: 5.2564 \n",
      "2022-02-15 10:30:47,648 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 12/17 -- train_loss: 5.5147 \n",
      "2022-02-15 10:30:47,982 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 13/17 -- train_loss: 5.1979 \n",
      "2022-02-15 10:30:48,328 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 14/17 -- train_loss: 5.4697 \n",
      "2022-02-15 10:30:48,666 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 15/17 -- train_loss: 5.3667 \n",
      "2022-02-15 10:30:48,992 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 16/17 -- train_loss: 5.3020 \n",
      "2022-02-15 10:30:49,336 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 3/1500, Iter: 17/17 -- train_loss: 5.8544 \n",
      "2022-02-15 10:30:49,337 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-15 10:30:49,338 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[3] Complete. Time taken: 00:00:07\n",
      "2022-02-15 10:30:51,513 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 1/17 -- train_loss: 5.3807 \n",
      "2022-02-15 10:30:51,803 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 2/17 -- train_loss: 5.4036 \n",
      "2022-02-15 10:30:52,093 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 3/17 -- train_loss: 5.5003 \n",
      "2022-02-15 10:30:52,475 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 4/17 -- train_loss: 5.4951 \n",
      "2022-02-15 10:30:52,886 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 5/17 -- train_loss: 5.6670 \n",
      "2022-02-15 10:30:53,178 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 6/17 -- train_loss: 5.2603 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 10:30:53,469 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 7/17 -- train_loss: 5.3351 \n",
      "2022-02-15 10:30:53,762 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 8/17 -- train_loss: 5.2552 \n",
      "2022-02-15 10:30:54,086 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 9/17 -- train_loss: 5.1195 \n",
      "2022-02-15 10:30:54,423 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 10/17 -- train_loss: 5.6687 \n",
      "2022-02-15 10:30:54,762 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 11/17 -- train_loss: 5.2802 \n",
      "2022-02-15 10:30:55,099 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 12/17 -- train_loss: 5.2207 \n",
      "2022-02-15 10:30:55,431 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 13/17 -- train_loss: 5.6938 \n",
      "2022-02-15 10:30:55,758 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 14/17 -- train_loss: 5.2398 \n",
      "2022-02-15 10:30:56,097 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 15/17 -- train_loss: 5.4778 \n",
      "2022-02-15 10:30:56,440 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 16/17 -- train_loss: 5.1687 \n",
      "2022-02-15 10:30:56,788 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 4/1500, Iter: 17/17 -- train_loss: 5.4509 \n",
      "2022-02-15 10:30:56,790 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run resuming from iteration 0, epoch 3 until 4 epochs\n",
      "2022-02-15 10:34:34,458 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[4] Metrics -- val_mean_dice: 0.0113 \n",
      "2022-02-15 10:34:34,572 - ignite.engine.engine.DynUNetEvaluator - INFO - Key metric: val_mean_dice best value: 0.012682793661952019 at epoch: 2\n",
      "2022-02-15 10:34:34,580 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[4] Complete. Time taken: 00:03:36\n",
      "2022-02-15 10:34:34,581 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run complete. Time taken: 00:03:38\n",
      "2022-02-15 10:34:34,976 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-15 10:34:34,977 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[4] Complete. Time taken: 00:03:46\n",
      "2022-02-15 10:34:38,164 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 1/17 -- train_loss: 4.9432 \n",
      "2022-02-15 10:34:38,549 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 2/17 -- train_loss: 4.7799 \n",
      "2022-02-15 10:34:38,848 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 3/17 -- train_loss: 5.7802 \n",
      "2022-02-15 10:34:39,189 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 4/17 -- train_loss: 4.6457 \n",
      "2022-02-15 10:34:39,575 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 5/17 -- train_loss: 4.9953 \n",
      "2022-02-15 10:34:39,967 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 6/17 -- train_loss: 5.3820 \n",
      "2022-02-15 10:34:40,263 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 7/17 -- train_loss: 5.4198 \n",
      "2022-02-15 10:34:40,559 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 8/17 -- train_loss: 5.4054 \n",
      "2022-02-15 10:34:40,902 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 9/17 -- train_loss: 5.2817 \n",
      "2022-02-15 10:34:41,239 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 10/17 -- train_loss: 5.0149 \n",
      "2022-02-15 10:34:41,587 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 11/17 -- train_loss: 5.1456 \n",
      "2022-02-15 10:34:41,924 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 12/17 -- train_loss: 5.4812 \n",
      "2022-02-15 10:34:42,261 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 13/17 -- train_loss: 5.6350 \n",
      "2022-02-15 10:34:42,612 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 14/17 -- train_loss: 5.7634 \n",
      "2022-02-15 10:34:42,948 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 15/17 -- train_loss: 5.2701 \n",
      "2022-02-15 10:34:43,285 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 16/17 -- train_loss: 5.5171 \n",
      "2022-02-15 10:34:43,648 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 5/1500, Iter: 17/17 -- train_loss: 5.7541 \n",
      "2022-02-15 10:34:43,649 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-15 10:34:43,650 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[5] Complete. Time taken: 00:00:09\n",
      "2022-02-15 10:34:45,602 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 1/17 -- train_loss: 5.6909 \n",
      "2022-02-15 10:34:45,976 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 2/17 -- train_loss: 5.2753 \n",
      "2022-02-15 10:34:46,269 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 3/17 -- train_loss: 5.2506 \n",
      "2022-02-15 10:34:46,691 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 4/17 -- train_loss: 5.3404 \n",
      "2022-02-15 10:34:46,985 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 5/17 -- train_loss: 5.2657 \n",
      "2022-02-15 10:34:47,278 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 6/17 -- train_loss: 5.1346 \n",
      "2022-02-15 10:34:47,623 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 7/17 -- train_loss: 5.6188 \n",
      "2022-02-15 10:34:48,019 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 8/17 -- train_loss: 5.2035 \n",
      "2022-02-15 10:34:48,314 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 9/17 -- train_loss: 5.3511 \n",
      "2022-02-15 10:34:48,649 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 10/17 -- train_loss: 4.9303 \n",
      "2022-02-15 10:34:49,003 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 11/17 -- train_loss: 5.5148 \n",
      "2022-02-15 10:34:49,355 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 12/17 -- train_loss: 4.7762 \n",
      "2022-02-15 10:34:49,700 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 13/17 -- train_loss: 5.3500 \n",
      "2022-02-15 10:34:50,040 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 14/17 -- train_loss: 5.3331 \n",
      "2022-02-15 10:34:50,394 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 15/17 -- train_loss: 5.3262 \n",
      "2022-02-15 10:34:50,746 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 16/17 -- train_loss: 4.7722 \n",
      "2022-02-15 10:34:51,084 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 6/1500, Iter: 17/17 -- train_loss: 4.9459 \n",
      "2022-02-15 10:34:51,086 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run resuming from iteration 0, epoch 5 until 6 epochs\n",
      "2022-02-15 10:38:00,168 - ignite.engine.engine.DynUNetEvaluator - INFO - Got new best metric of val_mean_dice: 0.015126219019293785\n",
      "2022-02-15 10:38:00,190 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[6] Metrics -- val_mean_dice: 0.0151 \n",
      "2022-02-15 10:38:00,191 - ignite.engine.engine.DynUNetEvaluator - INFO - Key metric: val_mean_dice best value: 0.015126219019293785 at epoch: 6\n",
      "2022-02-15 10:38:00,602 - ignite.engine.engine.DynUNetEvaluator - INFO - Epoch[6] Complete. Time taken: 00:03:08\n",
      "2022-02-15 10:38:00,603 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run complete. Time taken: 00:03:10\n",
      "2022-02-15 10:38:00,980 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-15 10:38:00,982 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[6] Complete. Time taken: 00:03:17\n",
      "2022-02-15 10:38:03,746 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 1/17 -- train_loss: 5.2042 \n",
      "2022-02-15 10:38:04,172 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 2/17 -- train_loss: 4.9381 \n",
      "2022-02-15 10:38:04,520 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 3/17 -- train_loss: 5.0529 \n",
      "2022-02-15 10:38:04,858 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 4/17 -- train_loss: 4.9933 \n",
      "2022-02-15 10:38:05,208 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 5/17 -- train_loss: 5.1542 \n",
      "2022-02-15 10:38:05,668 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 6/17 -- train_loss: 5.2652 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 10:38:05,961 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 7/17 -- train_loss: 4.8212 \n",
      "2022-02-15 10:38:06,261 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 8/17 -- train_loss: 5.0833 \n",
      "2022-02-15 10:38:06,596 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 9/17 -- train_loss: 5.2953 \n",
      "2022-02-15 10:38:06,945 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 10/17 -- train_loss: 4.9202 \n",
      "2022-02-15 10:38:07,295 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 11/17 -- train_loss: 5.1325 \n",
      "2022-02-15 10:38:07,642 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 12/17 -- train_loss: 4.9771 \n",
      "2022-02-15 10:38:07,976 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 13/17 -- train_loss: 4.7850 \n",
      "2022-02-15 10:38:08,327 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 14/17 -- train_loss: 5.5079 \n",
      "2022-02-15 10:38:08,677 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 15/17 -- train_loss: 5.4126 \n",
      "2022-02-15 10:38:09,023 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 16/17 -- train_loss: 5.3799 \n",
      "2022-02-15 10:38:09,358 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 7/1500, Iter: 17/17 -- train_loss: 5.1323 \n",
      "2022-02-15 10:38:09,360 - ignite.engine.engine.DynUNetTrainer - INFO - Key metric: None best value: -1 at epoch: -1\n",
      "2022-02-15 10:38:09,361 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch[7] Complete. Time taken: 00:00:08\n",
      "2022-02-15 10:38:11,714 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 1/17 -- train_loss: 4.9789 \n",
      "2022-02-15 10:38:12,010 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 2/17 -- train_loss: 5.0882 \n",
      "2022-02-15 10:38:12,302 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 3/17 -- train_loss: 5.3753 \n",
      "2022-02-15 10:38:12,723 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 4/17 -- train_loss: 4.9196 \n",
      "2022-02-15 10:38:13,069 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 5/17 -- train_loss: 4.8331 \n",
      "2022-02-15 10:38:13,367 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 6/17 -- train_loss: 4.9265 \n",
      "2022-02-15 10:38:13,662 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 7/17 -- train_loss: 4.9962 \n",
      "2022-02-15 10:38:14,005 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 8/17 -- train_loss: 4.6388 \n",
      "2022-02-15 10:38:14,341 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 9/17 -- train_loss: 4.9034 \n",
      "2022-02-15 10:38:14,693 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 10/17 -- train_loss: 5.0534 \n",
      "2022-02-15 10:38:15,033 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 11/17 -- train_loss: 5.1586 \n",
      "2022-02-15 10:38:15,374 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 12/17 -- train_loss: 5.0169 \n",
      "2022-02-15 10:38:15,726 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 13/17 -- train_loss: 4.7707 \n",
      "2022-02-15 10:38:16,062 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 14/17 -- train_loss: 4.6761 \n",
      "2022-02-15 10:38:16,413 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 15/17 -- train_loss: 5.0983 \n",
      "2022-02-15 10:38:16,751 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 16/17 -- train_loss: 5.2121 \n",
      "2022-02-15 10:38:17,110 - ignite.engine.engine.DynUNetTrainer - INFO - Epoch: 8/1500, Iter: 17/17 -- train_loss: 4.5617 \n",
      "2022-02-15 10:38:17,111 - ignite.engine.engine.DynUNetEvaluator - INFO - Engine run resuming from iteration 0, epoch 7 until 8 epochs\n",
      "2022-02-15 10:39:51,893 - ignite.engine.engine.DynUNetEvaluator - ERROR - Engine run is terminating due to exception: \n",
      "2022-02-15 10:39:51,897 - ignite.engine.engine.DynUNetEvaluator - ERROR - Exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 744, in _internal_run\n",
      "    time_taken = self._run_once_on_dataset()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 834, in _run_once_on_dataset\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/data/kehyeong/project/MONAI_examples/dynunet_pipeline/evaluator.py\", line 146, in _iteration\n",
      "    predictions = _compute_pred()\n",
      "  File \"/data/kehyeong/project/MONAI_examples/dynunet_pipeline/evaluator.py\", line 137, in _compute_pred\n",
      "    pred += flip_pred\n",
      "KeyboardInterrupt\n",
      "2022-02-15 10:39:52,167 - ignite.engine.engine.DynUNetTrainer - ERROR - Engine run is terminating due to exception: \n",
      "2022-02-15 10:39:52,168 - ignite.engine.engine.DynUNetTrainer - ERROR - Exception: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 751, in _internal_run\n",
      "    self._fire_event(Events.EPOCH_COMPLETED)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 424, in _fire_event\n",
      "    func(*first, *(event_args + others), **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 237, in wrapper\n",
      "    return handler(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/handlers/validation_handler.py\", line 76, in __call__\n",
      "    self.validator.run(engine.state.epoch)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/engines/evaluator.py\", line 137, in run\n",
      "    super().run()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/engines/workflow.py\", line 275, in run\n",
      "    super().run(data=self.data_loader, max_epochs=self.state.max_epochs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 701, in run\n",
      "    return self._internal_run()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 774, in _internal_run\n",
      "    self._handle_exception(e)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 467, in _handle_exception\n",
      "    self._fire_event(Events.EXCEPTION_RAISED, e)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 424, in _fire_event\n",
      "    func(*first, *(event_args + others), **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/monai/handlers/stats_handler.py\", line 158, in exception_raised\n",
      "    raise e\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 744, in _internal_run\n",
      "    time_taken = self._run_once_on_dataset()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\", line 834, in _run_once_on_dataset\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"/data/kehyeong/project/MONAI_examples/dynunet_pipeline/evaluator.py\", line 146, in _iteration\n",
      "    predictions = _compute_pred()\n",
      "  File \"/data/kehyeong/project/MONAI_examples/dynunet_pipeline/evaluator.py\", line 137, in _compute_pred\n",
      "    pred += flip_pred\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22273/3254222111.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/engines/trainer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \"\"\"\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_train_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/engines/workflow.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \"\"\"\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_handlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_fire_event\u001b[0;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mothers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/handlers/stats_handler.py\u001b[0m in \u001b[0;36mexception_raised\u001b[0;34m(self, _engine, e)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \"\"\"\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_default_epoch_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    749\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTERMINATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mhandlers_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0;31m# update time wrt handlers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_fire_event\u001b[0;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mothers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_attrib_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# setup input handler as parent to make has_event_handler work\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/handlers/validation_handler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"please set validator in __init__() or call `set_validator()` before training.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/engines/evaluator.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, global_epoch)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_epoch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_validation_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/engines/workflow.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \"\"\"\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_handlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_fire_event\u001b[0;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mothers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/monai/handlers/stats_handler.py\u001b[0m in \u001b[0;36mexception_raised\u001b[0;34m(self, _engine, e)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \"\"\"\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_default_epoch_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/kehyeong/project/MONAI_examples/dynunet_pipeline/evaluator.py\u001b[0m in \u001b[0;36m_iteration\u001b[0;34m(self, engine, batchdata)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compute_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compute_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/kehyeong/project/MONAI_examples/dynunet_pipeline/evaluator.py\u001b[0m in \u001b[0;36m_compute_pred\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mflip_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflip_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0;32mdel\u001b[0m \u001b[0mflip_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0mpred\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mflip_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                     \u001b[0;32mdel\u001b[0m \u001b[0mflip_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0mct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# produce the network\n",
    "val_output_dir = \"./runs_fold{}_{}/\".format(1, expr_name)\n",
    "checkpoint = checkpoint\n",
    "net = get_network_ke(properties, patch_size, spacing, deep_supr_num, \n",
    "                     val_output_dir, checkpoint)\n",
    "net = net.to(device)\n",
    "print(net)\n",
    "\n",
    "if multi_gpu_flag:\n",
    "    net = DistributedDataParallel(module=net, device_ids=[device])\n",
    "# net = DistributedDataParallel(module=net, device_ids=[device])\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    net.parameters(),\n",
    "    lr=learning_rate,\n",
    "    momentum=0.99,\n",
    "    weight_decay=3e-5,\n",
    "    nesterov=True,\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer, lr_lambda=lambda epoch: (1 - epoch / max_epochs) ** 0.9\n",
    ")\n",
    "# produce evaluator\n",
    "val_handlers = [\n",
    "    StatsHandler(output_transform=lambda x: None),\n",
    "    CheckpointSaver(\n",
    "        save_dir=val_output_dir, save_dict={\"net\": net}, save_key_metric=True\n",
    "    ),\n",
    "]\n",
    "\n",
    "evaluator = DynUNetEvaluator(\n",
    "    device=device,\n",
    "    val_data_loader=val_loader,\n",
    "    network=net,\n",
    "    num_classes=len(properties[\"labels\"]),\n",
    "    inferer=SlidingWindowInferer(\n",
    "        roi_size=patch_size,\n",
    "        sw_batch_size=sw_batch_size,\n",
    "        overlap=eval_overlap,\n",
    "        mode=window_mode,\n",
    "    ),\n",
    "    postprocessing=None,\n",
    "    key_val_metric={\n",
    "        \"val_mean_dice\": MeanDice(\n",
    "            include_background=False,\n",
    "            output_transform=from_engine([\"pred\", \"label\"]),\n",
    "        )\n",
    "    },\n",
    "    val_handlers=val_handlers,\n",
    "    amp=amp_flag,\n",
    "    tta_val=tta_val,\n",
    ")\n",
    "\n",
    "# produce trainer\n",
    "loss = DiceCELoss(to_onehot_y=True, softmax=True, batch=batch_dice)\n",
    "train_handlers = []\n",
    "if lr_decay_flag:\n",
    "    train_handlers += [LrScheduleHandler(lr_scheduler=scheduler, print_lr=True)]\n",
    "\n",
    "train_handlers += [\n",
    "    ValidationHandler(validator=evaluator, interval=interval, epoch_level=True),\n",
    "    StatsHandler(\n",
    "#         tag_name=\"train_loss\", output_transform=from_engine([\"loss\"], first=True)\n",
    "        tag_name=\"train_loss\", output_transform=lambda x: x[\"loss\"]\n",
    "    ),\n",
    "]\n",
    "\n",
    "trainer = DynUNetTrainer(\n",
    "    device=device,\n",
    "    max_epochs=max_epochs,\n",
    "    train_data_loader=train_loader,\n",
    "    network=net,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss,\n",
    "    inferer=SimpleInferer(),\n",
    "    postprocessing=None,\n",
    "    key_train_metric=None,\n",
    "    train_handlers=train_handlers,\n",
    "    amp=amp_flag,\n",
    ")\n",
    "\n",
    "if local_rank > 0:\n",
    "    evaluator.logger.setLevel(logging.WARNING)\n",
    "    trainer.logger.setLevel(logging.WARNING)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "formatter = logging.Formatter(\n",
    "    \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Setup file handler\n",
    "fhandler = logging.FileHandler(log_file)\n",
    "fhandler.setLevel(logging.INFO)\n",
    "fhandler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(fhandler)\n",
    "\n",
    "chandler = logging.StreamHandler()\n",
    "chandler.setLevel(logging.INFO)\n",
    "chandler.setFormatter(formatter)\n",
    "logger.addHandler(chandler)\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53973f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['image', 'label', 'image_meta_dict', 'label_meta_dict', 'image_transforms', 'label_transforms', 'resample_flag', 'anisotrophy_flag'])\n",
      "image, label shape\n",
      "torch.Size([12, 1, 64, 64, 64])\n",
      "torch.Size([12, 1, 64, 64, 64])\n",
      "torch.float32\n",
      "torch.uint8\n",
      "[  0   1   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  20  21  23  24  25  26  27  28  29  30  31  33  34  36  37  39  40  41\n",
      "  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59\n",
      "  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  78\n",
      "  79  80  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97\n",
      "  98  99 100 101 102 103 104 105 106 107 108]\n"
     ]
    }
   ],
   "source": [
    "test_data = first(train_loader)\n",
    "print(test_data.keys())\n",
    "print('image, label shape')\n",
    "print(test_data['image'].shape)\n",
    "print(test_data['label'].shape)\n",
    "print(test_data['image'].dtype)\n",
    "print(test_data['label'].dtype)\n",
    "print(np.unique(test_data['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7ed7ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3145728, 21233664)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['label'].numel(), 24*96*96*96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc3f2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d098d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 1, 64, 64, 64]) torch.Size([12, 1, 64, 64, 64])\n",
      "image shape: torch.Size([64, 64, 64]), label shape: torch.Size([64, 64, 64])\n",
      "image dtype: torch.float32, label dtype: torch.uint8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0  13  16  21  23  24  26  27  31  34  36  40  80  82  83  84  85  86\n",
      "  88  90  91  92  96  97  98  99 100 104 105 106 107 108]\n"
     ]
    }
   ],
   "source": [
    "H=60\n",
    "\n",
    "test_data = first(train_loader)\n",
    "image, label = (test_data[\"image\"][0][0], test_data[\"label\"][0][0])\n",
    "print(test_data['image'].shape, test_data['label'].shape)\n",
    "print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
    "print(f\"image dtype: {image.dtype}, label dtype: {label.dtype}\")\n",
    "# plot the slice [:, :, 80]\n",
    "plt.figure(\"check\", (15, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"image\")\n",
    "plt.imshow(image[:, :, H], cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"label\")\n",
    "plt.imshow(label[:, :, H])\n",
    "# plt.subplot(1, 4, 3)\n",
    "# plt.title(\"brain\")\n",
    "# plt.imshow(brain[:, :, H], cmap=\"gray\")\n",
    "# plt.subplot(1, 4, 4)\n",
    "# plt.title(\"mask\")\n",
    "# plt.imshow(mask[:, :, H])\n",
    "plt.show()\n",
    "\n",
    "print(np.unique(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb19a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(label), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b861dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ecbb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a4799",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = np.where(image == -0, image, image)\n",
    "new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d642d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_min, pixel_max = image.min().item(), image.max().item()\n",
    "print(pixel_min, pixel_max)\n",
    "histogram, bin_edges = np.histogram(image, bins=256, range=(pixel_min, pixel_max))\n",
    "plt.figure()\n",
    "plt.title(\"Grayscale Histogram\")\n",
    "plt.xlabel(\"grayscale value\")\n",
    "plt.ylabel(\"pixel count\")\n",
    "plt.xlim([pixel_min, pixel_max])  # <- named arguments do not work here\n",
    "\n",
    "plt.plot(bin_edges[0:-1], histogram)  # <- or here\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba77b7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7417c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = np.where(image < 0, 2, image)\n",
    "new_img.shape\n",
    "plt.figure(\"check\", (15, 10))\n",
    "plt.title(\"image\")\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(new_img[:, :, H], cmap=\"gray\")\n",
    "# plt.imshow(new_img[:, :, H])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(image[:, :, H], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28996d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img[:, :, H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadfc490",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0c5688",
   "metadata": {},
   "outputs": [],
   "source": [
    "label[:, :, H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba0c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image[:, :, H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81d5bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1826a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['image_meta_dict']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
