{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a105b425",
   "metadata": {},
   "source": [
    "## Inference 4D dynunet pipeline with NeuroI ROI dataset\n",
    "* `inference.py` 를 바탕으로 테스트\n",
    "* Brain image + mask image -> 4D modalities\n",
    "* in_channels: 4, out_channels:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c337c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from monai.inferers import SlidingWindowInferer\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "# from create_dataset import get_data\n",
    "from create_network import get_network_ke\n",
    "from inferrer import DynUNetInferrer\n",
    "# from task_params import patch_size, task_name\n",
    "from monai.utils import first\n",
    "from config import get_config\n",
    "from dataset_roi_4d import get_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1603256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"/data/kehyeong/project/MONAI_examples/dynunet_pipeline/config_roi_earlystop_toy_220209.yaml\"\n",
    "checkpoint = \"/data/train/running/l/model_roi_try1_220217/models/net_key_metric=0.3331.pt\"\n",
    "test_dataset = \"/work/NeuroI-models/ke-monai/data/roi/dataset_test_roi_toy2.csv\"\n",
    "\n",
    "infer_output_dir = \"./runs_inference\"\n",
    "\n",
    "\n",
    "# fold = 0\n",
    "# root_dir = \"/workspace/data/medical/\"\n",
    "# expr_name = \"expr\"  # test folder suffix\n",
    "# datalist_path = \"config/\"\n",
    "train_num_workers = 4   # the num_workers parameter of training dataloader.\n",
    "val_num_workers = 1\n",
    "interval = 5   # the validation interval under epoch level.\n",
    "eval_overlap = 0.5     #  the overlap parameter of SlidingWindowInferer.\n",
    "\n",
    "spacing = [1.0, 1.0, 1.0]\n",
    "deep_supr_num = 3\n",
    "window_mode = \"gaussian\"     # the mode parameter for SlidingWindowInferer.\n",
    "num_samples = 3.          # the num_samples parameter of RandCropByPosNegLabeld.\n",
    "pos_sample_num = 1\n",
    "neg_sample_num = 1\n",
    "cache_rate = 1.0\n",
    "amp = False\n",
    "tta_val = False\n",
    "multi_gpu = False\n",
    "local_rank = 0\n",
    "\n",
    "\n",
    "\n",
    "# task_id = args.task_id\n",
    "# checkpoint = args.checkpoint\n",
    "# val_output_dir = \"./runs_{}_fold{}_{}/\".format(\n",
    "#     args.task_id, args.fold, args.expr_name\n",
    "# )\n",
    "# sw_batch_size = args.sw_batch_size\n",
    "# infer_output_dir = os.path.join(val_output_dir, task_name[task_id])\n",
    "# window_mode = args.window_mode\n",
    "# eval_overlap = args.eval_overlap\n",
    "# amp = args.amp\n",
    "# tta_val = args.tta_val\n",
    "# multi_gpu_flag = args.multi_gpu\n",
    "# local_rank = args.local_rank\n",
    "\n",
    "\n",
    "# task_id = args.task_id\n",
    "# checkpoint = args.checkpoint\n",
    "# val_output_dir = \"./runs_{}_fold{}_{}/\".format(\n",
    "#     args.task_id, args.fold, args.expr_name\n",
    "# )\n",
    "# sw_batch_size = args.sw_batch_size\n",
    "# infer_output_dir = os.path.join(val_output_dir, task_name[task_id])\n",
    "\n",
    "# window_mode = args.window_mode\n",
    "# eval_overlap = args.eval_overlap\n",
    "# amp = args.amp\n",
    "# tta_val = args.tta_val\n",
    "multi_gpu_flag = multi_gpu\n",
    "# local_rank = args.local_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82059f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0454 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0454 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0303 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0303 01_d\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0197 00_0\n",
      "{dir}/s_{id}_{aid}_b.nii.gz /data/train/running/l/input_augmented SU0197 01_d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|███████████████████████████████████████████████████████████████████████████| 6/6 [00:29<00:00,  4.96s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "config = get_config(config)\n",
    "image_file_path = config[\"image_file_path\"]\n",
    "mask_file_path = config[\"mask_file_path\"]\n",
    "# val_batch_size = config[\"val\"][\"batch_size\"]\n",
    "val_num_workers = config[\"val\"][\"num_workers\"]\n",
    "data_dir = config[\"data_dir\"]\n",
    "num_classes = config[\"num_classes\"]\n",
    "patch_size = config[\"patch_size\"]\n",
    "sw_batch_size = config[\"val\"][\"batch_size\"]      # the sw_batch_size parameter of SlidingWindowInferer.  # 학습 시켰던 파라미터로 고정\n",
    "\n",
    "# infer_output_dir = data_dir\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "if not os.path.exists(infer_output_dir):\n",
    "    os.makedirs(infer_output_dir)\n",
    "\n",
    "if multi_gpu_flag:\n",
    "    dist.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "    device = torch.device(f\"cuda:{local_rank}\")\n",
    "    torch.cuda.set_device(device)\n",
    "else:\n",
    "#     device = torch.device(\"cuda\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "test_loader = get_test_loader(\n",
    "    data_dir=data_dir,\n",
    "    id_file=test_dataset,\n",
    "    image_file_pattern=image_file_path,\n",
    "    mask_file_pattern=mask_file_path,\n",
    "    batch_size=1,\n",
    "    num_workers=val_num_workers,\n",
    "    multi_gpu_flag=multi_gpu_flag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32af0b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['image', 'mask', 'image_meta_dict', 'mask_meta_dict', 'image_transforms', 'mask_transforms', 'original_shape', 'bbox', 'crop_shape', 'resample_flag', 'anisotrophy_flag'])\n",
      "image shape: torch.Size([1, 2, 134, 152, 132])\n",
      "image dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "test_data = first(test_loader)\n",
    "print(test_data.keys())\n",
    "print(\"image shape:\", test_data['image'].shape)\n",
    "print(\"image dtype:\", test_data['image'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ed4172b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 109)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties = {\n",
    "    'modality': [0,1],\n",
    "    'labels': np.arange(num_classes)\n",
    "}\n",
    "n_class = len(properties[\"labels\"])\n",
    "in_channels = len(properties[\"modality\"])\n",
    "in_channels, n_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cc43733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained checkpoint: /data/train/running/l/model_roi_try1_220217/models/net_key_metric=0.3331.pt loaded\n",
      "Loading nnUNET Done!!!\n",
      "Loading nnUNET to GPU devices Done!!!\n",
      "DynUNet(\n",
      "  (input_block): UnetBasicBlock(\n",
      "    (conv1): Convolution(\n",
      "      (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "    (conv2): Convolution(\n",
      "      (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "    (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  )\n",
      "  (downsamples): ModuleList(\n",
      "    (0): UnetBasicBlock(\n",
      "      (conv1): Convolution(\n",
      "        (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (conv2): Convolution(\n",
      "        (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (1): UnetBasicBlock(\n",
      "      (conv1): Convolution(\n",
      "        (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (conv2): Convolution(\n",
      "        (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (2): UnetBasicBlock(\n",
      "      (conv1): Convolution(\n",
      "        (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (conv2): Convolution(\n",
      "        (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "  )\n",
      "  (bottleneck): UnetBasicBlock(\n",
      "    (conv1): Convolution(\n",
      "      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "    (conv2): Convolution(\n",
      "      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    )\n",
      "    (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (norm1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (norm2): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  )\n",
      "  (upsamples): ModuleList(\n",
      "    (0): UnetUpBlock(\n",
      "      (transp_conv): Convolution(\n",
      "        (conv): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "      )\n",
      "      (conv_block): UnetBasicBlock(\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (1): UnetUpBlock(\n",
      "      (transp_conv): Convolution(\n",
      "        (conv): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "      )\n",
      "      (conv_block): UnetBasicBlock(\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (2): UnetUpBlock(\n",
      "      (transp_conv): Convolution(\n",
      "        (conv): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "      )\n",
      "      (conv_block): UnetBasicBlock(\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (3): UnetUpBlock(\n",
      "      (transp_conv): Convolution(\n",
      "        (conv): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "      )\n",
      "      (conv_block): UnetBasicBlock(\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output_block): UnetOutBlock(\n",
      "    (conv): Convolution(\n",
      "      (conv): Conv3d(32, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "    )\n",
      "  )\n",
      "  (deep_supervision_heads): ModuleList(\n",
      "    (0): UnetOutBlock(\n",
      "      (conv): Convolution(\n",
      "        (conv): Conv3d(64, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): UnetOutBlock(\n",
      "      (conv): Convolution(\n",
      "        (conv): Conv3d(128, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): UnetOutBlock(\n",
      "      (conv): Convolution(\n",
      "        (conv): Conv3d(256, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (skip_layers): DynUNetSkipLayer(\n",
      "    (downsample): UnetBasicBlock(\n",
      "      (conv1): Convolution(\n",
      "        (conv): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (conv2): Convolution(\n",
      "        (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      )\n",
      "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (next_layer): DynUNetSkipLayer(\n",
      "      (downsample): UnetBasicBlock(\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "      (next_layer): DynUNetSkipLayer(\n",
      "        (downsample): UnetBasicBlock(\n",
      "          (conv1): Convolution(\n",
      "            (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "          )\n",
      "          (conv2): Convolution(\n",
      "            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          )\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "        (next_layer): DynUNetSkipLayer(\n",
      "          (downsample): UnetBasicBlock(\n",
      "            (conv1): Convolution(\n",
      "              (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "            )\n",
      "            (conv2): Convolution(\n",
      "              (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            )\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          )\n",
      "          (next_layer): UnetBasicBlock(\n",
      "            (conv1): Convolution(\n",
      "              (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "            )\n",
      "            (conv2): Convolution(\n",
      "              (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            )\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (norm1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (norm2): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          )\n",
      "          (upsample): UnetUpBlock(\n",
      "            (transp_conv): Convolution(\n",
      "              (conv): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "            )\n",
      "            (conv_block): UnetBasicBlock(\n",
      "              (conv1): Convolution(\n",
      "                (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              )\n",
      "              (conv2): Convolution(\n",
      "                (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "              )\n",
      "              (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "              (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            )\n",
      "          )\n",
      "          (super_head): UnetOutBlock(\n",
      "            (conv): Convolution(\n",
      "              (conv): Conv3d(256, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (upsample): UnetUpBlock(\n",
      "          (transp_conv): Convolution(\n",
      "            (conv): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "          )\n",
      "          (conv_block): UnetBasicBlock(\n",
      "            (conv1): Convolution(\n",
      "              (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            )\n",
      "            (conv2): Convolution(\n",
      "              (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "            )\n",
      "            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          )\n",
      "        )\n",
      "        (super_head): UnetOutBlock(\n",
      "          (conv): Convolution(\n",
      "            (conv): Conv3d(128, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (upsample): UnetUpBlock(\n",
      "        (transp_conv): Convolution(\n",
      "          (conv): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "        )\n",
      "        (conv_block): UnetBasicBlock(\n",
      "          (conv1): Convolution(\n",
      "            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          )\n",
      "          (conv2): Convolution(\n",
      "            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          )\n",
      "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (super_head): UnetOutBlock(\n",
      "        (conv): Convolution(\n",
      "          (conv): Conv3d(64, 109, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (upsample): UnetUpBlock(\n",
      "      (transp_conv): Convolution(\n",
      "        (conv): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
      "      )\n",
      "      (conv_block): UnetBasicBlock(\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        )\n",
      "        (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (norm1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (norm2): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# produce the network\n",
    "val_output_dir = \"./runs_{}/\".format(\"inference\")\n",
    "net = get_network_ke(properties, patch_size, spacing, deep_supr_num, \n",
    "                     val_output_dir, checkpoint)    # val_output_dir은 삭제 필요. 안씀\n",
    "print('Loading nnUNET Done!!!')\n",
    "net = net.to(device)\n",
    "print('Loading nnUNET to GPU devices Done!!!')\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cf3463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if multi_gpu_flag:\n",
    "    net = DistributedDataParallel(\n",
    "        module=net, device_ids=[device], find_unused_parameters=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10be8962",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "inferrer = DynUNetInferrer(\n",
    "    device=device,\n",
    "    val_data_loader=test_loader,\n",
    "    network=net,\n",
    "    output_dir=infer_output_dir,\n",
    "    num_classes=len(properties[\"labels\"]),\n",
    "    inferer=SlidingWindowInferer(\n",
    "        roi_size=patch_size,\n",
    "        sw_batch_size=sw_batch_size,\n",
    "        overlap=eval_overlap,\n",
    "        mode=window_mode,\n",
    "    ),\n",
    "    amp=amp,\n",
    "    tta_val=tta_val,\n",
    ")\n",
    "\n",
    "# inferrer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81e2756b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save s_SU0454_00_0_b.nii.gz with shape: (186, 230, 230), mean values: 3.6415143199788607\n",
      "save s_SU0454_01_d_b.nii.gz with shape: (186, 230, 230), mean values: 4.753923918125089\n",
      "save s_SU0303_00_0_b.nii.gz with shape: (186, 230, 230), mean values: 5.029365713356506\n",
      "save s_SU0303_01_d_b.nii.gz with shape: (186, 230, 230), mean values: 4.6382436937211615\n",
      "save s_SU0197_00_0_b.nii.gz with shape: (186, 230, 230), mean values: 3.925215053763441\n",
      "save s_SU0197_01_d_b.nii.gz with shape: (186, 230, 230), mean values: 3.6964137040876475\n"
     ]
    }
   ],
   "source": [
    "inferrer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5686655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1716295a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1fc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af9f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_id = \"01\"\n",
    "# fold = 0\n",
    "# root_dir = \"/data/kehyeong/project/MONAI_examples/data/brats/\"\n",
    "# datalist_path =\"config/\"\n",
    "\n",
    "config = \"/data/kehyeong/project/MONAI_examples/dynunet_pipeline/config_roi_earlystop_toy_220209.yaml\"\n",
    "train_dataset = \"/work/NeuroI-models/ke-monai/data/roi/dataset_train_roi_toy2.csv\"\n",
    "val_dataset = \"/work/NeuroI-models/ke-monai/data/roi/dataset_val_roi_toy2.csv\"\n",
    "log_file = \"/data/train/running/l/model_roi_toy_220210/train.log\"\n",
    "checkpoint = None\n",
    "\n",
    "## [아래 config에서 불러 오는 params]\n",
    "# max_epochs = 1500\n",
    "# num_samples = 4\n",
    "# train_num_workers = 4\n",
    "# val_num_workers = 2\n",
    "\n",
    "patch_size = [64, 64, 64] # [128, 128, 128]    #[96, 96, 96]\n",
    "learning_rate = 1.0e-3    # working: 1e-1\n",
    "interval = 2\n",
    "multi_gpu = False  # True\n",
    "local_rank = 0\n",
    "\n",
    "## [Dafault setting] - 변경 필요 없음\n",
    "window_mode = \"gaussian\"  # \"constant\", \"gaussian\"\n",
    "eval_overlap = 0.5\n",
    "tta_val = True\n",
    "batch_dice = False\n",
    "lr_decay_flag = False\n",
    "spacing = [1.0, 1.0, 1.0]\n",
    "deep_supr_num = 3\n",
    "expr_name = \"baseline\"\n",
    "####################################\n",
    "\n",
    "\n",
    "# pos_sample_num = 1\n",
    "# neg_sample_num = 1\n",
    "# cache_rate = 1.0\n",
    "\n",
    "\n",
    "# mode = \"train\"\n",
    "# checkpoint = None\n",
    "# amp = False\n",
    "# lr_decay = False\n",
    "# tta_val = True\n",
    "# batch_dice = False\n",
    "# determinism_flag = False\n",
    "# determinism_seed = 0\n",
    "# expr_name = \"baseline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf83b130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from config import get_config\n",
    "from dataset_roi_4d import get_train_loader, get_val_loader   # 4D modality test\n",
    "import monai\n",
    "\n",
    "local_rank = local_rank\n",
    "log_file = log_file\n",
    "train_dataset = train_dataset\n",
    "val_dataset = val_dataset\n",
    "checkpoint = checkpoint\n",
    "\n",
    "multi_gpu_flag = multi_gpu\n",
    "config = get_config(config)\n",
    "data_dir = config[\"data_dir\"]\n",
    "image_file_path = config[\"image_file_path\"]\n",
    "label_file_path = config[\"label_file_path\"]\n",
    "# brain_file_path = config[\"brain_file_path\"]\n",
    "mask_file_path = config[\"mask_file_path\"]\n",
    "random_seed = config[\"random_seed\"]\n",
    "max_epochs = config[\"train\"][\"max_epoches\"]\n",
    "num_classes = config[\"num_classes\"]\n",
    "\n",
    "# patch_size = tuple(config[\"patch_size\"])\n",
    "lr = config[\"train\"][\"lr\"]\n",
    "train_batch_size = config[\"train\"][\"batch_size\"]\n",
    "train_num_samples = config[\"train\"][\"num_samples\"]\n",
    "train_num_workers = config[\"train\"][\"num_workers\"]\n",
    "# val_interval = config[\"train\"][\"val_interval\"]\n",
    "val_batch_size = config[\"val\"][\"batch_size\"]\n",
    "sw_batch_size = val_batch_size    # for evaluator\n",
    "val_num_workers = config[\"val\"][\"num_workers\"]\n",
    "log_dir = config[\"log_dir\"]\n",
    "model_dir = config[\"model_dir\"]\n",
    "mlflow_dir = os.path.join(log_dir, \"mlruns\")\n",
    "\n",
    "amp_flag = (True if monai.utils.get_torch_version_tuple() >= (1, 6) else False,)\n",
    "\n",
    "monai.utils.set_determinism(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5,6\"\n",
    "\n",
    "if multi_gpu_flag:\n",
    "    dist.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "    device = torch.device(f\"cuda:{local_rank}\")\n",
    "    torch.cuda.set_device(device)\n",
    "else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "#\n",
    "# data loader\n",
    "#\n",
    "train_loader = get_train_loader(\n",
    "    data_dir=data_dir,\n",
    "    id_file=train_dataset,\n",
    "    image_file_pattern=image_file_path,\n",
    "    label_file_pattern=label_file_path,\n",
    "    # brain_file_pattern=brain_file_path,\n",
    "    mask_file_pattern=mask_file_path,\n",
    "    batch_size=train_batch_size,\n",
    "    patch_size=patch_size,\n",
    "    num_samples=train_num_samples,\n",
    "    num_workers=train_num_workers,\n",
    "    multi_gpu_flag=multi_gpu_flag\n",
    ")\n",
    "val_loader = get_val_loader(\n",
    "    data_dir=data_dir,\n",
    "    id_file=val_dataset,\n",
    "    image_file_pattern=image_file_path,\n",
    "    label_file_pattern=label_file_path,\n",
    "    # brain_file_pattern=brain_file_path,\n",
    "    mask_file_pattern=mask_file_path,\n",
    "    batch_size=val_batch_size,\n",
    "    num_workers=val_num_workers,\n",
    "    multi_gpu_flag=multi_gpu_flag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73edccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be28fc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = first(train_loader)\n",
    "print(f\"배치 수: num_sample({train_num_samples}) x batch_num({train_batch_size}) -> {train_num_samples*train_batch_size}\")\n",
    "print(test_data.keys())\n",
    "print(\"image shape:\", test_data['image'].shape)\n",
    "print(\"label shape:\", test_data['label'].shape)\n",
    "print(\"image dtype:\", test_data['image'].dtype)\n",
    "print(\"label dtype:\", test_data['label'].dtype)\n",
    "print(\"1번 배치의 유니크한 라벨 리스트:\", np.unique(test_data['label']))\n",
    "total_labels = np.unique(test_data['label'])\n",
    "print(f'1번 배치의 유니크한 라벨 class 수: {len(total_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1a7942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 1번의 전체 라벨의 shape과 유니크한 라벨 수 조사.\n",
    "for each in test_data['label']:\n",
    "    print(each.shape)\n",
    "    total_labels = np.unique(each)\n",
    "    print(f'class 수 {len(total_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0396624",
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = {\n",
    "    'modality': [0,1],\n",
    "    'labels': np.arange(num_classes)\n",
    "}\n",
    "n_class = len(properties[\"labels\"])\n",
    "in_channels = len(properties[\"modality\"])\n",
    "in_channels, n_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f1d38e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# produce the network\n",
    "val_output_dir = \"./runs_fold{}_{}/\".format(1, expr_name)\n",
    "checkpoint = checkpoint\n",
    "net = get_network_ke(properties, patch_size, spacing, deep_supr_num, \n",
    "                     val_output_dir, checkpoint)\n",
    "net = net.to(device)\n",
    "print(net)\n",
    "\n",
    "if multi_gpu_flag:\n",
    "    net = DistributedDataParallel(module=net, device_ids=[device])\n",
    "# net = DistributedDataParallel(module=net, device_ids=[device])\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    net.parameters(),\n",
    "    lr=learning_rate,\n",
    "    momentum=0.99,\n",
    "    weight_decay=3e-5,\n",
    "    nesterov=True,\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer, lr_lambda=lambda epoch: (1 - epoch / max_epochs) ** 0.9\n",
    ")\n",
    "# produce evaluator\n",
    "val_handlers = [\n",
    "    StatsHandler(output_transform=lambda x: None),\n",
    "    CheckpointSaver(\n",
    "        save_dir=val_output_dir, save_dict={\"net\": net}, save_key_metric=True\n",
    "    ),\n",
    "]\n",
    "\n",
    "evaluator = DynUNetEvaluator(\n",
    "    device=device,\n",
    "    val_data_loader=val_loader,\n",
    "    network=net,\n",
    "    num_classes=len(properties[\"labels\"]),\n",
    "    inferer=SlidingWindowInferer(\n",
    "        roi_size=patch_size,\n",
    "        sw_batch_size=sw_batch_size,\n",
    "        overlap=eval_overlap,\n",
    "        mode=window_mode,\n",
    "    ),\n",
    "    postprocessing=None,\n",
    "    key_val_metric={\n",
    "        \"val_mean_dice\": MeanDice(\n",
    "            include_background=False,\n",
    "            output_transform=from_engine([\"pred\", \"label\"]),\n",
    "        )\n",
    "    },\n",
    "    val_handlers=val_handlers,\n",
    "    amp=amp_flag,\n",
    "    tta_val=tta_val,\n",
    ")\n",
    "\n",
    "# produce trainer\n",
    "loss = DiceCELoss(to_onehot_y=True, softmax=True, batch=batch_dice)\n",
    "train_handlers = []\n",
    "if lr_decay_flag:\n",
    "    train_handlers += [LrScheduleHandler(lr_scheduler=scheduler, print_lr=True)]\n",
    "\n",
    "train_handlers += [\n",
    "    ValidationHandler(validator=evaluator, interval=interval, epoch_level=True),\n",
    "    StatsHandler(\n",
    "#         tag_name=\"train_loss\", output_transform=from_engine([\"loss\"], first=True)\n",
    "        tag_name=\"train_loss\", output_transform=lambda x: x[\"loss\"]\n",
    "    ),\n",
    "]\n",
    "\n",
    "trainer = DynUNetTrainer(\n",
    "    device=device,\n",
    "    max_epochs=max_epochs,\n",
    "    train_data_loader=train_loader,\n",
    "    network=net,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss,\n",
    "    inferer=SimpleInferer(),\n",
    "    postprocessing=None,\n",
    "    key_train_metric=None,\n",
    "    train_handlers=train_handlers,\n",
    "    amp=amp_flag,\n",
    ")\n",
    "\n",
    "if local_rank > 0:\n",
    "    evaluator.logger.setLevel(logging.WARNING)\n",
    "    trainer.logger.setLevel(logging.WARNING)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "formatter = logging.Formatter(\n",
    "    \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Setup file handler\n",
    "fhandler = logging.FileHandler(log_file)\n",
    "fhandler.setLevel(logging.INFO)\n",
    "fhandler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(fhandler)\n",
    "\n",
    "chandler = logging.StreamHandler()\n",
    "chandler.setLevel(logging.INFO)\n",
    "chandler.setFormatter(formatter)\n",
    "logger.addHandler(chandler)\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53973f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = first(train_loader)\n",
    "print(test_data.keys())\n",
    "print('image, label shape')\n",
    "print(test_data['image'].shape)\n",
    "print(test_data['label'].shape)\n",
    "print(test_data['image'].dtype)\n",
    "print(test_data['label'].dtype)\n",
    "print(np.unique(test_data['label']))\n",
    "print(len(np.unique(test_data['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ed7ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['label'].numel(), 24*96*96*96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3f2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d098d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "H=60\n",
    "\n",
    "test_data = first(train_loader)\n",
    "image, label = (test_data[\"image\"][0][0], test_data[\"label\"][0][0])\n",
    "print(test_data['image'].shape, test_data['label'].shape)\n",
    "print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
    "print(f\"image dtype: {image.dtype}, label dtype: {label.dtype}\")\n",
    "# plot the slice [:, :, 80]\n",
    "plt.figure(\"check\", (15, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"image\")\n",
    "plt.imshow(image[:, :, H], cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"label\")\n",
    "plt.imshow(label[:, :, H])\n",
    "# plt.subplot(1, 4, 3)\n",
    "# plt.title(\"brain\")\n",
    "# plt.imshow(brain[:, :, H], cmap=\"gray\")\n",
    "# plt.subplot(1, 4, 4)\n",
    "# plt.title(\"mask\")\n",
    "# plt.imshow(mask[:, :, H])\n",
    "plt.show()\n",
    "\n",
    "print(np.unique(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb19a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(label), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b861dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d642d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_min, pixel_max = image.min().item(), image.max().item()\n",
    "print(pixel_min, pixel_max)\n",
    "histogram, bin_edges = np.histogram(image, bins=256, range=(pixel_min, pixel_max))\n",
    "plt.figure()\n",
    "plt.title(\"Grayscale Histogram\")\n",
    "plt.xlabel(\"grayscale value\")\n",
    "plt.ylabel(\"pixel count\")\n",
    "plt.xlim([pixel_min, pixel_max])  # <- named arguments do not work here\n",
    "\n",
    "plt.plot(bin_edges[0:-1], histogram)  # <- or here\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba77b7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7417c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = np.where(image < 0, 2, image)\n",
    "new_img.shape\n",
    "plt.figure(\"check\", (15, 10))\n",
    "plt.title(\"image\")\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(new_img[:, :, H], cmap=\"gray\")\n",
    "# plt.imshow(new_img[:, :, H])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(image[:, :, H], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28996d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img[:, :, H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadfc490",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0c5688",
   "metadata": {},
   "outputs": [],
   "source": [
    "label[:, :, H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba0c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image[:, :, H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81d5bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1826a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['image_meta_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4157bd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
