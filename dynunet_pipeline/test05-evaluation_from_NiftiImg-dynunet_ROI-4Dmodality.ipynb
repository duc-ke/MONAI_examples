{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e18e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from monai.handlers import (\n",
    "    MeanDice,\n",
    "    from_engine,\n",
    ")\n",
    "from config import get_config\n",
    "from monai.utils import first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1e8a788",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"/data/kehyeong/project/MONAI_examples/dynunet_pipeline/config_evalImg_toy_220317.yaml\"\n",
    "# checkpoint = \"/data/train/running/l/model_roi_try1_220217/models/net_key_metric=0.3331.pt\"\n",
    "eval_dataset = \"/work/NeuroI-models/ke-monai/data/roi/dataset_test_roi_toy2.csv\"\n",
    "eval_output_dir = \"./runs_eval2\"\n",
    "\n",
    "config = get_config(config)\n",
    "data_dir = config[\"data_dir\"]\n",
    "# image_file_path = config[\"image_file_path\"]\n",
    "# label_file_path = config[\"label_file_path\"]\n",
    "# mask_file_path = config[\"mask_file_path\"]\n",
    "pred_file_path = config[\"pred_file_path\"]\n",
    "label_file_path = config[\"label_file_path\"]\n",
    "\n",
    "eval_batch_size = config[\"eval\"][\"batch_size\"] \n",
    "eval_num_workers = config[\"eval\"][\"num_workers\"]\n",
    "num_classes = config[\"num_classes\"]\n",
    "# patch_size = config[\"patch_size\"]\n",
    "\n",
    "spacing = [1.0, 1.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc63844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(eval_dataset)\n",
    "# rows = csv.DictReader(f)\n",
    "# data = []\n",
    "# for row in rows:\n",
    "# #     id = row[\"id\"]\n",
    "# #     for aid in eval_aids:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40ee4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    CastToTyped,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    EnsureTyped,\n",
    "    MapLabelValued,\n",
    "    AsDiscreted\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "from monai.transforms.compose import MapTransform\n",
    "\n",
    "orig_label_classes, target_label_classes = (                                      # 109개 ROIs from zag\n",
    "    np.array([   0,    2,    3,    4,    5,    7,    8,   10,   11,   12,   13,\n",
    "         14,   15,   16,   17,   18,   24,   26,   28,   30,   31,   41,\n",
    "         42,   43,   44,   46,   47,   49,   50,   51,   52,   53,   54,\n",
    "         58,   60,   62,   63,   77,   80,   85,  251,  252,  253,  254,\n",
    "        255, 1000, 1002, 1003, 1005, 1006, 1007, 1008, 1009, 1010, 1011,\n",
    "       1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022,\n",
    "       1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1034, 1035,\n",
    "       2000, 2002, 2003, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012,\n",
    "       2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023,\n",
    "       2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2034, 2035]),\n",
    "    np.array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
    "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
    "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
    "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
    "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
    "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
    "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
    "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
    "       104, 105, 106, 107, 108])\n",
    "    )\n",
    "\n",
    "def get_eval_from_img_transform():\n",
    "    keys = [\"pred\", \"label\"]\n",
    "    transforms = [\n",
    "        LoadImaged(keys=keys),\n",
    "        AddChanneld(keys=keys),\n",
    "        Orientationd(keys=keys, axcodes=\"RAS\"),\n",
    "        MapLabelValued(\n",
    "            keys=keys, \n",
    "            orig_labels=orig_label_classes, \n",
    "            target_labels=target_label_classes,\n",
    "            dtype=np.uint8\n",
    "        ),\n",
    "#         Lambdad(keys='image', func=lambda x: np.where(x==-0, 0, x)),\n",
    "        # ScaleIntensityd(keys=[\"image\"], minv=0.0, maxv=1.0),\n",
    "        # ScaleIntensityRanged(\n",
    "        #     keys=[\"image\"],\n",
    "        #     a_min=-175,\n",
    "        #     a_max=250,\n",
    "        #     b_min=0.0,\n",
    "        #     b_max=1.0,\n",
    "        #     clip=True,\n",
    "        # ),\n",
    "#         ConcatItemsd(keys=[\"image\", \"mask\"], name=\"image\"),\n",
    "        # SelectItemsd(\n",
    "        #     keys=[\"image\", \"label\", \n",
    "        #           \"image_meta_dict\", \"label_meta_dict\", \n",
    "        #           \"image_transforms\", \"label_transforms\"]\n",
    "        # ),\n",
    "        Checkpixdim(\n",
    "            keys=keys,\n",
    "            pixdim=spacing,\n",
    "        ),        \n",
    "#         PreprocessAnisotropic(\n",
    "#             keys=[\"image\", \"label\"],\n",
    "#             clip_values=clip_values,\n",
    "#             pixdim=spacing,\n",
    "#             normalize_values=normalize_values,\n",
    "#             model_mode=\"validation\",\n",
    "#         ),\n",
    "        CastToTyped(keys=keys, dtype=(np.uint8, np.uint8)),\n",
    "        EnsureTyped(keys=keys),\n",
    "#         AsDiscreted(keys=keys, to_onehot=num_classes)\n",
    "        # DeleteItemsd(\n",
    "        #     keys=[\"mask\", \"mask_meta_dict\", \"mask_transforms\"]\n",
    "        # ),\n",
    "    ]\n",
    "    return Compose(transforms)\n",
    "\n",
    "class Checkpixdim(MapTransform):\n",
    "    # 주어진 spacing과 업로드한 이미지들의 pixel dim이 일치 하는지 확인 by K.E\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys,\n",
    "        pixdim,\n",
    "    ) -> None:\n",
    "        super().__init__(keys)\n",
    "        self.keys = keys\n",
    "        self.target_spacing = pixdim\n",
    "    def __call__(self, data):\n",
    "        # load data\n",
    "        d = dict(data)\n",
    "#         image_spacings = d[\"pred_meta_dict\"][\"pixdim\"][1:4].tolist()\n",
    "        pred_spacings = d[\"pred_meta_dict\"][\"pixdim\"][1:4].tolist()\n",
    "        label_spacings = d[\"label_meta_dict\"][\"pixdim\"][1:4].tolist()\n",
    "        \n",
    "        if self.target_spacing != pred_spacings:\n",
    "            raise AssertionError(f\"pred nifti img의 pixdim({pred_spacings})이 지정된 spacing({self.target_spacing})과 일치 하지 않습니다.\")\n",
    "        elif self.target_spacing != pred_spacings:\n",
    "            raise AssertionError(f\"label nifti img의 pixdim({label_spacings})이 지정된 spacing({self.target_spacing})과 일치 하지 않습니다.\")\n",
    "            \n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ec4ea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### dataset_roi에 심어야 함\n",
    "import csv\n",
    "from monai.data import (\n",
    "    CacheDataset,\n",
    "    DataLoader,\n",
    "    partition_dataset,\n",
    ")\n",
    "\n",
    "eval_aids = [\n",
    "    \"00_0\",\n",
    "    # \"01_d\",\n",
    "]\n",
    "\n",
    "def get_eval_data_from_img(\n",
    "    id_file, data_dir, \n",
    "    pred_file_pattern, \n",
    "    label_file_pattern\n",
    "):\n",
    "    f = open(id_file)\n",
    "    rows = csv.DictReader(f)\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        id = row[\"id\"]\n",
    "        for aid in eval_aids:\n",
    "            data.append(\n",
    "                {\n",
    "                    \"pred\": pred_file_pattern.format(dir=data_dir, id=id, aid=aid),\n",
    "                    \"label\": label_file_pattern.format(dir=data_dir, id=id, aid=aid),\n",
    "                }\n",
    "            )\n",
    "    return data\n",
    "\n",
    "def get_eval_loader(\n",
    "    data_dir,\n",
    "    id_file,\n",
    "    pred_file_pattern,\n",
    "    label_file_pattern,\n",
    "    batch_size,\n",
    "    num_workers=1,\n",
    "):\n",
    "    data = get_eval_data_from_img(\n",
    "        id_file, data_dir, \n",
    "        pred_file_pattern, label_file_pattern\n",
    "    )\n",
    "\n",
    "    transform = get_eval_from_img_transform()\n",
    "\n",
    "#     if torch.cuda.is_available() and dist.get_world_size() > 1:\n",
    "#         data = partition_dataset(\n",
    "#             data=data,\n",
    "#             shuffle=False,\n",
    "#             num_partitions=dist.get_world_size(),\n",
    "#             even_divisible=False,\n",
    "#         )[dist.get_rank()]\n",
    "\n",
    "    dataset = CacheDataset(data=data, transform=transform, num_workers=4)   # 4\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "311115db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.22s/it]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(eval_output_dir):\n",
    "    os.makedirs(eval_output_dir)\n",
    "    \n",
    "# if multi_gpu_flag:\n",
    "#     dist.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "#     device = torch.device(f\"cuda:{local_rank}\")\n",
    "#     torch.cuda.set_device(device)\n",
    "# else:\n",
    "#     device = torch.device(\"cuda:6\")\n",
    "# #     device = torch.device(\"cpu\")\n",
    "\n",
    "eval_loader = get_eval_loader(\n",
    "    data_dir=data_dir,\n",
    "    id_file=eval_dataset,\n",
    "    pred_file_pattern=pred_file_path,\n",
    "    label_file_pattern=label_file_path,\n",
    "    batch_size=eval_batch_size,\n",
    "    num_workers=eval_num_workers,\n",
    "#     multi_gpu_flag=multi_gpu_flag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a916a58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pred', 'label', 'pred_meta_dict', 'label_meta_dict', 'pred_transforms', 'label_transforms'])\n",
      "pred shape: torch.Size([1, 1, 186, 230, 230])\n",
      "pred dtype: torch.uint8\n",
      "label shape: torch.Size([1, 1, 186, 230, 230])\n",
      "label dtype: torch.uint8\n"
     ]
    }
   ],
   "source": [
    "test_data = first(eval_loader)\n",
    "print(test_data.keys())\n",
    "print(\"pred shape:\", test_data['pred'].shape)\n",
    "print(\"pred dtype:\", test_data['pred'].dtype)\n",
    "print(\"label shape:\", test_data['label'].shape)\n",
    "print(\"label dtype:\", test_data['label'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d956658",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bca5956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  20,  21,  23,  24,  25,  26,  27,  28,\n",
       "        29,  30,  31,  32,  33,  34,  36,  37,  39,  40,  41,  42,  43,\n",
       "        44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
       "        57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "        70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,\n",
       "        83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,\n",
       "        96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_data['pred']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "318d9287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  20,  21,  23,  24,  25,  26,  27,  28,\n",
       "        29,  30,  31,  32,  33,  34,  36,  37,  39,  40,  41,  42,  43,\n",
       "        44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
       "        57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "        70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,\n",
       "        83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,\n",
       "        96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3499f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sizeof_hdr': tensor([348], dtype=torch.int32),\n",
       " 'extents': tensor([0], dtype=torch.int32),\n",
       " 'session_error': tensor([0], dtype=torch.int16),\n",
       " 'dim_info': tensor([0], dtype=torch.uint8),\n",
       " 'dim': tensor([[  3, 186, 230, 230,   1,   1,   1,   1]], dtype=torch.int16),\n",
       " 'intent_p1': tensor([0.]),\n",
       " 'intent_p2': tensor([0.]),\n",
       " 'intent_p3': tensor([0.]),\n",
       " 'intent_code': tensor([0], dtype=torch.int16),\n",
       " 'datatype': tensor([16], dtype=torch.int16),\n",
       " 'bitpix': tensor([32], dtype=torch.int16),\n",
       " 'slice_start': tensor([0], dtype=torch.int16),\n",
       " 'pixdim': tensor([[1., 1., 1., 1., 0., 0., 0., 0.]]),\n",
       " 'vox_offset': tensor([0.]),\n",
       " 'scl_slope': tensor([nan]),\n",
       " 'scl_inter': tensor([nan]),\n",
       " 'slice_end': tensor([0], dtype=torch.int16),\n",
       " 'slice_code': tensor([0], dtype=torch.uint8),\n",
       " 'xyzt_units': tensor([2], dtype=torch.uint8),\n",
       " 'cal_max': tensor([0.]),\n",
       " 'cal_min': tensor([0.]),\n",
       " 'slice_duration': tensor([0.]),\n",
       " 'toffset': tensor([0.]),\n",
       " 'glmax': tensor([0], dtype=torch.int32),\n",
       " 'glmin': tensor([0], dtype=torch.int32),\n",
       " 'qform_code': tensor([1], dtype=torch.int16),\n",
       " 'sform_code': tensor([1], dtype=torch.int16),\n",
       " 'quatern_b': tensor([-0.0045]),\n",
       " 'quatern_c': tensor([0.0119]),\n",
       " 'quatern_d': tensor([0.0148]),\n",
       " 'qoffset_x': tensor([-91.3984]),\n",
       " 'qoffset_y': tensor([-121.7941]),\n",
       " 'qoffset_z': tensor([-94.6716]),\n",
       " 'srow_x': tensor([[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01]]),\n",
       " 'srow_y': tensor([[ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02]]),\n",
       " 'srow_z': tensor([[-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01]]),\n",
       " 'affine': tensor([[[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]]),\n",
       " 'original_affine': tensor([[[ 9.9928e-01, -2.9683e-02,  2.3596e-02, -9.1398e+01],\n",
       "          [ 2.9468e-02,  9.9952e-01,  9.4261e-03, -1.2179e+02],\n",
       "          [-2.3865e-02, -8.7240e-03,  9.9968e-01, -9.4672e+01],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],\n",
       "        dtype=torch.float64),\n",
       " 'as_closest_canonical': tensor([False]),\n",
       " 'spatial_shape': tensor([[186, 230, 230]], dtype=torch.int16),\n",
       " 'original_channel_dim': ['no_channel'],\n",
       " 'filename_or_obj': ['/data/train/running/l/input_augmented/s_SU0303_00_0_l.nii.gz']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['pred_meta_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46aad098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_spacings = test_data['pred_meta_dict'][\"pixdim\"][0][1:4].tolist()\n",
    "pred_spacings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0486260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['pred_meta_dict'][\"pixdim\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6902d3",
   "metadata": {},
   "source": [
    "---------------\n",
    "\n",
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10e4db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import AsDiscrete, Transform\n",
    "from monai.data import decollate_batch\n",
    "\n",
    "post_transforms = AsDiscreted(keys=[\"pred\", \"label\"], to_onehot=num_classes)\n",
    "\n",
    "# def get_post_transforms():\n",
    "#     keys = [\"pred\", \"label\"]\n",
    "#     transforms = [\n",
    "#         AsDiscreted(keys=keys, to_onehot=num_classes)\n",
    "#     ]\n",
    "#     return Compose(transforms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375a298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f06344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decollate_batch(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b4d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [post_transforms(i) for i in decollate_batch(test_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f781a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2747d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[0]['pred'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a572765",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 각 데이터 모양\n",
    "# test_data [{'pred': tensor, 'label': tensor}]\n",
    "# val_output [tensor], val_labels [tensor]\n",
    "val_outputs, val_labels = from_engine([\"pred\", \"label\"])(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d73e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a, b = test_data  ## Error!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381476a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d380335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4fa0bf",
   "metadata": {},
   "source": [
    "### 실험 1. dice_metric은 실행할 수록 쌓이는 구조인가?\n",
    "* 쌓이는 구조는 아니고 한번 실행마다 넣어준 pred, label의 dice 결과 텐서를 출력해줌.\n",
    "* 그런데 MONAI doc을 보니 `CumulativeIterationMetric`의 개념으로 metric는 aggregate final result를 출력가능하다고 나옴.\n",
    "  * 방식 : `dice_metric.aggregate().item()`\n",
    "  * 주의할 점: aggregate를 한번 더 하면 예상치 못한 쓰레기 결과도 함께 포함될 수 있음. 딱 처음 한번만 해야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d785bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.metrics import DiceMetric, compute_meandice\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "result = dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b7593",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935d6095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차곡차곡 쌓이는 구조인가?\n",
    "result = dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763362d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038c3e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = dice_metric.aggregate().item()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed7059",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_metric.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1d4253",
   "metadata": {},
   "source": [
    "### 실험 2. dice_metric에 리스트 텐서-[tensor] 구조가 아닌 그냥 tensor만 넣어도 계산될까?\n",
    "-> 이상한 형태의 결과값이 나옴.. 결과 의도를 파악 못하겠음.. 리스트 구조로 꼭 넣는걸로.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ee4c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [tensor] 구조가 아닌 그냥 tensor만 넣어도 계산될까? -> 계산 된다.\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "a = dice_metric(y_pred=val_outputs[0], y=val_labels[0])\n",
    "a.shape, a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf6277c",
   "metadata": {},
   "source": [
    "### 실험 3. 한셀 코딩\n",
    "* loader의 결과가 2차원 리스트 형식으로 들어가도록 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c135e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample : s_SU0303_00_0_l....... done\n",
      "sample : s_SU0197_00_0_l....... done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ori_name</th>\n",
       "      <th>original_index</th>\n",
       "      <th>target_index</th>\n",
       "      <th>s_SU0303_00_0_l</th>\n",
       "      <th>s_SU0197_00_0_l</th>\n",
       "      <th>roi_meanDice</th>\n",
       "      <th>total_meanDice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clear Label</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L Cerebral-White-Matter</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L Cerebral-Cortex</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L Lateral-Ventricle</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L Inf-Lat-Vent</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>R superiorparietal</td>\n",
       "      <td>2029</td>\n",
       "      <td>104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>R superiortemporal</td>\n",
       "      <td>2030</td>\n",
       "      <td>105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>R supramarginal</td>\n",
       "      <td>2031</td>\n",
       "      <td>106</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>R transversetemporal</td>\n",
       "      <td>2034</td>\n",
       "      <td>107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>R insula</td>\n",
       "      <td>2035</td>\n",
       "      <td>108</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ori_name  original_index  target_index  s_SU0303_00_0_l  \\\n",
       "0                Clear Label               0             0              NaN   \n",
       "1    L Cerebral-White-Matter               2             1              1.0   \n",
       "2          L Cerebral-Cortex               3             2              NaN   \n",
       "3        L Lateral-Ventricle               4             3              1.0   \n",
       "4             L Inf-Lat-Vent               5             4              1.0   \n",
       "..                       ...             ...           ...              ...   \n",
       "104       R superiorparietal            2029           104              1.0   \n",
       "105       R superiortemporal            2030           105              1.0   \n",
       "106          R supramarginal            2031           106              1.0   \n",
       "107     R transversetemporal            2034           107              1.0   \n",
       "108                 R insula            2035           108              1.0   \n",
       "\n",
       "     s_SU0197_00_0_l  roi_meanDice  total_meanDice  \n",
       "0                NaN           NaN             1.0  \n",
       "1                1.0           1.0             1.0  \n",
       "2                NaN           NaN             1.0  \n",
       "3                1.0           1.0             1.0  \n",
       "4                1.0           1.0             1.0  \n",
       "..               ...           ...             ...  \n",
       "104              1.0           1.0             1.0  \n",
       "105              1.0           1.0             1.0  \n",
       "106              1.0           1.0             1.0  \n",
       "107              1.0           1.0             1.0  \n",
       "108              1.0           1.0             1.0  \n",
       "\n",
       "[109 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from monai.transforms import AsDiscreted, Transform\n",
    "from monai.data import decollate_batch\n",
    "from monai.metrics import DiceMetric\n",
    "\n",
    "filename_list = []\n",
    "total_sample_dice = []\n",
    "post_transforms = AsDiscreted(keys=[\"pred\", \"label\"], to_onehot=num_classes)\n",
    "\n",
    "for idx, eval_data in enumerate(eval_loader):\n",
    "    filename = eval_data['pred_meta_dict']['filename_or_obj'][0].split(\"/\")[-1].split(\".\")[0]\n",
    "    filename_list.append(filename)\n",
    "    \n",
    "    \n",
    "    sample_num = idx+1\n",
    "    eval_data = [post_transforms(i) for i in decollate_batch(eval_data)]\n",
    "    eval_outputs, eval_labels = from_engine([\"pred\", \"label\"])(eval_data)\n",
    "    \n",
    "    dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "    sample_dice_result = dice_metric(y_pred=eval_outputs, y=eval_labels)\n",
    "    sample_dice_result = sample_dice_result.numpy()\n",
    "    total_sample_dice.append(sample_dice_result)\n",
    "    \n",
    "    print(f'sample : {filename}....... done')\n",
    "\n",
    "# Average Mean Dice\n",
    "avg_mean_dice = dice_metric.aggregate().item()\n",
    "dice_metric.reset()\n",
    "\n",
    "# arrange each sample's dice coefficient per ROIs\n",
    "sample_num = sample_num * eval_batch_size\n",
    "total_sample_dice = np.array(total_sample_dice)\n",
    "total_sample_dice = total_sample_dice.reshape(sample_num, -1)\n",
    "\n",
    "# add ROIs Means & total Mean\n",
    "df = pd.DataFrame(total_sample_dice).T\n",
    "df = pd.concat([pd.DataFrame(np.zeros(df.shape[1])).T, df])\n",
    "df.columns = filename_list\n",
    "df['roi_meanDice'] = df.mean(axis=1)\n",
    "df['total_meanDice'] = avg_mean_dice\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df = df.applymap(lambda x: np.nan if x==0 else x)    # missing -> NaN 처리\n",
    "\n",
    "# add orig_index, target_index\n",
    "df_index = pd.DataFrame([orig_label_classes, target_label_classes]).T\n",
    "df_index.columns = ['original_index', 'target_index']\n",
    "df_mid = pd.concat([df_index, df], axis=1)\n",
    "\n",
    "# mapping original name\n",
    "mapping_f = '/data/kehyeong/project/NeuroI-models/ROI-pipeline/data/ROI_mapping_final_220314.txt'\n",
    "df_name_map = pd.read_csv(mapping_f, sep='\\t')\n",
    "df_final = pd.merge(df_name_map, df_mid, how='right', left_on=\"label_label-from\", right_on=\"original_index\")\n",
    "df_final.drop(columns=[\"label_label-from\", \"label_label-to\"], inplace=True)\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7679d7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_SU0303_00_0_l</th>\n",
       "      <th>s_SU0197_00_0_l</th>\n",
       "      <th>roi_meanDice</th>\n",
       "      <th>total_meanDice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     s_SU0303_00_0_l  s_SU0197_00_0_l  roi_meanDice  total_meanDice\n",
       "0                NaN              NaN           NaN             1.0\n",
       "1                1.0              1.0           1.0             1.0\n",
       "2                NaN              NaN           NaN             1.0\n",
       "3                1.0              1.0           1.0             1.0\n",
       "4                1.0              1.0           1.0             1.0\n",
       "..               ...              ...           ...             ...\n",
       "104              1.0              1.0           1.0             1.0\n",
       "105              1.0              1.0           1.0             1.0\n",
       "106              1.0              1.0           1.0             1.0\n",
       "107              1.0              1.0           1.0             1.0\n",
       "108              1.0              1.0           1.0             1.0\n",
       "\n",
       "[109 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc3ec820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['total_meanDice'] = df['roi_meanDice'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a5e6064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ori_name</th>\n",
       "      <th>Clear Label</th>\n",
       "      <th>L Cerebral-White-Matter</th>\n",
       "      <th>L Cerebral-Cortex</th>\n",
       "      <th>L Lateral-Ventricle</th>\n",
       "      <th>L Inf-Lat-Vent</th>\n",
       "      <th>L Cerebellum-White-Matter</th>\n",
       "      <th>L Cerebellum-Cortex</th>\n",
       "      <th>L Thalamus-Proper</th>\n",
       "      <th>L Caudate</th>\n",
       "      <th>L Putamen</th>\n",
       "      <th>...</th>\n",
       "      <th>R precentral</th>\n",
       "      <th>R precuneus</th>\n",
       "      <th>R rostralanteriorcingulate</th>\n",
       "      <th>R rostralmiddlefrontal</th>\n",
       "      <th>R superiorfrontal</th>\n",
       "      <th>R superiorparietal</th>\n",
       "      <th>R superiortemporal</th>\n",
       "      <th>R supramarginal</th>\n",
       "      <th>R transversetemporal</th>\n",
       "      <th>R insula</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>original_index</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>2024</td>\n",
       "      <td>2025</td>\n",
       "      <td>2026</td>\n",
       "      <td>2027</td>\n",
       "      <td>2028</td>\n",
       "      <td>2029</td>\n",
       "      <td>2030</td>\n",
       "      <td>2031</td>\n",
       "      <td>2034</td>\n",
       "      <td>2035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_index</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>102</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>105</td>\n",
       "      <td>106</td>\n",
       "      <td>107</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s_SU0303_00_0_l</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s_SU0197_00_0_l</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roi_meanDice</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_meanDice</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ori_name        Clear Label L Cerebral-White-Matter L Cerebral-Cortex  \\\n",
       "original_index            0                       2                 3   \n",
       "target_index              0                       1                 2   \n",
       "s_SU0303_00_0_l         NaN                     1.0               NaN   \n",
       "s_SU0197_00_0_l         NaN                     1.0               NaN   \n",
       "roi_meanDice            NaN                     1.0               NaN   \n",
       "total_meanDice          1.0                     1.0               1.0   \n",
       "\n",
       "ori_name        L Lateral-Ventricle L Inf-Lat-Vent L Cerebellum-White-Matter  \\\n",
       "original_index                    4              5                         7   \n",
       "target_index                      3              4                         5   \n",
       "s_SU0303_00_0_l                 1.0            1.0                       1.0   \n",
       "s_SU0197_00_0_l                 1.0            1.0                       1.0   \n",
       "roi_meanDice                    1.0            1.0                       1.0   \n",
       "total_meanDice                  1.0            1.0                       1.0   \n",
       "\n",
       "ori_name        L Cerebellum-Cortex L Thalamus-Proper L Caudate L Putamen  \\\n",
       "original_index                    8                10        11        12   \n",
       "target_index                      6                 7         8         9   \n",
       "s_SU0303_00_0_l                 1.0               1.0       1.0       1.0   \n",
       "s_SU0197_00_0_l                 1.0               1.0       1.0       1.0   \n",
       "roi_meanDice                    1.0               1.0       1.0       1.0   \n",
       "total_meanDice                  1.0               1.0       1.0       1.0   \n",
       "\n",
       "ori_name         ... R precentral R precuneus R rostralanteriorcingulate  \\\n",
       "original_index   ...         2024        2025                       2026   \n",
       "target_index     ...           99         100                        101   \n",
       "s_SU0303_00_0_l  ...          1.0         1.0                        1.0   \n",
       "s_SU0197_00_0_l  ...          1.0         1.0                        1.0   \n",
       "roi_meanDice     ...          1.0         1.0                        1.0   \n",
       "total_meanDice   ...          1.0         1.0                        1.0   \n",
       "\n",
       "ori_name        R rostralmiddlefrontal R superiorfrontal R superiorparietal  \\\n",
       "original_index                    2027              2028               2029   \n",
       "target_index                       102               103                104   \n",
       "s_SU0303_00_0_l                    1.0               1.0                1.0   \n",
       "s_SU0197_00_0_l                    1.0               1.0                1.0   \n",
       "roi_meanDice                       1.0               1.0                1.0   \n",
       "total_meanDice                     1.0               1.0                1.0   \n",
       "\n",
       "ori_name        R superiortemporal R supramarginal R transversetemporal  \\\n",
       "original_index                2030            2031                 2034   \n",
       "target_index                   105             106                  107   \n",
       "s_SU0303_00_0_l                1.0             1.0                  1.0   \n",
       "s_SU0197_00_0_l                1.0             1.0                  1.0   \n",
       "roi_meanDice                   1.0             1.0                  1.0   \n",
       "total_meanDice                 1.0             1.0                  1.0   \n",
       "\n",
       "ori_name        R insula  \n",
       "original_index      2035  \n",
       "target_index         108  \n",
       "s_SU0303_00_0_l      1.0  \n",
       "s_SU0197_00_0_l      1.0  \n",
       "roi_meanDice         1.0  \n",
       "total_meanDice       1.0  \n",
       "\n",
       "[6 rows x 109 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 행/열 전환된 결과 파일 출력\n",
    "df_transpose = df_final.T\n",
    "new_header = df_transpose.iloc[0,:]\n",
    "df_tf = df_transpose[1:]\n",
    "df_tf.columns = new_header\n",
    "df_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca742d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
