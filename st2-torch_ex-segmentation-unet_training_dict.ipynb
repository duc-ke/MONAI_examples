{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8354e5bc",
   "metadata": {},
   "source": [
    "다음을 리뷰 :\n",
    "https://github.com/Project-MONAI/tutorials/blob/master/3d_segmentation/torch/unet_training_dict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e7d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib    # nifti 포맷 파일 생성때만 이용\n",
    "\n",
    "import torch\n",
    "\n",
    "## from monai.data import DataLoader 와 기능이 다름\n",
    "## RandCropByPosNegLabeld 에서 sample값을 설정시,\n",
    "## torch DataLoader는 sample 수 만큼 리스트 형태로 반환 (list_data_collate를 옵션으로 설정시 {}dict로 반환해준다.)\n",
    "## monai DataLoader는 sample x batch 만큼 {}dict로 반환해준다.\n",
    "from torch.utils.data import DataLoader   \n",
    "# from monai.data import DataLoader\n",
    "\n",
    "import monai\n",
    "## decollate_batch : 배치 텐서를 리스트의 텐서로 변환\n",
    "from monai.data import create_test_image_3d, decollate_batch\n",
    "# from monai.transforms import RandSpatialCrop, ScaleIntensity, EnsureType\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.visualize import plot_2d_or_3d_image\n",
    "# tensorboard가 읽을 수 있도록 loss, metric, out image, out_seg 를 기록 \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "## 삭제\n",
    "from monai.data import ImageDataset\n",
    "from monai.transforms import AddChannel\n",
    "\n",
    "# 이건 image, seg 파일 배열을 넣어주면 데이터셋을 만들어주는 API인듯하다. segmentation 한정 사용가능\n",
    "# train_ds = ImageDataset(images[:20], segs[:20], transform=train_imtrans, seg_transform=train_segtrans)\n",
    "\n",
    "# AddChannel : 맨 앞단 1 차원 삽입 (ex) torch.Size([6]) -> torch.Size([1, 6]) \n",
    "\n",
    "\n",
    "## 새롭게 추가\n",
    "from monai.data import Dataset   # dict에선 ImageDataset대신 이용\n",
    "from monai.data import list_data_collate\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsChannelFirstd,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    RandCropByPosNegLabeld,  # randomly crop patch samples from big image based on pos / neg ratio.\n",
    "    RandRotate90d,\n",
    "    ScaleIntensityd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    AddChanneld,\n",
    "    Orientationd,\n",
    "    SpatialPadd,\n",
    "    CastToTyped\n",
    ")\n",
    "\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0607d2a7",
   "metadata": {},
   "source": [
    "```python\n",
    "# AddChannel Test\n",
    "test = np.array([-1, -0.4, 0.2, 0.4, 0.8, 1.5])\n",
    "post_trans_test1 = Compose([EnsureType(), AddChannel()])\n",
    "print(post_trans_test1(test).shape, post_trans_test1(test))\n",
    "\n",
    "post_trans_test2 = Compose([EnsureType()])\n",
    "print(post_trans_test2(test).shape, post_trans_test2(test))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fbbf335",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ca19b7",
   "metadata": {},
   "source": [
    "### making random 3D segmentation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "347f4822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.9.dev2152\n",
      "Numpy version: 1.21.2\n",
      "Pytorch version: 1.10.0a0+0aef44c\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: c5bd8aff8ba461d7b349eb92427d452481a7eb72\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.6\n",
      "Nibabel version: 3.2.1\n",
      "scikit-image version: 0.18.3\n",
      "Pillow version: 8.4.0\n",
      "Tensorboard version: 2.6.0\n",
      "gdown version: 4.2.0\n",
      "TorchVision version: 0.11.0a0\n",
      "tqdm version: 4.62.3\n",
      "lmdb version: 1.2.1\n",
      "psutil version: 5.8.0\n",
      "pandas version: 1.3.4\n",
      "einops version: 0.3.2\n",
      "transformers version: 4.12.5\n",
      "mlflow version: 1.21.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "generating synthetic data to ./data/unet_tmp (this may take a while)\n"
     ]
    }
   ],
   "source": [
    "# tempdir = './dataset'\n",
    "tempdir = './data/unet_tmp'\n",
    "monai.config.print_config()\n",
    "\n",
    "\n",
    "# 디렉토리에 40개 랜덤이미지, 마스크 생성\n",
    "print(f\"generating synthetic data to {tempdir} (this may take a while)\")\n",
    "for i in range(40):\n",
    "    # np image 생성\n",
    "    im, seg = create_test_image_3d(128, 128, 128, num_seg_classes=1, channel_dim=-1)  \n",
    "#     print(type(im), type(seg))  # np.array\n",
    "#     print(im.shape, seg.shape)  # (128, 128, 128) (128, 128, 128) 3d 라서 img, seg가 같은 dim인 듯?\n",
    "#     print(im)\n",
    "\n",
    "#     print(np.eye(4))  # 2차원 identity 행렬(4x4) 생성\n",
    "    n = nib.Nifti1Image(im, np.eye(4))\n",
    "#     print(type(n), n)   # nifti 이미지\n",
    "    nib.save(n, os.path.join(tempdir, f\"img{i:d}.nii.gz\"))\n",
    "\n",
    "    n = nib.Nifti1Image(seg, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, f\"seg{i:d}.nii.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9bd407",
   "metadata": {},
   "source": [
    "### image, seg 파일 dict Loading\n",
    "\n",
    "* 참고: list form에선, 이미지리스트를 그대로 사용하여 ds를 만듦\n",
    "```python \n",
    "# list form\n",
    "train_ds = ImageDataset(images[:20], segs[:20], transform=train_imtrans, seg_transform=train_segtrans)\n",
    "val_ds = ImageDataset(images[-20:], segs[-20:], transform=val_imtrans, seg_transform=val_segtrans)\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b815c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sorted(glob(os.path.join(tempdir, \"img*.nii.gz\")))    # 40개 nifti file 리스트\n",
    "segs = sorted(glob(os.path.join(tempdir, \"seg*.nii.gz\")))\n",
    "\n",
    "train_files = [{\"img\": img, \"seg\": seg}for img, seg in zip(images[:20], segs[:20])]\n",
    "val_files = [{\"img\": img, \"seg\": seg}for img, seg in zip(images[-20:], segs[-20:])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e164e7",
   "metadata": {},
   "source": [
    "### Transform 정의\n",
    "* 참고: list form에선, img, seg에 해당하는 각각의 transform을 따로 정의하여 사용함\n",
    "```python\n",
    "train_imtrans = Compose(\n",
    "    [\n",
    "        ScaleIntensity(),\n",
    "        AddChannel(),\n",
    "        # aug\n",
    "        RandSpatialCrop((96, 96, 96), random_size=False),\n",
    "        RandRotate90(prob=0.5, spatial_axes=(0, 2)),\n",
    "        EnsureType(),\n",
    "    ]\n",
    ")\n",
    "train_segtrans = Compose(\n",
    "    [\n",
    "        # 스케일링 필요없나 봄 (1또는 0이므로)\n",
    "        AddChannel(),\n",
    "        # aug (img와 같은 aug를 해주는가..? -> 맞음.. 왜인진.. 모름)\n",
    "        RandSpatialCrop((96, 96, 96), random_size=False),\n",
    "        RandRotate90(prob=0.5, spatial_axes=(0, 2)),\n",
    "        EnsureType(),\n",
    "    ]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6da9f87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 96, 96, 96]) torch.Size([8, 1, 96, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),   # list에선 ImageDataset을 대신썻기 때문에 LoadImage가 포함되어있었음\n",
    "        # 위의 예제는 128, 128, 128, 1 임. AsChannelFirst는 channel 1을 맨앞으로 바꿔주는 역할\n",
    "        AsChannelFirstd(keys=[\"img\", \"seg\"], channel_dim=-1),  \n",
    "        ScaleIntensityd(keys=\"img\"),   # scaling은 img에만.\n",
    "        # aug\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"img\", \"seg\"],\n",
    "            label_key=\"seg\",\n",
    "            spatial_size=[96, 96, 96],\n",
    "            pos=1,   # foreground voxel as a center rather than a background voxel. ``pos / (pos + neg)``\n",
    "            neg=1,\n",
    "            num_samples=4    # 1개 이미지당 4개 결과생성. 즉 4배로 뻥튀기\n",
    "        ),\n",
    "        RandRotate90d(keys=[\"img\", \"seg\"], prob=0.5, spatial_axes=[0, 2]),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"])\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),  \n",
    "        AsChannelFirstd(keys=[\"img\", \"seg\"], channel_dim=-1),\n",
    "        ScaleIntensityd(keys=\"img\"), \n",
    "        EnsureTyped(keys=[\"img\", \"seg\"])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 잘 되는지 프로세스 검증\n",
    "check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "# RandCrop에서 samples 4개 만들면, 이게 리스트로 만들어짐. 이걸 풀어서 tensor 하나에 8개(2x4)를 넣어주는게 list_data_collate임\n",
    "check_loader = DataLoader(check_ds, batch_size=2, num_workers=4, collate_fn=list_data_collate)\n",
    "# check_loader = DataLoader(check_ds, batch_size=2, num_workers=4)\n",
    "check_data = monai.utils.misc.first(check_loader)\n",
    "# print(check_data)\n",
    "print(check_data[\"img\"].shape, check_data[\"seg\"].shape)\n",
    "\n",
    "# list_data_collate -> torch.Size([8, 1, 96, 96, 96]) torch.Size([8, 1, 96, 96, 96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29477465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "torch.Size([2, 1, 96, 96, 96])\n",
      "[{'img': tensor([[[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]]]), 'seg': tensor([[[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]]]), 'img_meta_dict': {'sizeof_hdr': tensor([348, 348], dtype=torch.int32), 'extents': tensor([0, 0], dtype=torch.int32), 'session_error': tensor([0, 0], dtype=torch.int16), 'dim_info': tensor([0, 0], dtype=torch.uint8), 'dim': tensor([[  4, 128, 128, 128,   1,   1,   1,   1],\n",
      "        [  4, 128, 128, 128,   1,   1,   1,   1]], dtype=torch.int16), 'intent_p1': tensor([0., 0.]), 'intent_p2': tensor([0., 0.]), 'intent_p3': tensor([0., 0.]), 'intent_code': tensor([0, 0], dtype=torch.int16), 'datatype': tensor([16, 16], dtype=torch.int16), 'bitpix': tensor([32, 32], dtype=torch.int16), 'slice_start': tensor([0, 0], dtype=torch.int16), 'pixdim': tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]]), 'vox_offset': tensor([0., 0.]), 'scl_slope': tensor([nan, nan]), 'scl_inter': tensor([nan, nan]), 'slice_end': tensor([0, 0], dtype=torch.int16), 'slice_code': tensor([0, 0], dtype=torch.uint8), 'xyzt_units': tensor([0, 0], dtype=torch.uint8), 'cal_max': tensor([0., 0.]), 'cal_min': tensor([0., 0.]), 'slice_duration': tensor([0., 0.]), 'toffset': tensor([0., 0.]), 'glmax': tensor([0, 0], dtype=torch.int32), 'glmin': tensor([0, 0], dtype=torch.int32), 'qform_code': tensor([0, 0], dtype=torch.int16), 'sform_code': tensor([2, 2], dtype=torch.int16), 'quatern_b': tensor([0., 0.]), 'quatern_c': tensor([0., 0.]), 'quatern_d': tensor([0., 0.]), 'qoffset_x': tensor([0., 0.]), 'qoffset_y': tensor([0., 0.]), 'qoffset_z': tensor([0., 0.]), 'srow_x': tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]]), 'srow_y': tensor([[0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.]]), 'srow_z': tensor([[0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.]]), 'affine': tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]]], dtype=torch.float64), 'original_affine': tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]]], dtype=torch.float64), 'as_closest_canonical': tensor([False, False]), 'spatial_shape': tensor([[128, 128, 128],\n",
      "        [128, 128, 128]], dtype=torch.int16), 'original_channel_dim': tensor([-1, -1]), 'filename_or_obj': ['data/unet_tmp/img0.nii.gz', 'data/unet_tmp/img1.nii.gz'], 'patch_index': tensor([0, 0])}, 'seg_meta_dict': {'sizeof_hdr': tensor([348, 348], dtype=torch.int32), 'extents': tensor([0, 0], dtype=torch.int32), 'session_error': tensor([0, 0], dtype=torch.int16), 'dim_info': tensor([0, 0], dtype=torch.uint8), 'dim': tensor([[  4, 128, 128, 128,   1,   1,   1,   1],\n",
      "        [  4, 128, 128, 128,   1,   1,   1,   1]], dtype=torch.int16), 'intent_p1': tensor([0., 0.]), 'intent_p2': tensor([0., 0.]), 'intent_p3': tensor([0., 0.]), 'intent_code': tensor([0, 0], dtype=torch.int16), 'datatype': tensor([8, 8], dtype=torch.int16), 'bitpix': tensor([32, 32], dtype=torch.int16), 'slice_start': tensor([0, 0], dtype=torch.int16), 'pixdim': tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]]), 'vox_offset': tensor([0., 0.]), 'scl_slope': tensor([nan, nan]), 'scl_inter': tensor([nan, nan]), 'slice_end': tensor([0, 0], dtype=torch.int16), 'slice_code': tensor([0, 0], dtype=torch.uint8), 'xyzt_units': tensor([0, 0], dtype=torch.uint8), 'cal_max': tensor([0., 0.]), 'cal_min': tensor([0., 0.]), 'slice_duration': tensor([0., 0.]), 'toffset': tensor([0., 0.]), 'glmax': tensor([0, 0], dtype=torch.int32), 'glmin': tensor([0, 0], dtype=torch.int32), 'qform_code': tensor([0, 0], dtype=torch.int16), 'sform_code': tensor([2, 2], dtype=torch.int16), 'quatern_b': tensor([0., 0.]), 'quatern_c': tensor([0., 0.]), 'quatern_d': tensor([0., 0.]), 'qoffset_x': tensor([0., 0.]), 'qoffset_y': tensor([0., 0.]), 'qoffset_z': tensor([0., 0.]), 'srow_x': tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]]), 'srow_y': tensor([[0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.]]), 'srow_z': tensor([[0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.]]), 'affine': tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]]], dtype=torch.float64), 'original_affine': tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]]], dtype=torch.float64), 'as_closest_canonical': tensor([False, False]), 'spatial_shape': tensor([[128, 128, 128],\n",
      "        [128, 128, 128]], dtype=torch.int16), 'original_channel_dim': tensor([-1, -1]), 'filename_or_obj': ['data/unet_tmp/seg0.nii.gz', 'data/unet_tmp/seg1.nii.gz'], 'patch_index': tensor([0, 0])}, 'img_transforms': [{'class': ['RandCropByPosNegLabeld', 'RandCropByPosNegLabeld'], 'id': tensor([140527689923024, 140527689923024]), 'orig_size': [tensor([128, 128]), tensor([128, 128]), tensor([128, 128])], 'extra_info': {'center': [tensor([53, 55]), tensor([67, 48]), tensor([80, 77])]}}, {'class': ['RandRotate90d', 'RandRotate90d'], 'id': tensor([140527689923120, 140527689923120]), 'orig_size': [tensor([96, 96]), tensor([96, 96]), tensor([96, 96])], 'extra_info': {'rand_k': tensor([3, 2])}, 'do_transforms': tensor([False, False])}, {'class': ['EnsureTyped', 'EnsureTyped'], 'id': tensor([140527689923168, 140527689923168]), 'orig_size': [tensor([96, 96]), tensor([96, 96]), tensor([96, 96])]}], 'seg_transforms': [{'class': ['RandCropByPosNegLabeld', 'RandCropByPosNegLabeld'], 'id': tensor([140527689923024, 140527689923024]), 'orig_size': [tensor([128, 128]), tensor([128, 128]), tensor([128, 128])], 'extra_info': {'center': [tensor([53, 55]), tensor([67, 48]), tensor([80, 77])]}}, {'class': ['RandRotate90d', 'RandRotate90d'], 'id': tensor([140527689923120, 140527689923120]), 'orig_size': [tensor([96, 96]), tensor([96, 96]), tensor([96, 96])], 'extra_info': {'rand_k': tensor([3, 2])}, 'do_transforms': tensor([False, False])}, {'class': ['EnsureTyped', 'EnsureTyped'], 'id': tensor([140527689923168, 140527689923168]), 'orig_size': [tensor([96, 96]), tensor([96, 96]), tensor([96, 96])]}]}, {'img': tensor([[[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           ...,\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           ...,\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           ...,\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           ...,\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           ...,\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           ...,\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           ...,\n",
      "           [0.8250, 0.8250, 0.8250,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.8250, 0.8250, 0.8250,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.8250, 0.8250, 0.8250,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           ...,\n",
      "           [0.8250, 0.8250, 0.8250,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.8250, 0.8250, 0.8250,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.8250, 0.8250, 0.8250,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           ...,\n",
      "           [0.8250, 0.8250, 0.8250,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.8250, 0.8250, 0.8250,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.8250, 0.8250, 0.8250,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           ...,\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           ...,\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "          [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           ...,\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]]]), 'seg': tensor([[[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "           [1., 1., 1.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "           [1., 1., 1.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "           [1., 1., 1.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]]]), 'img_meta_dict': {'sizeof_hdr': tensor([348, 348], dtype=torch.int32), 'extents': tensor([0, 0], dtype=torch.int32), 'session_error': tensor([0, 0], dtype=torch.int16), 'dim_info': tensor([0, 0], dtype=torch.uint8), 'dim': tensor([[  4, 128, 128, 128,   1,   1,   1,   1],\n",
      "        [  4, 128, 128, 128,   1,   1,   1,   1]], dtype=torch.int16), 'intent_p1': tensor([0., 0.]), 'intent_p2': tensor([0., 0.]), 'intent_p3': tensor([0., 0.]), 'intent_code': tensor([0, 0], dtype=torch.int16), 'datatype': tensor([16, 16], dtype=torch.int16), 'bitpix': tensor([32, 32], dtype=torch.int16), 'slice_start': tensor([0, 0], dtype=torch.int16), 'pixdim': tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]]), 'vox_offset': tensor([0., 0.]), 'scl_slope': tensor([nan, nan]), 'scl_inter': tensor([nan, nan]), 'slice_end': tensor([0, 0], dtype=torch.int16), 'slice_code': tensor([0, 0], dtype=torch.uint8), 'xyzt_units': tensor([0, 0], dtype=torch.uint8), 'cal_max': tensor([0., 0.]), 'cal_min': tensor([0., 0.]), 'slice_duration': tensor([0., 0.]), 'toffset': tensor([0., 0.]), 'glmax': tensor([0, 0], dtype=torch.int32), 'glmin': tensor([0, 0], dtype=torch.int32), 'qform_code': tensor([0, 0], dtype=torch.int16), 'sform_code': tensor([2, 2], dtype=torch.int16), 'quatern_b': tensor([0., 0.]), 'quatern_c': tensor([0., 0.]), 'quatern_d': tensor([0., 0.]), 'qoffset_x': tensor([0., 0.]), 'qoffset_y': tensor([0., 0.]), 'qoffset_z': tensor([0., 0.]), 'srow_x': tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]]), 'srow_y': tensor([[0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.]]), 'srow_z': tensor([[0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.]]), 'affine': tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]]], dtype=torch.float64), 'original_affine': tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]]], dtype=torch.float64), 'as_closest_canonical': tensor([False, False]), 'spatial_shape': tensor([[128, 128, 128],\n",
      "        [128, 128, 128]], dtype=torch.int16), 'original_channel_dim': tensor([-1, -1]), 'filename_or_obj': ['data/unet_tmp/img0.nii.gz', 'data/unet_tmp/img1.nii.gz'], 'patch_index': tensor([1, 1])}, 'seg_meta_dict': {'sizeof_hdr': tensor([348, 348], dtype=torch.int32), 'extents': tensor([0, 0], dtype=torch.int32), 'session_error': tensor([0, 0], dtype=torch.int16), 'dim_info': tensor([0, 0], dtype=torch.uint8), 'dim': tensor([[  4, 128, 128, 128,   1,   1,   1,   1],\n",
      "        [  4, 128, 128, 128,   1,   1,   1,   1]], dtype=torch.int16), 'intent_p1': tensor([0., 0.]), 'intent_p2': tensor([0., 0.]), 'intent_p3': tensor([0., 0.]), 'intent_code': tensor([0, 0], dtype=torch.int16), 'datatype': tensor([8, 8], dtype=torch.int16), 'bitpix': tensor([32, 32], dtype=torch.int16), 'slice_start': tensor([0, 0], dtype=torch.int16), 'pixdim': tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]]), 'vox_offset': tensor([0., 0.]), 'scl_slope': tensor([nan, nan]), 'scl_inter': tensor([nan, nan]), 'slice_end': tensor([0, 0], dtype=torch.int16), 'slice_code': tensor([0, 0], dtype=torch.uint8), 'xyzt_units': tensor([0, 0], dtype=torch.uint8), 'cal_max': tensor([0., 0.]), 'cal_min': tensor([0., 0.]), 'slice_duration': tensor([0., 0.]), 'toffset': tensor([0., 0.]), 'glmax': tensor([0, 0], dtype=torch.int32), 'glmin': tensor([0, 0], dtype=torch.int32), 'qform_code': tensor([0, 0], dtype=torch.int16), 'sform_code': tensor([2, 2], dtype=torch.int16), 'quatern_b': tensor([0., 0.]), 'quatern_c': tensor([0., 0.]), 'quatern_d': tensor([0., 0.]), 'qoffset_x': tensor([0., 0.]), 'qoffset_y': tensor([0., 0.]), 'qoffset_z': tensor([0., 0.]), 'srow_x': tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]]), 'srow_y': tensor([[0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.]]), 'srow_z': tensor([[0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.]]), 'affine': tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]]], dtype=torch.float64), 'original_affine': tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]]], dtype=torch.float64), 'as_closest_canonical': tensor([False, False]), 'spatial_shape': tensor([[128, 128, 128],\n",
      "        [128, 128, 128]], dtype=torch.int16), 'original_channel_dim': tensor([-1, -1]), 'filename_or_obj': ['data/unet_tmp/seg0.nii.gz', 'data/unet_tmp/seg1.nii.gz'], 'patch_index': tensor([1, 1])}, 'img_transforms': [{'class': ['RandCropByPosNegLabeld', 'RandCropByPosNegLabeld'], 'id': tensor([140527689923024, 140527689923024]), 'orig_size': [tensor([128, 128]), tensor([128, 128]), tensor([128, 128])], 'extra_info': {'center': [tensor([66, 80]), tensor([63, 48]), tensor([60, 48])]}}, {'class': ['RandRotate90d', 'RandRotate90d'], 'id': tensor([140527689923120, 140527689923120]), 'orig_size': [tensor([96, 96]), tensor([96, 96]), tensor([96, 96])], 'extra_info': {'rand_k': tensor([2, 1])}, 'do_transforms': tensor([False,  True])}, {'class': ['EnsureTyped', 'EnsureTyped'], 'id': tensor([140527689923168, 140527689923168]), 'orig_size': [tensor([96, 96]), tensor([96, 96]), tensor([96, 96])]}], 'seg_transforms': [{'class': ['RandCropByPosNegLabeld', 'RandCropByPosNegLabeld'], 'id': tensor([140527689923024, 140527689923024]), 'orig_size': [tensor([128, 128]), tensor([128, 128]), tensor([128, 128])], 'extra_info': {'center': [tensor([66, 80]), tensor([63, 48]), tensor([60, 48])]}}, {'class': ['RandRotate90d', 'RandRotate90d'], 'id': tensor([140527689923120, 140527689923120]), 'orig_size': [tensor([96, 96]), tensor([96, 96]), tensor([96, 96])], 'extra_info': {'rand_k': tensor([2, 1])}, 'do_transforms': tensor([False,  True])}, {'class': ['EnsureTyped', 'EnsureTyped'], 'id': tensor([140527689923168, 140527689923168]), 'orig_size': [tensor([96, 96]), tensor([96, 96]), tensor([96, 96])]}]}, {'img': tensor([[[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]]]), 'seg': tensor([[[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]]]), 'img_meta_dict': {'sizeof_hdr': tensor([348, 348], dtype=torch.int32), 'extents': tensor([0, 0], dtype=torch.int32), 'session_error': tensor([0, 0], dtype=torch.int16), 'dim_info': tensor([0, 0], dtype=torch.uint8), 'dim': tensor([[  4, 128, 128, 128,   1,   1,   1,   1],\n",
      "        [  4, 128, 128, 128,   1,   1,   1,   1]], dtype=torch.int16), 'intent_p1': tensor([0., 0.]), 'intent_p2': tensor([0., 0.]), 'intent_p3': tensor([0., 0.]), 'intent_code': tensor([0, 0], dtype=torch.int16), 'datatype': tensor([16, 16], dtype=torch.int16), 'bitpix': tensor([32, 32], dtype=torch.int16), 'slice_start': tensor([0, 0], dtype=torch.int16), 'pixdim': tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]]), 'vox_offset': tensor([0., 0.]), 'scl_slope': tensor([nan, nan]), 'scl_inter': tensor([nan, nan]), 'slice_end': tensor([0, 0], dtype=torch.int16), 'slice_code': tensor([0, 0], dtype=torch.uint8), 'xyzt_units': tensor([0, 0], dtype=torch.uint8), 'cal_max': tensor([0., 0.]), 'cal_min': tensor([0., 0.]), 'slice_duration': tensor([0., 0.]), 'toffset': tensor([0., 0.]), 'glmax': tensor([0, 0], dtype=torch.int32), 'glmin': tensor([0, 0], dtype=torch.int32), 'qform_code': tensor([0, 0], dtype=torch.int16), 'sform_code': tensor([2, 2], dtype=torch.int16), 'quatern_b': tensor([0., 0.]), 'quatern_c': tensor([0., 0.]), 'quatern_d': tensor([0., 0.]), 'qoffset_x': tensor([0., 0.]), 'qoffset_y': tensor([0., 0.]), 'qoffset_z': tensor([0., 0.]), 'srow_x': tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]]), 'srow_y': tensor([[0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.]]), 'srow_z': tensor([[0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.]]), 'affine': tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]]], dtype=torch.float64), 'original_affine': tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]]], dtype=torch.float64), 'as_closest_canonical': tensor([False, False]), 'spatial_shape': tensor([[128, 128, 128],\n",
      "        [128, 128, 128]], dtype=torch.int16), 'original_channel_dim': tensor([-1, -1]), 'filename_or_obj': ['data/unet_tmp/img0.nii.gz', 'data/unet_tmp/img1.nii.gz'], 'patch_index': tensor([2, 2])}, 'seg_meta_dict': {'sizeof_hdr': tensor([348, 348], dtype=torch.int32), 'extents': tensor([0, 0], dtype=torch.int32), 'session_error': tensor([0, 0], dtype=torch.int16), 'dim_info': tensor([0, 0], dtype=torch.uint8), 'dim': tensor([[  4, 128, 128, 128,   1,   1,   1,   1],\n",
      "        [  4, 128, 128, 128,   1,   1,   1,   1]], dtype=torch.int16), 'intent_p1': tensor([0., 0.]), 'intent_p2': tensor([0., 0.]), 'intent_p3': tensor([0., 0.]), 'intent_code': tensor([0, 0], dtype=torch.int16), 'datatype': tensor([8, 8], dtype=torch.int16), 'bitpix': tensor([32, 32], dtype=torch.int16), 'slice_start': tensor([0, 0], dtype=torch.int16), 'pixdim': tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]]), 'vox_offset': tensor([0., 0.]), 'scl_slope': tensor([nan, nan]), 'scl_inter': tensor([nan, nan]), 'slice_end': tensor([0, 0], dtype=torch.int16), 'slice_code': tensor([0, 0], dtype=torch.uint8), 'xyzt_units': tensor([0, 0], dtype=torch.uint8), 'cal_max': tensor([0., 0.]), 'cal_min': tensor([0., 0.]), 'slice_duration': tensor([0., 0.]), 'toffset': tensor([0., 0.]), 'glmax': tensor([0, 0], dtype=torch.int32), 'glmin': tensor([0, 0], dtype=torch.int32), 'qform_code': tensor([0, 0], dtype=torch.int16), 'sform_code': tensor([2, 2], dtype=torch.int16), 'quatern_b': tensor([0., 0.]), 'quatern_c': tensor([0., 0.]), 'quatern_d': tensor([0., 0.]), 'qoffset_x': tensor([0., 0.]), 'qoffset_y': tensor([0., 0.]), 'qoffset_z': tensor([0., 0.]), 'srow_x': tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]]), 'srow_y': tensor([[0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.]]), 'srow_z': tensor([[0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.]]), 'affine': tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]]], dtype=torch.float64), 'original_affine': tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]]], dtype=torch.float64), 'as_closest_canonical': tensor([False, False]), 'spatial_shape': tensor([[128, 128, 128],\n",
      "        [128, 128, 128]], dtype=torch.int16), 'original_channel_dim': tensor([-1, -1]), 'filename_or_obj': ['data/unet_tmp/seg0.nii.gz', 'data/unet_tmp/seg1.nii.gz'], 'patch_index': tensor([2, 2])}, 'img_transforms': [{'class': ['RandCropByPosNegLabeld', 'RandCropByPosNegLabeld'], 'id': tensor([140527689923024, 140527689923024]), 'orig_size': [tensor([128, 128]), tensor([128, 128]), tensor([128, 128])], 'extra_info': {'center': [tensor([48, 63]), tensor([70, 80]), tensor([80, 71])]}}, {'class': ['RandRotate90d', 'RandRotate90d'], 'id': tensor([140527689923120, 140527689923120]), 'orig_size': [tensor([96, 96]), tensor([96, 96]), tensor([96, 96])], 'extra_info': {'rand_k': tensor([2, 1])}, 'do_transforms': tensor([False, False])}, {'class': ['EnsureTyped', 'EnsureTyped'], 'id': tensor([140527689923168, 140527689923168]), 'orig_size': [tensor([96, 96]), tensor([96, 96]), tensor([96, 96])]}], 'seg_transforms': [{'class': ['RandCropByPosNegLabeld', 'RandCropByPosNegLabeld'], 'id': tensor([140527689923024, 140527689923024]), 'orig_size': [tensor([128, 128]), tensor([128, 128]), tensor([128, 128])], 'extra_info': {'center': [tensor([48, 63]), tensor([70, 80]), tensor([80, 71])]}}, {'class': ['RandRotate90d', 'RandRotate90d'], 'id': tensor([140527689923120, 140527689923120]), 'orig_size': [tensor([96, 96]), tensor([96, 96]), tensor([96, 96])], 'extra_info': {'rand_k': tensor([2, 1])}, 'do_transforms': tensor([False, False])}, {'class': ['EnsureTyped', 'EnsureTyped'], 'id': tensor([140527689923168, 140527689923168]), 'orig_size': [tensor([96, 96]), tensor([96, 96]), tensor([96, 96])]}]}, {'img': tensor([[[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]]]), 'seg': tensor([[[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           ...,\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "           [0., 0., 0.,  ..., 0., 0., 0.]]]]]), 'img_meta_dict': {'sizeof_hdr': tensor([348, 348], dtype=torch.int32), 'extents': tensor([0, 0], dtype=torch.int32), 'session_error': tensor([0, 0], dtype=torch.int16), 'dim_info': tensor([0, 0], dtype=torch.uint8), 'dim': tensor([[  4, 128, 128, 128,   1,   1,   1,   1],\n",
      "        [  4, 128, 128, 128,   1,   1,   1,   1]], dtype=torch.int16), 'intent_p1': tensor([0., 0.]), 'intent_p2': tensor([0., 0.]), 'intent_p3': tensor([0., 0.]), 'intent_code': tensor([0, 0], dtype=torch.int16), 'datatype': tensor([16, 16], dtype=torch.int16), 'bitpix': tensor([32, 32], dtype=torch.int16), 'slice_start': tensor([0, 0], dtype=torch.int16), 'pixdim': tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]]), 'vox_offset': tensor([0., 0.]), 'scl_slope': tensor([nan, nan]), 'scl_inter': tensor([nan, nan]), 'slice_end': tensor([0, 0], dtype=torch.int16), 'slice_code': tensor([0, 0], dtype=torch.uint8), 'xyzt_units': tensor([0, 0], dtype=torch.uint8), 'cal_max': tensor([0., 0.]), 'cal_min': tensor([0., 0.]), 'slice_duration': tensor([0., 0.]), 'toffset': tensor([0., 0.]), 'glmax': tensor([0, 0], dtype=torch.int32), 'glmin': tensor([0, 0], dtype=torch.int32), 'qform_code': tensor([0, 0], dtype=torch.int16), 'sform_code': tensor([2, 2], dtype=torch.int16), 'quatern_b': tensor([0., 0.]), 'quatern_c': tensor([0., 0.]), 'quatern_d': tensor([0., 0.]), 'qoffset_x': tensor([0., 0.]), 'qoffset_y': tensor([0., 0.]), 'qoffset_z': tensor([0., 0.]), 'srow_x': tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]]), 'srow_y': tensor([[0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.]]), 'srow_z': tensor([[0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.]]), 'affine': tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]]], dtype=torch.float64), 'original_affine': tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]]], dtype=torch.float64), 'as_closest_canonical': tensor([False, False]), 'spatial_shape': tensor([[128, 128, 128],\n",
      "        [128, 128, 128]], dtype=torch.int16), 'original_channel_dim': tensor([-1, -1]), 'filename_or_obj': ['data/unet_tmp/img0.nii.gz', 'data/unet_tmp/img1.nii.gz'], 'patch_index': tensor([3, 3])}, 'seg_meta_dict': {'sizeof_hdr': tensor([348, 348], dtype=torch.int32), 'extents': tensor([0, 0], dtype=torch.int32), 'session_error': tensor([0, 0], dtype=torch.int16), 'dim_info': tensor([0, 0], dtype=torch.uint8), 'dim': tensor([[  4, 128, 128, 128,   1,   1,   1,   1],\n",
      "        [  4, 128, 128, 128,   1,   1,   1,   1]], dtype=torch.int16), 'intent_p1': tensor([0., 0.]), 'intent_p2': tensor([0., 0.]), 'intent_p3': tensor([0., 0.]), 'intent_code': tensor([0, 0], dtype=torch.int16), 'datatype': tensor([8, 8], dtype=torch.int16), 'bitpix': tensor([32, 32], dtype=torch.int16), 'slice_start': tensor([0, 0], dtype=torch.int16), 'pixdim': tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]]), 'vox_offset': tensor([0., 0.]), 'scl_slope': tensor([nan, nan]), 'scl_inter': tensor([nan, nan]), 'slice_end': tensor([0, 0], dtype=torch.int16), 'slice_code': tensor([0, 0], dtype=torch.uint8), 'xyzt_units': tensor([0, 0], dtype=torch.uint8), 'cal_max': tensor([0., 0.]), 'cal_min': tensor([0., 0.]), 'slice_duration': tensor([0., 0.]), 'toffset': tensor([0., 0.]), 'glmax': tensor([0, 0], dtype=torch.int32), 'glmin': tensor([0, 0], dtype=torch.int32), 'qform_code': tensor([0, 0], dtype=torch.int16), 'sform_code': tensor([2, 2], dtype=torch.int16), 'quatern_b': tensor([0., 0.]), 'quatern_c': tensor([0., 0.]), 'quatern_d': tensor([0., 0.]), 'qoffset_x': tensor([0., 0.]), 'qoffset_y': tensor([0., 0.]), 'qoffset_z': tensor([0., 0.]), 'srow_x': tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]]), 'srow_y': tensor([[0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.]]), 'srow_z': tensor([[0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.]]), 'affine': tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]]], dtype=torch.float64), 'original_affine': tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]]], dtype=torch.float64), 'as_closest_canonical': tensor([False, False]), 'spatial_shape': tensor([[128, 128, 128],\n",
      "        [128, 128, 128]], dtype=torch.int16), 'original_channel_dim': tensor([-1, -1]), 'filename_or_obj': ['data/unet_tmp/seg0.nii.gz', 'data/unet_tmp/seg1.nii.gz'], 'patch_index': tensor([3, 3])}, 'img_transforms': [{'class': ['RandCropByPosNegLabeld', 'RandCropByPosNegLabeld'], 'id': tensor([140527689923024, 140527689923024]), 'orig_size': [tensor([128, 128]), tensor([128, 128]), tensor([128, 128])], 'extra_info': {'center': [tensor([73, 48]), tensor([61, 80]), tensor([54, 64])]}}, {'class': ['RandRotate90d', 'RandRotate90d'], 'id': tensor([140527689923120, 140527689923120]), 'orig_size': [tensor([96, 96]), tensor([96, 96]), tensor([96, 96])], 'extra_info': {'rand_k': tensor([3, 1])}, 'do_transforms': tensor([True, True])}, {'class': ['EnsureTyped', 'EnsureTyped'], 'id': tensor([140527689923168, 140527689923168]), 'orig_size': [tensor([96, 96]), tensor([96, 96]), tensor([96, 96])]}], 'seg_transforms': [{'class': ['RandCropByPosNegLabeld', 'RandCropByPosNegLabeld'], 'id': tensor([140527689923024, 140527689923024]), 'orig_size': [tensor([128, 128]), tensor([128, 128]), tensor([128, 128])], 'extra_info': {'center': [tensor([73, 48]), tensor([61, 80]), tensor([54, 64])]}}, {'class': ['RandRotate90d', 'RandRotate90d'], 'id': tensor([140527689923120, 140527689923120]), 'orig_size': [tensor([96, 96]), tensor([96, 96]), tensor([96, 96])], 'extra_info': {'rand_k': tensor([3, 1])}, 'do_transforms': tensor([True, True])}, {'class': ['EnsureTyped', 'EnsureTyped'], 'id': tensor([140527689923168, 140527689923168]), 'orig_size': [tensor([96, 96]), tensor([96, 96]), tensor([96, 96])]}]}]\n"
     ]
    }
   ],
   "source": [
    "# 만약 list_data_collate를 안준다면?\n",
    "check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "check_loader_test = DataLoader(check_ds, batch_size=2, num_workers=4)\n",
    "check_data_test = monai.utils.misc.first(check_loader_test)\n",
    "print(len(check_data_test))    # RandCrop sample 수 : 4 \n",
    "print(check_data_test[0][\"img\"].shape)   # torch.Size([2, 1, 96, 96, 96])  # batch가 2개임\n",
    "print(check_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b640e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f717669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db447634",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "# create a validation data loader\n",
    "val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, collate_fn=list_data_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f86d84c",
   "metadata": {},
   "source": [
    "### post-proc, metric, model, loss,  정의\n",
    "* 아예 차이 없음\n",
    "\n",
    "### training 정의\n",
    "* data 분리할 때 외엔 거의 차이 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "878e80a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "epoch: 1/50 \n",
      "1/10, train_loss: 0.6403\n",
      "2/10, train_loss: 0.6004\n",
      "3/10, train_loss: 0.6406\n",
      "4/10, train_loss: 0.5386\n",
      "5/10, train_loss: 0.5179\n",
      "6/10, train_loss: 0.5563\n",
      "7/10, train_loss: 0.4939\n",
      "8/10, train_loss: 0.4896\n",
      "9/10, train_loss: 0.4794\n",
      "10/10, train_loss: 0.4999\n",
      "epoch 1 average loss: 0.5457\n",
      "saved new best metric model\n",
      "current epoch: 1 current mean dice: 0.8196 best mean dice: 0.8196 at epoch 1\n",
      "--------------------\n",
      "epoch: 2/50 \n",
      "1/10, train_loss: 0.4481\n",
      "2/10, train_loss: 0.4910\n",
      "3/10, train_loss: 0.4345\n",
      "4/10, train_loss: 0.5354\n",
      "5/10, train_loss: 0.4631\n",
      "6/10, train_loss: 0.4383\n",
      "7/10, train_loss: 0.4603\n",
      "8/10, train_loss: 0.4566\n",
      "9/10, train_loss: 0.4265\n",
      "10/10, train_loss: 0.5626\n",
      "epoch 2 average loss: 0.4716\n",
      "saved new best metric model\n",
      "current epoch: 2 current mean dice: 0.8881 best mean dice: 0.8881 at epoch 2\n",
      "--------------------\n",
      "epoch: 3/50 \n",
      "1/10, train_loss: 0.4258\n",
      "2/10, train_loss: 0.5167\n",
      "3/10, train_loss: 0.4474\n",
      "4/10, train_loss: 0.4517\n",
      "5/10, train_loss: 0.4503\n",
      "6/10, train_loss: 0.4454\n",
      "7/10, train_loss: 0.3847\n",
      "8/10, train_loss: 0.4438\n",
      "9/10, train_loss: 0.4122\n",
      "10/10, train_loss: 0.4443\n",
      "epoch 3 average loss: 0.4422\n",
      "saved new best metric model\n",
      "current epoch: 3 current mean dice: 0.9028 best mean dice: 0.9028 at epoch 3\n",
      "--------------------\n",
      "epoch: 4/50 \n",
      "1/10, train_loss: 0.3879\n",
      "2/10, train_loss: 0.3915\n",
      "3/10, train_loss: 0.3926\n",
      "4/10, train_loss: 0.5390\n",
      "5/10, train_loss: 0.4584\n",
      "6/10, train_loss: 0.4732\n",
      "7/10, train_loss: 0.3616\n",
      "8/10, train_loss: 0.4304\n",
      "9/10, train_loss: 0.4050\n",
      "10/10, train_loss: 0.4621\n",
      "epoch 4 average loss: 0.4302\n",
      "saved new best metric model\n",
      "current epoch: 4 current mean dice: 0.9159 best mean dice: 0.9159 at epoch 4\n",
      "--------------------\n",
      "epoch: 5/50 \n",
      "1/10, train_loss: 0.3901\n",
      "2/10, train_loss: 0.3856\n",
      "3/10, train_loss: 0.4092\n",
      "4/10, train_loss: 0.4313\n",
      "5/10, train_loss: 0.3779\n",
      "6/10, train_loss: 0.3602\n",
      "7/10, train_loss: 0.4023\n",
      "8/10, train_loss: 0.5488\n",
      "9/10, train_loss: 0.3853\n",
      "10/10, train_loss: 0.4221\n",
      "epoch 5 average loss: 0.4113\n",
      "saved new best metric model\n",
      "current epoch: 5 current mean dice: 0.9270 best mean dice: 0.9270 at epoch 5\n",
      "--------------------\n",
      "epoch: 6/50 \n",
      "1/10, train_loss: 0.3695\n",
      "2/10, train_loss: 0.5675\n",
      "3/10, train_loss: 0.3997\n",
      "4/10, train_loss: 0.4350\n",
      "5/10, train_loss: 0.3681\n",
      "6/10, train_loss: 0.4838\n",
      "7/10, train_loss: 0.3721\n",
      "8/10, train_loss: 0.3460\n",
      "9/10, train_loss: 0.3915\n",
      "10/10, train_loss: 0.3697\n",
      "epoch 6 average loss: 0.4103\n",
      "saved new best metric model\n",
      "current epoch: 6 current mean dice: 0.9304 best mean dice: 0.9304 at epoch 6\n",
      "--------------------\n",
      "epoch: 7/50 \n",
      "1/10, train_loss: 0.4354\n",
      "2/10, train_loss: 0.3753\n",
      "3/10, train_loss: 0.3078\n",
      "4/10, train_loss: 0.4087\n",
      "5/10, train_loss: 0.3660\n",
      "6/10, train_loss: 0.4543\n",
      "7/10, train_loss: 0.3959\n",
      "8/10, train_loss: 0.3339\n",
      "9/10, train_loss: 0.3685\n",
      "10/10, train_loss: 0.3749\n",
      "epoch 7 average loss: 0.3821\n",
      "saved new best metric model\n",
      "current epoch: 7 current mean dice: 0.9337 best mean dice: 0.9337 at epoch 7\n",
      "--------------------\n",
      "epoch: 8/50 \n",
      "1/10, train_loss: 0.3575\n",
      "2/10, train_loss: 0.4424\n",
      "3/10, train_loss: 0.3285\n",
      "4/10, train_loss: 0.3880\n",
      "5/10, train_loss: 0.3205\n",
      "6/10, train_loss: 0.3799\n",
      "7/10, train_loss: 0.3305\n",
      "8/10, train_loss: 0.5052\n",
      "9/10, train_loss: 0.4009\n",
      "10/10, train_loss: 0.3635\n",
      "epoch 8 average loss: 0.3817\n",
      "saved new best metric model\n",
      "current epoch: 8 current mean dice: 0.9407 best mean dice: 0.9407 at epoch 8\n",
      "--------------------\n",
      "epoch: 9/50 \n",
      "1/10, train_loss: 0.3659\n",
      "2/10, train_loss: 0.4035\n",
      "3/10, train_loss: 0.3309\n",
      "4/10, train_loss: 0.3804\n",
      "5/10, train_loss: 0.3464\n",
      "6/10, train_loss: 0.4053\n",
      "7/10, train_loss: 0.3119\n",
      "8/10, train_loss: 0.4422\n",
      "9/10, train_loss: 0.4115\n",
      "10/10, train_loss: 0.3078\n",
      "epoch 9 average loss: 0.3706\n",
      "current epoch: 9 current mean dice: 0.9402 best mean dice: 0.9407 at epoch 8\n",
      "--------------------\n",
      "epoch: 10/50 \n",
      "1/10, train_loss: 0.2843\n",
      "2/10, train_loss: 0.3671\n",
      "3/10, train_loss: 0.2836\n",
      "4/10, train_loss: 0.2967\n",
      "5/10, train_loss: 0.3872\n",
      "6/10, train_loss: 0.4939\n",
      "7/10, train_loss: 0.3191\n",
      "8/10, train_loss: 0.4100\n",
      "9/10, train_loss: 0.3422\n",
      "10/10, train_loss: 0.3870\n",
      "epoch 10 average loss: 0.3571\n",
      "saved new best metric model\n",
      "current epoch: 10 current mean dice: 0.9449 best mean dice: 0.9449 at epoch 10\n",
      "--------------------\n",
      "epoch: 11/50 \n",
      "1/10, train_loss: 0.4053\n",
      "2/10, train_loss: 0.3062\n",
      "3/10, train_loss: 0.3364\n",
      "4/10, train_loss: 0.4174\n",
      "5/10, train_loss: 0.3415\n",
      "6/10, train_loss: 0.2711\n",
      "7/10, train_loss: 0.3262\n",
      "8/10, train_loss: 0.4608\n",
      "9/10, train_loss: 0.3253\n",
      "10/10, train_loss: 0.3546\n",
      "epoch 11 average loss: 0.3545\n",
      "saved new best metric model\n",
      "current epoch: 11 current mean dice: 0.9461 best mean dice: 0.9461 at epoch 11\n",
      "--------------------\n",
      "epoch: 12/50 \n",
      "1/10, train_loss: 0.3487\n",
      "2/10, train_loss: 0.2810\n",
      "3/10, train_loss: 0.2617\n",
      "4/10, train_loss: 0.2946\n",
      "5/10, train_loss: 0.2956\n",
      "6/10, train_loss: 0.2983\n",
      "7/10, train_loss: 0.3292\n",
      "8/10, train_loss: 0.3860\n",
      "9/10, train_loss: 0.4510\n",
      "10/10, train_loss: 0.3711\n",
      "epoch 12 average loss: 0.3317\n",
      "saved new best metric model\n",
      "current epoch: 12 current mean dice: 0.9516 best mean dice: 0.9516 at epoch 12\n",
      "--------------------\n",
      "epoch: 13/50 \n",
      "1/10, train_loss: 0.3975\n",
      "2/10, train_loss: 0.3062\n",
      "3/10, train_loss: 0.2716\n",
      "4/10, train_loss: 0.4905\n",
      "5/10, train_loss: 0.3556\n",
      "6/10, train_loss: 0.2929\n",
      "7/10, train_loss: 0.2681\n",
      "8/10, train_loss: 0.3221\n",
      "9/10, train_loss: 0.2764\n",
      "10/10, train_loss: 0.2667\n",
      "epoch 13 average loss: 0.3248\n",
      "saved new best metric model\n",
      "current epoch: 13 current mean dice: 0.9534 best mean dice: 0.9534 at epoch 13\n",
      "--------------------\n",
      "epoch: 14/50 \n",
      "1/10, train_loss: 0.2704\n",
      "2/10, train_loss: 0.3551\n",
      "3/10, train_loss: 0.3412\n",
      "4/10, train_loss: 0.2551\n",
      "5/10, train_loss: 0.4509\n",
      "6/10, train_loss: 0.2786\n",
      "7/10, train_loss: 0.2801\n",
      "8/10, train_loss: 0.2151\n",
      "9/10, train_loss: 0.3110\n",
      "10/10, train_loss: 0.3695\n",
      "epoch 14 average loss: 0.3127\n",
      "saved new best metric model\n",
      "current epoch: 14 current mean dice: 0.9556 best mean dice: 0.9556 at epoch 14\n",
      "--------------------\n",
      "epoch: 15/50 \n",
      "1/10, train_loss: 0.3340\n",
      "2/10, train_loss: 0.2828\n",
      "3/10, train_loss: 0.2879\n",
      "4/10, train_loss: 0.2693\n",
      "5/10, train_loss: 0.2586\n",
      "6/10, train_loss: 0.2860\n",
      "7/10, train_loss: 0.3928\n",
      "8/10, train_loss: 0.2870\n",
      "9/10, train_loss: 0.3035\n",
      "10/10, train_loss: 0.3273\n",
      "epoch 15 average loss: 0.3029\n",
      "saved new best metric model\n",
      "current epoch: 15 current mean dice: 0.9580 best mean dice: 0.9580 at epoch 15\n",
      "--------------------\n",
      "epoch: 16/50 \n",
      "1/10, train_loss: 0.4186\n",
      "2/10, train_loss: 0.3018\n",
      "3/10, train_loss: 0.2409\n",
      "4/10, train_loss: 0.2297\n",
      "5/10, train_loss: 0.2450\n",
      "6/10, train_loss: 0.3300\n",
      "7/10, train_loss: 0.2828\n",
      "8/10, train_loss: 0.3151\n",
      "9/10, train_loss: 0.2453\n",
      "10/10, train_loss: 0.2221\n",
      "epoch 16 average loss: 0.2831\n",
      "saved new best metric model\n",
      "current epoch: 16 current mean dice: 0.9598 best mean dice: 0.9598 at epoch 16\n",
      "--------------------\n",
      "epoch: 17/50 \n",
      "1/10, train_loss: 0.2285\n",
      "2/10, train_loss: 0.1972\n",
      "3/10, train_loss: 0.2510\n",
      "4/10, train_loss: 0.2750\n",
      "5/10, train_loss: 0.3059\n",
      "6/10, train_loss: 0.4083\n",
      "7/10, train_loss: 0.2490\n",
      "8/10, train_loss: 0.2925\n",
      "9/10, train_loss: 0.2303\n",
      "10/10, train_loss: 0.2492\n",
      "epoch 17 average loss: 0.2687\n",
      "saved new best metric model\n",
      "current epoch: 17 current mean dice: 0.9635 best mean dice: 0.9635 at epoch 17\n",
      "--------------------\n",
      "epoch: 18/50 \n",
      "1/10, train_loss: 0.3369\n",
      "2/10, train_loss: 0.2079\n",
      "3/10, train_loss: 0.3221\n",
      "4/10, train_loss: 0.2057\n",
      "5/10, train_loss: 0.2660\n",
      "6/10, train_loss: 0.2369\n",
      "7/10, train_loss: 0.2730\n",
      "8/10, train_loss: 0.2669\n",
      "9/10, train_loss: 0.2260\n",
      "10/10, train_loss: 0.2369\n",
      "epoch 18 average loss: 0.2578\n",
      "saved new best metric model\n",
      "current epoch: 18 current mean dice: 0.9653 best mean dice: 0.9653 at epoch 18\n",
      "--------------------\n",
      "epoch: 19/50 \n",
      "1/10, train_loss: 0.3337\n",
      "2/10, train_loss: 0.2949\n",
      "3/10, train_loss: 0.1932\n",
      "4/10, train_loss: 0.2700\n",
      "5/10, train_loss: 0.2264\n",
      "6/10, train_loss: 0.2672\n",
      "7/10, train_loss: 0.2085\n",
      "8/10, train_loss: 0.2717\n",
      "9/10, train_loss: 0.2180\n",
      "10/10, train_loss: 0.2552\n",
      "epoch 19 average loss: 0.2539\n",
      "saved new best metric model\n",
      "current epoch: 19 current mean dice: 0.9665 best mean dice: 0.9665 at epoch 19\n",
      "--------------------\n",
      "epoch: 20/50 \n",
      "1/10, train_loss: 0.2299\n",
      "2/10, train_loss: 0.1865\n",
      "3/10, train_loss: 0.2782\n",
      "4/10, train_loss: 0.1798\n",
      "5/10, train_loss: 0.2061\n",
      "6/10, train_loss: 0.2994\n",
      "7/10, train_loss: 0.2085\n",
      "8/10, train_loss: 0.1793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/10, train_loss: 0.2615\n",
      "10/10, train_loss: 0.2339\n",
      "epoch 20 average loss: 0.2263\n",
      "saved new best metric model\n",
      "current epoch: 20 current mean dice: 0.9709 best mean dice: 0.9709 at epoch 20\n",
      "--------------------\n",
      "epoch: 21/50 \n",
      "1/10, train_loss: 0.2362\n",
      "2/10, train_loss: 0.2848\n",
      "3/10, train_loss: 0.1479\n",
      "4/10, train_loss: 0.3767\n",
      "5/10, train_loss: 0.1655\n",
      "6/10, train_loss: 0.2136\n",
      "7/10, train_loss: 0.2139\n",
      "8/10, train_loss: 0.1610\n",
      "9/10, train_loss: 0.1954\n",
      "10/10, train_loss: 0.2174\n",
      "epoch 21 average loss: 0.2212\n",
      "saved new best metric model\n",
      "current epoch: 21 current mean dice: 0.9740 best mean dice: 0.9740 at epoch 21\n",
      "--------------------\n",
      "epoch: 22/50 \n",
      "1/10, train_loss: 0.1784\n",
      "2/10, train_loss: 0.3761\n",
      "3/10, train_loss: 0.1859\n",
      "4/10, train_loss: 0.1714\n",
      "5/10, train_loss: 0.2011\n",
      "6/10, train_loss: 0.1899\n",
      "7/10, train_loss: 0.1461\n",
      "8/10, train_loss: 0.1715\n",
      "9/10, train_loss: 0.1960\n",
      "10/10, train_loss: 0.1772\n",
      "epoch 22 average loss: 0.1994\n",
      "current epoch: 22 current mean dice: 0.9728 best mean dice: 0.9740 at epoch 21\n",
      "--------------------\n",
      "epoch: 23/50 \n",
      "1/10, train_loss: 0.2314\n",
      "2/10, train_loss: 0.1709\n",
      "3/10, train_loss: 0.1465\n",
      "4/10, train_loss: 0.1368\n",
      "5/10, train_loss: 0.1395\n",
      "6/10, train_loss: 0.1808\n",
      "7/10, train_loss: 0.3170\n",
      "8/10, train_loss: 0.1868\n",
      "9/10, train_loss: 0.1865\n",
      "10/10, train_loss: 0.1693\n",
      "epoch 23 average loss: 0.1866\n",
      "saved new best metric model\n",
      "current epoch: 23 current mean dice: 0.9766 best mean dice: 0.9766 at epoch 23\n",
      "--------------------\n",
      "epoch: 24/50 \n",
      "1/10, train_loss: 0.2215\n",
      "2/10, train_loss: 0.1586\n",
      "3/10, train_loss: 0.1538\n",
      "4/10, train_loss: 0.1866\n",
      "5/10, train_loss: 0.3312\n",
      "6/10, train_loss: 0.1766\n",
      "7/10, train_loss: 0.1208\n",
      "8/10, train_loss: 0.1049\n",
      "9/10, train_loss: 0.2016\n",
      "10/10, train_loss: 0.1470\n",
      "epoch 24 average loss: 0.1803\n",
      "saved new best metric model\n",
      "current epoch: 24 current mean dice: 0.9800 best mean dice: 0.9800 at epoch 24\n",
      "--------------------\n",
      "epoch: 25/50 \n",
      "1/10, train_loss: 0.1383\n",
      "2/10, train_loss: 0.1973\n",
      "3/10, train_loss: 0.1402\n",
      "4/10, train_loss: 0.1322\n",
      "5/10, train_loss: 0.1414\n",
      "6/10, train_loss: 0.1758\n",
      "7/10, train_loss: 0.1446\n",
      "8/10, train_loss: 0.1460\n",
      "9/10, train_loss: 0.2951\n",
      "10/10, train_loss: 0.1197\n",
      "epoch 25 average loss: 0.1631\n",
      "saved new best metric model\n",
      "current epoch: 25 current mean dice: 0.9812 best mean dice: 0.9812 at epoch 25\n",
      "--------------------\n",
      "epoch: 26/50 \n",
      "1/10, train_loss: 0.2217\n",
      "2/10, train_loss: 0.1576\n",
      "3/10, train_loss: 0.1086\n",
      "4/10, train_loss: 0.1688\n",
      "5/10, train_loss: 0.2778\n",
      "6/10, train_loss: 0.1609\n",
      "7/10, train_loss: 0.1119\n",
      "8/10, train_loss: 0.0770\n",
      "9/10, train_loss: 0.1440\n",
      "10/10, train_loss: 0.1688\n",
      "epoch 26 average loss: 0.1597\n",
      "saved new best metric model\n",
      "current epoch: 26 current mean dice: 0.9838 best mean dice: 0.9838 at epoch 26\n",
      "--------------------\n",
      "epoch: 27/50 \n",
      "1/10, train_loss: 0.1356\n",
      "2/10, train_loss: 0.1228\n",
      "3/10, train_loss: 0.1284\n",
      "4/10, train_loss: 0.3137\n",
      "5/10, train_loss: 0.1454\n",
      "6/10, train_loss: 0.0676\n",
      "7/10, train_loss: 0.1528\n",
      "8/10, train_loss: 0.1321\n",
      "9/10, train_loss: 0.1156\n",
      "10/10, train_loss: 0.1517\n",
      "epoch 27 average loss: 0.1466\n",
      "saved new best metric model\n",
      "current epoch: 27 current mean dice: 0.9864 best mean dice: 0.9864 at epoch 27\n",
      "--------------------\n",
      "epoch: 28/50 \n",
      "1/10, train_loss: 0.1451\n",
      "2/10, train_loss: 0.1152\n",
      "3/10, train_loss: 0.1039\n",
      "4/10, train_loss: 0.1127\n",
      "5/10, train_loss: 0.1739\n",
      "6/10, train_loss: 0.1314\n",
      "7/10, train_loss: 0.1428\n",
      "8/10, train_loss: 0.0874\n",
      "9/10, train_loss: 0.1288\n",
      "10/10, train_loss: 0.2301\n",
      "epoch 28 average loss: 0.1371\n",
      "current epoch: 28 current mean dice: 0.9858 best mean dice: 0.9864 at epoch 27\n",
      "--------------------\n",
      "epoch: 29/50 \n",
      "1/10, train_loss: 0.1009\n",
      "2/10, train_loss: 0.0904\n",
      "3/10, train_loss: 0.1364\n",
      "4/10, train_loss: 0.0820\n",
      "5/10, train_loss: 0.1342\n",
      "6/10, train_loss: 0.1205\n",
      "7/10, train_loss: 0.0925\n",
      "8/10, train_loss: 0.1383\n",
      "9/10, train_loss: 0.1493\n",
      "10/10, train_loss: 0.2197\n",
      "epoch 29 average loss: 0.1264\n",
      "saved new best metric model\n",
      "current epoch: 29 current mean dice: 0.9879 best mean dice: 0.9879 at epoch 29\n",
      "--------------------\n",
      "epoch: 30/50 \n",
      "1/10, train_loss: 0.2448\n",
      "2/10, train_loss: 0.1239\n",
      "3/10, train_loss: 0.1230\n",
      "4/10, train_loss: 0.0963\n",
      "5/10, train_loss: 0.1571\n",
      "6/10, train_loss: 0.0991\n",
      "7/10, train_loss: 0.0646\n",
      "8/10, train_loss: 0.0997\n",
      "9/10, train_loss: 0.1181\n",
      "10/10, train_loss: 0.1205\n",
      "epoch 30 average loss: 0.1247\n",
      "saved new best metric model\n",
      "current epoch: 30 current mean dice: 0.9905 best mean dice: 0.9905 at epoch 30\n",
      "--------------------\n",
      "epoch: 31/50 \n",
      "1/10, train_loss: 0.0705\n",
      "2/10, train_loss: 0.1532\n",
      "3/10, train_loss: 0.0945\n",
      "4/10, train_loss: 0.1036\n",
      "5/10, train_loss: 0.2079\n",
      "6/10, train_loss: 0.0527\n",
      "7/10, train_loss: 0.0993\n",
      "8/10, train_loss: 0.1155\n",
      "9/10, train_loss: 0.0652\n",
      "10/10, train_loss: 0.0732\n",
      "epoch 31 average loss: 0.1036\n",
      "current epoch: 31 current mean dice: 0.9890 best mean dice: 0.9905 at epoch 30\n",
      "--------------------\n",
      "epoch: 32/50 \n",
      "1/10, train_loss: 0.0664\n",
      "2/10, train_loss: 0.0896\n",
      "3/10, train_loss: 0.2217\n",
      "4/10, train_loss: 0.1481\n",
      "5/10, train_loss: 0.1304\n",
      "6/10, train_loss: 0.0794\n",
      "7/10, train_loss: 0.0815\n",
      "8/10, train_loss: 0.0547\n",
      "9/10, train_loss: 0.0711\n",
      "10/10, train_loss: 0.0861\n",
      "epoch 32 average loss: 0.1029\n",
      "current epoch: 32 current mean dice: 0.9897 best mean dice: 0.9905 at epoch 30\n",
      "--------------------\n",
      "epoch: 33/50 \n",
      "1/10, train_loss: 0.0772\n",
      "2/10, train_loss: 0.0622\n",
      "3/10, train_loss: 0.1395\n",
      "4/10, train_loss: 0.0647\n",
      "5/10, train_loss: 0.0863\n",
      "6/10, train_loss: 0.0990\n",
      "7/10, train_loss: 0.1808\n",
      "8/10, train_loss: 0.0990\n",
      "9/10, train_loss: 0.0710\n",
      "10/10, train_loss: 0.0582\n",
      "epoch 33 average loss: 0.0938\n",
      "saved new best metric model\n",
      "current epoch: 33 current mean dice: 0.9920 best mean dice: 0.9920 at epoch 33\n",
      "--------------------\n",
      "epoch: 34/50 \n",
      "1/10, train_loss: 0.0499\n",
      "2/10, train_loss: 0.0548\n",
      "3/10, train_loss: 0.1311\n",
      "4/10, train_loss: 0.0573\n",
      "5/10, train_loss: 0.0969\n",
      "6/10, train_loss: 0.0579\n",
      "7/10, train_loss: 0.2276\n",
      "8/10, train_loss: 0.0638\n",
      "9/10, train_loss: 0.0929\n",
      "10/10, train_loss: 0.0661\n",
      "epoch 34 average loss: 0.0898\n",
      "saved new best metric model\n",
      "current epoch: 34 current mean dice: 0.9938 best mean dice: 0.9938 at epoch 34\n",
      "--------------------\n",
      "epoch: 35/50 \n",
      "1/10, train_loss: 0.0451\n",
      "2/10, train_loss: 0.0701\n",
      "3/10, train_loss: 0.0541\n",
      "4/10, train_loss: 0.2111\n",
      "5/10, train_loss: 0.0741\n",
      "6/10, train_loss: 0.0787\n",
      "7/10, train_loss: 0.1038\n",
      "8/10, train_loss: 0.1002\n",
      "9/10, train_loss: 0.0733\n",
      "10/10, train_loss: 0.0614\n",
      "epoch 35 average loss: 0.0872\n",
      "current epoch: 35 current mean dice: 0.9924 best mean dice: 0.9938 at epoch 34\n",
      "--------------------\n",
      "epoch: 36/50 \n",
      "1/10, train_loss: 0.1457\n",
      "2/10, train_loss: 0.0645\n",
      "3/10, train_loss: 0.0403\n",
      "4/10, train_loss: 0.0976\n",
      "5/10, train_loss: 0.0967\n",
      "6/10, train_loss: 0.0803\n",
      "7/10, train_loss: 0.0406\n",
      "8/10, train_loss: 0.0559\n",
      "9/10, train_loss: 0.0882\n",
      "10/10, train_loss: 0.0522\n",
      "epoch 36 average loss: 0.0762\n",
      "saved new best metric model\n",
      "current epoch: 36 current mean dice: 0.9941 best mean dice: 0.9941 at epoch 36\n",
      "--------------------\n",
      "epoch: 37/50 \n",
      "1/10, train_loss: 0.1617\n",
      "2/10, train_loss: 0.0361\n",
      "3/10, train_loss: 0.0862\n",
      "4/10, train_loss: 0.0916\n",
      "5/10, train_loss: 0.0669\n",
      "6/10, train_loss: 0.0580\n",
      "7/10, train_loss: 0.0395\n",
      "8/10, train_loss: 0.0728\n",
      "9/10, train_loss: 0.0645\n",
      "10/10, train_loss: 0.0545\n",
      "epoch 37 average loss: 0.0732\n",
      "saved new best metric model\n",
      "current epoch: 37 current mean dice: 0.9944 best mean dice: 0.9944 at epoch 37\n",
      "--------------------\n",
      "epoch: 38/50 \n",
      "1/10, train_loss: 0.0433\n",
      "2/10, train_loss: 0.1015\n",
      "3/10, train_loss: 0.0656\n",
      "4/10, train_loss: 0.0644\n",
      "5/10, train_loss: 0.0608\n",
      "6/10, train_loss: 0.0597\n",
      "7/10, train_loss: 0.1492\n",
      "8/10, train_loss: 0.0515\n",
      "9/10, train_loss: 0.0381\n",
      "10/10, train_loss: 0.0566\n",
      "epoch 38 average loss: 0.0691\n",
      "saved new best metric model\n",
      "current epoch: 38 current mean dice: 0.9949 best mean dice: 0.9949 at epoch 38\n",
      "--------------------\n",
      "epoch: 39/50 \n",
      "1/10, train_loss: 0.0601\n",
      "2/10, train_loss: 0.0282\n",
      "3/10, train_loss: 0.0466\n",
      "4/10, train_loss: 0.0438\n",
      "5/10, train_loss: 0.0948\n",
      "6/10, train_loss: 0.0472\n",
      "7/10, train_loss: 0.0421\n",
      "8/10, train_loss: 0.0598\n",
      "9/10, train_loss: 0.0561\n",
      "10/10, train_loss: 0.1382\n",
      "epoch 39 average loss: 0.0617\n",
      "current epoch: 39 current mean dice: 0.9948 best mean dice: 0.9949 at epoch 38\n",
      "--------------------\n",
      "epoch: 40/50 \n",
      "1/10, train_loss: 0.0463\n",
      "2/10, train_loss: 0.0449\n",
      "3/10, train_loss: 0.0384\n",
      "4/10, train_loss: 0.0356\n",
      "5/10, train_loss: 0.0843\n",
      "6/10, train_loss: 0.0261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/10, train_loss: 0.0541\n",
      "8/10, train_loss: 0.0450\n",
      "9/10, train_loss: 0.0615\n",
      "10/10, train_loss: 0.1239\n",
      "epoch 40 average loss: 0.0560\n",
      "current epoch: 40 current mean dice: 0.9941 best mean dice: 0.9949 at epoch 38\n",
      "--------------------\n",
      "epoch: 41/50 \n",
      "1/10, train_loss: 0.0396\n",
      "2/10, train_loss: 0.0494\n",
      "3/10, train_loss: 0.0293\n",
      "4/10, train_loss: 0.0361\n",
      "5/10, train_loss: 0.0568\n",
      "6/10, train_loss: 0.0580\n",
      "7/10, train_loss: 0.0388\n",
      "8/10, train_loss: 0.0261\n",
      "9/10, train_loss: 0.1204\n",
      "10/10, train_loss: 0.0670\n",
      "epoch 41 average loss: 0.0521\n",
      "saved new best metric model\n",
      "current epoch: 41 current mean dice: 0.9952 best mean dice: 0.9952 at epoch 41\n",
      "--------------------\n",
      "epoch: 42/50 \n",
      "1/10, train_loss: 0.0397\n",
      "2/10, train_loss: 0.0432\n",
      "3/10, train_loss: 0.0842\n",
      "4/10, train_loss: 0.0743\n",
      "5/10, train_loss: 0.1566\n",
      "6/10, train_loss: 0.0410\n",
      "7/10, train_loss: 0.0295\n",
      "8/10, train_loss: 0.0250\n",
      "9/10, train_loss: 0.0421\n",
      "10/10, train_loss: 0.0474\n",
      "epoch 42 average loss: 0.0583\n",
      "saved new best metric model\n",
      "current epoch: 42 current mean dice: 0.9964 best mean dice: 0.9964 at epoch 42\n",
      "--------------------\n",
      "epoch: 43/50 \n",
      "1/10, train_loss: 0.0805\n",
      "2/10, train_loss: 0.1305\n",
      "3/10, train_loss: 0.0493\n",
      "4/10, train_loss: 0.0289\n",
      "5/10, train_loss: 0.0343\n",
      "6/10, train_loss: 0.0228\n",
      "7/10, train_loss: 0.0484\n",
      "8/10, train_loss: 0.0228\n",
      "9/10, train_loss: 0.0496\n",
      "10/10, train_loss: 0.0408\n",
      "epoch 43 average loss: 0.0508\n",
      "saved new best metric model\n",
      "current epoch: 43 current mean dice: 0.9970 best mean dice: 0.9970 at epoch 43\n",
      "--------------------\n",
      "epoch: 44/50 \n",
      "1/10, train_loss: 0.0295\n",
      "2/10, train_loss: 0.0297\n",
      "3/10, train_loss: 0.0458\n",
      "4/10, train_loss: 0.0283\n",
      "5/10, train_loss: 0.0397\n",
      "6/10, train_loss: 0.0376\n",
      "7/10, train_loss: 0.0363\n",
      "8/10, train_loss: 0.1119\n",
      "9/10, train_loss: 0.0524\n",
      "10/10, train_loss: 0.0683\n",
      "epoch 44 average loss: 0.0479\n",
      "current epoch: 44 current mean dice: 0.9965 best mean dice: 0.9970 at epoch 43\n",
      "--------------------\n",
      "epoch: 45/50 \n",
      "1/10, train_loss: 0.0187\n",
      "2/10, train_loss: 0.0296\n",
      "3/10, train_loss: 0.0278\n",
      "4/10, train_loss: 0.0434\n",
      "5/10, train_loss: 0.0376\n",
      "6/10, train_loss: 0.0270\n",
      "7/10, train_loss: 0.0335\n",
      "8/10, train_loss: 0.0302\n",
      "9/10, train_loss: 0.0604\n",
      "10/10, train_loss: 0.1181\n",
      "epoch 45 average loss: 0.0426\n",
      "current epoch: 45 current mean dice: 0.9969 best mean dice: 0.9970 at epoch 43\n",
      "--------------------\n",
      "epoch: 46/50 \n",
      "1/10, train_loss: 0.0511\n",
      "2/10, train_loss: 0.0208\n",
      "3/10, train_loss: 0.1174\n",
      "4/10, train_loss: 0.0477\n",
      "5/10, train_loss: 0.0344\n",
      "6/10, train_loss: 0.0217\n",
      "7/10, train_loss: 0.0283\n",
      "8/10, train_loss: 0.0334\n",
      "9/10, train_loss: 0.0462\n",
      "10/10, train_loss: 0.0470\n",
      "epoch 46 average loss: 0.0448\n",
      "current epoch: 46 current mean dice: 0.9963 best mean dice: 0.9970 at epoch 43\n",
      "--------------------\n",
      "epoch: 47/50 \n",
      "1/10, train_loss: 0.0305\n",
      "2/10, train_loss: 0.0590\n",
      "3/10, train_loss: 0.0361\n",
      "4/10, train_loss: 0.0205\n",
      "5/10, train_loss: 0.0309\n",
      "6/10, train_loss: 0.1462\n",
      "7/10, train_loss: 0.0163\n",
      "8/10, train_loss: 0.0318\n",
      "9/10, train_loss: 0.0357\n",
      "10/10, train_loss: 0.0494\n",
      "epoch 47 average loss: 0.0456\n",
      "saved new best metric model\n",
      "current epoch: 47 current mean dice: 0.9971 best mean dice: 0.9971 at epoch 47\n",
      "--------------------\n",
      "epoch: 48/50 \n",
      "1/10, train_loss: 0.0279\n",
      "2/10, train_loss: 0.0625\n",
      "3/10, train_loss: 0.0271\n",
      "4/10, train_loss: 0.0454\n",
      "5/10, train_loss: 0.0323\n",
      "6/10, train_loss: 0.0165\n",
      "7/10, train_loss: 0.0244\n",
      "8/10, train_loss: 0.1234\n",
      "9/10, train_loss: 0.0178\n",
      "10/10, train_loss: 0.0281\n",
      "epoch 48 average loss: 0.0405\n",
      "current epoch: 48 current mean dice: 0.9967 best mean dice: 0.9971 at epoch 47\n",
      "--------------------\n",
      "epoch: 49/50 \n",
      "1/10, train_loss: 0.0207\n",
      "2/10, train_loss: 0.0382\n",
      "3/10, train_loss: 0.0273\n",
      "4/10, train_loss: 0.1005\n",
      "5/10, train_loss: 0.0234\n",
      "6/10, train_loss: 0.0288\n",
      "7/10, train_loss: 0.0334\n",
      "8/10, train_loss: 0.0200\n",
      "9/10, train_loss: 0.0216\n",
      "10/10, train_loss: 0.0597\n",
      "epoch 49 average loss: 0.0374\n",
      "saved new best metric model\n",
      "current epoch: 49 current mean dice: 0.9971 best mean dice: 0.9971 at epoch 49\n",
      "--------------------\n",
      "epoch: 50/50 \n",
      "1/10, train_loss: 0.0450\n",
      "2/10, train_loss: 0.1286\n",
      "3/10, train_loss: 0.0229\n",
      "4/10, train_loss: 0.0317\n",
      "5/10, train_loss: 0.0242\n",
      "6/10, train_loss: 0.0165\n",
      "7/10, train_loss: 0.0206\n",
      "8/10, train_loss: 0.0491\n",
      "9/10, train_loss: 0.0282\n",
      "10/10, train_loss: 0.0239\n",
      "epoch 50 average loss: 0.0391\n",
      "current epoch: 50 current mean dice: 0.9969 best mean dice: 0.9971 at epoch 49\n",
      "train completed, best_metric: 0.9971 at epoch: 49\n"
     ]
    }
   ],
   "source": [
    "post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = monai.networks.nets.UNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        channels=(16, 32, 64, 128, 256),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=2,\n",
    "    ).to(device)\n",
    "loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "\n",
    "epochs = 50\n",
    "epoch_loss_values = list()   # for training loss\n",
    "val_interval = 1\n",
    "metric_values = list()   # for validation metric\n",
    "best_metric = -1\n",
    "best_epoch = -1\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('-'*20)\n",
    "    print(f'epoch: {epoch + 1}/{epochs} ')\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch[\"img\"].to(device), batch[\"seg\"].to(device)  # dic form\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size\n",
    "        print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_images = None\n",
    "            val_labels = None\n",
    "            val_outputs = None\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)  # dic form\n",
    "                roi_size = (96, 96, 96)\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
    "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            dice_metric.reset()\n",
    "            metric_values.append(metric)\n",
    "\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), \"./models/best_metric_model_segmentation3d_dict.pth\")\n",
    "                print(\"saved new best metric model\")\n",
    "\n",
    "            print(\n",
    "                \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n",
    "                    epoch + 1, metric, best_metric, best_epoch )\n",
    "            )\n",
    "            writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n",
    "            # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
    "            plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
    "            plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
    "            plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
    "                \n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_epoch}\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0350a41d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c4df0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
