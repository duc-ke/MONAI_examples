{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8354e5bc",
   "metadata": {},
   "source": [
    "다음을 리뷰 :\n",
    "https://github.com/Project-MONAI/tutorials/blob/master/3d_segmentation/torch/unet_training_dict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e7d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib    # nifti 포맷 파일 생성때만 이용\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import monai\n",
    "## decollate_batch : 배치 텐서를 리스트의 텐서로 변환\n",
    "from monai.data import create_test_image_3d, decollate_batch\n",
    "# from monai.transforms import RandSpatialCrop, ScaleIntensity, EnsureType\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.visualize import plot_2d_or_3d_image\n",
    "# tensorboard가 읽을 수 있도록 loss, metric, out image, out_seg 를 기록 \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "## 삭제\n",
    "from monai.data import ImageDataset\n",
    "from monai.transforms import AddChannel\n",
    "\n",
    "# 이건 image, seg 파일 배열을 넣어주면 데이터셋을 만들어주는 API인듯하다. segmentation 한정 사용가능\n",
    "# train_ds = ImageDataset(images[:20], segs[:20], transform=train_imtrans, seg_transform=train_segtrans)\n",
    "\n",
    "# AddChannel : 맨 앞단 1 차원 삽입 (ex) torch.Size([6]) -> torch.Size([1, 6]) \n",
    "\n",
    "\n",
    "## 새롭게 추가\n",
    "from monai.data import Dataset   # dict에선 ImageDataset대신 이용\n",
    "from monai.data import list_data_collate\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsChannelFirstd,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    RandCropByPosNegLabeld,  # randomly crop patch samples from big image based on pos / neg ratio.\n",
    "    RandRotate90d,\n",
    "    ScaleIntensityd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    ")\n",
    "\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0607d2a7",
   "metadata": {},
   "source": [
    "```python\n",
    "# AddChannel Test\n",
    "test = np.array([-1, -0.4, 0.2, 0.4, 0.8, 1.5])\n",
    "post_trans_test1 = Compose([EnsureType(), AddChannel()])\n",
    "print(post_trans_test1(test).shape, post_trans_test1(test))\n",
    "\n",
    "post_trans_test2 = Compose([EnsureType()])\n",
    "print(post_trans_test2(test).shape, post_trans_test2(test))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fbbf335",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ca19b7",
   "metadata": {},
   "source": [
    "### making random 3D segmentation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "347f4822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.9.dev2152\n",
      "Numpy version: 1.21.2\n",
      "Pytorch version: 1.10.0a0+0aef44c\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: c5bd8aff8ba461d7b349eb92427d452481a7eb72\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.6\n",
      "Nibabel version: 3.2.1\n",
      "scikit-image version: 0.18.3\n",
      "Pillow version: 8.4.0\n",
      "Tensorboard version: 2.6.0\n",
      "gdown version: 4.2.0\n",
      "TorchVision version: 0.11.0a0\n",
      "tqdm version: 4.62.3\n",
      "lmdb version: 1.2.1\n",
      "psutil version: 5.8.0\n",
      "pandas version: 1.3.4\n",
      "einops version: 0.3.2\n",
      "transformers version: 4.12.5\n",
      "mlflow version: 1.21.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "generating synthetic data to ./dataset (this may take a while)\n"
     ]
    }
   ],
   "source": [
    "tempdir = './dataset'\n",
    "monai.config.print_config()\n",
    "\n",
    "\n",
    "# 디렉토리에 40개 랜덤이미지, 마스크 생성\n",
    "print(f\"generating synthetic data to {tempdir} (this may take a while)\")\n",
    "for i in range(40):\n",
    "    # np image 생성\n",
    "    im, seg = create_test_image_3d(128, 128, 128, num_seg_classes=1, channel_dim=-1)  \n",
    "#     print(type(im), type(seg))  # np.array\n",
    "#     print(im.shape, seg.shape)  # (128, 128, 128) (128, 128, 128) 3d 라서 img, seg가 같은 dim인 듯?\n",
    "#     print(im)\n",
    "\n",
    "#     print(np.eye(4))  # 2차원 identity 행렬(4x4) 생성\n",
    "    n = nib.Nifti1Image(im, np.eye(4))\n",
    "#     print(type(n), n)   # nifti 이미지\n",
    "    nib.save(n, os.path.join(tempdir, f\"img{i:d}.nii.gz\"))\n",
    "\n",
    "    n = nib.Nifti1Image(seg, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, f\"seg{i:d}.nii.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9bd407",
   "metadata": {},
   "source": [
    "### image, seg 파일 dict Loading\n",
    "\n",
    "* 참고: list form에선, 이미지리스트를 그대로 사용하여 ds를 만듦\n",
    "```python \n",
    "# list form\n",
    "train_ds = ImageDataset(images[:20], segs[:20], transform=train_imtrans, seg_transform=train_segtrans)\n",
    "val_ds = ImageDataset(images[-20:], segs[-20:], transform=val_imtrans, seg_transform=val_segtrans)\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b815c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sorted(glob(os.path.join(tempdir, \"img*.nii.gz\")))    # 40개 nifti file 리스트\n",
    "segs = sorted(glob(os.path.join(tempdir, \"seg*.nii.gz\")))\n",
    "\n",
    "train_files = [{\"img\": img, \"seg\": seg}for img, seg in zip(images[:20], segs[:20])]\n",
    "val_files = [{\"img\": img, \"seg\": seg}for img, seg in zip(images[-20:], segs[-20:])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e164e7",
   "metadata": {},
   "source": [
    "### Transform 정의\n",
    "* 참고: list form에선, img, seg에 해당하는 각각의 transform을 따로 정의하여 사용함\n",
    "```python\n",
    "train_imtrans = Compose(\n",
    "    [\n",
    "        ScaleIntensity(),\n",
    "        AddChannel(),\n",
    "        # aug\n",
    "        RandSpatialCrop((96, 96, 96), random_size=False),\n",
    "        RandRotate90(prob=0.5, spatial_axes=(0, 2)),\n",
    "        EnsureType(),\n",
    "    ]\n",
    ")\n",
    "train_segtrans = Compose(\n",
    "    [\n",
    "        # 스케일링 필요없나 봄 (1또는 0이므로)\n",
    "        AddChannel(),\n",
    "        # aug (img와 같은 aug를 해주는가..? -> 맞음.. 왜인진.. 모름)\n",
    "        RandSpatialCrop((96, 96, 96), random_size=False),\n",
    "        RandRotate90(prob=0.5, spatial_axes=(0, 2)),\n",
    "        EnsureType(),\n",
    "    ]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da9f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),   # list에선 ImageDataset을 대신썻기 때문에 LoadImage가 포함되어있었음\n",
    "        AsChannelFirstd(keys=[\"img\", \"seg\"], channel_dim=-1),\n",
    "        ScaleIntensityd(keys=\"img\"),   # scaling은 img에만.\n",
    "        # aug\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"img\", \"seg\"],\n",
    "            label_key=\"seg\",\n",
    "            spatial_size=[96, 96, 96],\n",
    "            pos=1,   # foreground voxel as a center rather than a background voxel. ``pos / (pos + neg)``\n",
    "            neg=1,\n",
    "            num_samples=4    # 1개 이미지당 4개 결과생성. 즉 4배로 뻥튀기\n",
    "        ),\n",
    "        RandRotate90d(keys=[\"img\", \"seg\"], prob=0.5, spatial_axes=[0, 2]),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"])\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),  \n",
    "        AsChannelFirstd(keys=[\"img\", \"seg\"], channel_dim=-1),\n",
    "        ScaleIntensityd(keys=\"img\"), \n",
    "        EnsureTyped(keys=[\"img\", \"seg\"])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 잘 되는지 프로세스 검증\n",
    "check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "# RandCrop에서 samples 4개 만들면, 이게 리스트로 만들어짐. 이걸 풀어서 tensor 하나에 8개(2x4)를 넣어주는게 list_data_collate임\n",
    "check_loader = DataLoader(check_ds, batch_size=2, num_workers=4, collate_fn=list_data_collate)\n",
    "# check_loader = DataLoader(check_ds, batch_size=2, num_workers=4)\n",
    "check_data = monai.utils.misc.first(check_loader)\n",
    "print(check_data[\"img\"].shape, check_data[\"seg\"].shape)\n",
    "\n",
    "# torch.Size([8, 1, 96, 96, 96]) torch.Size([8, 1, 96, 96, 96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db447634",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "# create a validation data loader\n",
    "val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, collate_fn=list_data_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f86d84c",
   "metadata": {},
   "source": [
    "### post-proc, metric, model, loss,  정의\n",
    "* 아예 차이 없음\n",
    "\n",
    "### training 정의\n",
    "* data 분리할 때 외엔 거의 차이 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878e80a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = monai.networks.nets.UNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        channels=(16, 32, 64, 128, 256),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=2,\n",
    "    ).to(device)\n",
    "loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
    "\n",
    "epochs = 5\n",
    "epoch_loss_values = list()   # for training loss\n",
    "val_interval = 1\n",
    "metric_values = list()   # for validation metric\n",
    "best_metric = -1\n",
    "best_epoch = -1\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('-'*20)\n",
    "    print(f'epoch: {epoch + 1}/{epochs} ')\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch[\"img\"].to(device), batch[\"seg\"].to(device)  # dic form\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size\n",
    "        print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_images = None\n",
    "            val_labels = None\n",
    "            val_outputs = None\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)  # dic form\n",
    "                roi_size = (96, 96, 96)\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
    "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            dice_metric.reset()\n",
    "            metric_values.append(metric)\n",
    "\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), \"./models/best_metric_model_segmentation3d_dict.pth\")\n",
    "                print(\"saved new best metric model\")\n",
    "\n",
    "            print(\n",
    "                \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n",
    "                    epoch + 1, metric, best_metric, best_epoch )\n",
    "            )\n",
    "            writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n",
    "            # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
    "            plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
    "            plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
    "            plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
    "                \n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_epoch}\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0350a41d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
