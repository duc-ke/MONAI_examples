{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duc-ke/MONAI_examples/blob/main/sp3_st6_inference_FashionMNIST_igniteList-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMov-LUSabxx"
      },
      "source": [
        "# Convolutional Neural Networks for Classifying Fashion-MNIST Dataset using Ignite\n",
        "This is a tutorial on using Ignite to train neural network models, setup experiments and validate models.\n",
        "\n",
        "In this notebook, we will be doing classification of images using Convolutional Neural Networks \n",
        "\n",
        "We will be using the [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist) Fashion-MNIST is a set of 28x28 grayscale images of clothes.\n",
        "\n",
        "![Fashion MNIST dataset](https://github.com/abdulelahsm/ignite/blob/update-tutorials/examples/notebooks/assets/fashion-mnist.png?raw=1)\n",
        "\n",
        "Lets get started!\n",
        "\n",
        "\n",
        "----\n",
        "28x28 grayscale 이미지"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXZxwFvCGqz0"
      },
      "source": [
        "## Required Dependencies\n",
        "\n",
        "We assume that `torch` and `ignite` are already installed. We can install it using `pip`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "A7LJdJfU6pra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63092eaf-2708-4608-cb46-0d27cb914bb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.8-py3-none-any.whl (251 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▎                              | 10 kB 27.1 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 20 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 40 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 51 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 81 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 92 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 251 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.10.0.2)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.8\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-ignite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PiU02-fabxz"
      },
      "source": [
        "### Importing libraries\n",
        "\n",
        "General Data-Science Libraries like numpy, matplotlib and seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZC7eCA942-B"
      },
      "outputs": [],
      "source": [
        "# !pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-FlbGAEe6prv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp_4isvHabx5"
      },
      "source": [
        "We import `torch`, `nn` and `functional` modules to create our models.\n",
        "\n",
        "We also import `datasets` and `transforms` from torchvision for loading the dataset and applying transforms to the images in the dataset.\n",
        "\n",
        "We import `Dataloader` for making train and validation loader for loading data into our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "E-OllAGT6pr-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QDr20jEt42-C",
        "outputId": "a3640537-9576-417d-81bb-7320da9c4131"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.10.0+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj7oLY36abx8"
      },
      "source": [
        "`Ignite` is a High-level library to help with training neural networks in PyTorch. It comes with an `Engine` to setup a training loop, various metrics, handlers and a helpful contrib section! \n",
        "\n",
        "Below we import the following:\n",
        "* **Engine**: Runs a given process_function over each batch of a dataset, emitting events as it goes.(주어진 process_function을 실행하여 이벤트를 발생)\n",
        "* **Events**: Allows users to attach functions to an `Engine` to fire functions at a specific event. Eg: `EPOCH_COMPLETED`, `ITERATION_STARTED`, etc.\n",
        "* **Accuracy**: Metric to calculate accuracy over a dataset, for binary, multiclass, multilabel cases. \n",
        "* **Loss**: General metric that takes a loss function as a parameter, calculate loss over a dataset.\n",
        "* **RunningAverage**: General metric to attach to Engine during training. \n",
        "* **ModelCheckpoint**: Handler to checkpoint models. \n",
        "* **EarlyStopping**: Handler to stop training based on a score function. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YodbjXPi6psK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d878d543-f0d5-4e89-e3d3-db0fd4f68e49"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b36e9a3bf4e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## trainer, evaluator를 create 에서 가져와서 씀\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_supervised_trainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_supervised_evaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunningAverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfusionMatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ignite'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "## trainer, evaluator를 create 에서 가져와서 씀\n",
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
        "from ignite.metrics import Accuracy, Loss, RunningAverage, ConfusionMatrix\n",
        "from ignite.handlers import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FD8C9B3I42-E"
      },
      "outputs": [],
      "source": [
        "from ignite.contrib.handlers import ProgressBar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO53-X98abx-"
      },
      "source": [
        "The code below first sets up transform using `torhvision transfroms` for converting images to pytorch tensors and normalizing the images.\n",
        "\n",
        "Next, We use `torchvision datasets` for dowloading the fashion mnist dataset and applying transforms which we defined above.\n",
        "\n",
        "* `trainset` contains the training data.\n",
        "* `validationset` contains the validation data\n",
        "\n",
        "Next, We use `pytorch dataloader` for making dataloader from the train and validation sets.\n",
        "\n",
        "-----\n",
        "torchvision transform : 이미지를 텐서 변환, 정규화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbwRHbz542-F"
      },
      "outputs": [],
      "source": [
        "# !pip install ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2dqyxnr6psU"
      },
      "outputs": [],
      "source": [
        "# transform to normalize the data\n",
        "# gray 이미지기 때문에 1 채널 밖에 없음\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.FashionMNIST('./data', download=True, train=True, transform=transform)\n",
        "train_loader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "validationset = datasets.FashionMNIST('./data', download=True, train=False, transform=transform)\n",
        "val_loader = DataLoader(validationset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWTe0FXM42-F",
        "outputId": "dd47b9ad-78e5-42e9-df56-91b11533ee18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aaa = next(iter(train_loader))\n",
        "len(aaa)   # img와 label 두개임, dict form 이였다면 aaa에 aaa['img'], aaa['seg']로 접근했어야 함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78Mir2P442-G",
        "outputId": "4c714e15-e043-4d52-80b6-1874773922d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 흑백이미지라서 Channel이 1임\n",
        "aaa[0].shape, aaa[1].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvzm-Oe1abyB"
      },
      "source": [
        "### CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf4AVJ44abyC"
      },
      "source": [
        "Explanation of Model Architecture\n",
        "\n",
        "* [Convolutional layers](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html), the Convolutional layer is used to create a convolution kernel that is convolved with the layer input to produce a tensor of outputs.\n",
        "* [Maxpooling layers](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html), the Maxpooling layer is used to downsample an input representation keeping the most active pixels from the previous layer.\n",
        "* The usual [Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) + [Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout2d.html) layers to avoid overfitting and produce a 10-dim output.\n",
        "* We had used [Relu](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) Non Linearity for the model and [logsoftmax](https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html) at the last layer because we are going to use the [NLLL loss](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AST_DtTC6psh"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        \n",
        "        self.convlayer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3,padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        \n",
        "        self.convlayer2 = nn.Sequential(\n",
        "            nn.Conv2d(32,64,3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        \n",
        "        self.fc1 = nn.Linear(64*6*6,600)\n",
        "        self.drop = nn.Dropout2d(0.25)\n",
        "        self.fc2 = nn.Linear(600, 120)\n",
        "        self.fc3 = nn.Linear(120, 10)   # 마지막 출력을 10개로\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.convlayer1(x)\n",
        "        x = self.convlayer2(x)\n",
        "        x = x.view(-1,64*6*6)\n",
        "        x = self.fc1(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)   \n",
        "        \n",
        "        return F.log_softmax(x,dim=1)   # log_softmax로 10개 확률값 취하기(multiclasses classification적용)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqvY1QLBabyE"
      },
      "source": [
        "### Creating Model, Optimizer and Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z2zUS5zabyF"
      },
      "source": [
        "Below we create an instance of the CNN model. The model is placed on a device and then a loss function of `negative log likelihood loss` and `Adam optimizer` with learning rate of 0.001 are setup. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SfOLmfc42-H"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '6'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXyVBBYw6pst"
      },
      "outputs": [],
      "source": [
        "# creating model,and defining optimizer and loss\n",
        "model = CNN()\n",
        "# moving model to gpu if available\n",
        "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.NLLLoss()    # negative log likelihood loss. \n",
        "# 만약 crossentropy loss를 사용하면 마지막 레이어에 log_softmax를 사용안해도 됌."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o69S4bEvabyI"
      },
      "source": [
        "### Training and Evaluating using Ignite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PALFpjYoabyJ"
      },
      "source": [
        "### Instantiating Training and Evaluating Engines\n",
        "\n",
        "Below we create 3 engines, a trainer, an evaluator for the training set and an evaluator for the validation set, by using the `create_supervised_trainer` and `create_supervised_evaluator` and passing the required arguments.\n",
        "\n",
        "We import the metrics from `ignite.metrics` which we want to calculate for the model. Like `Accuracy`, `ConfusionMatrix`, and `Loss` and we pass them to `evaluator` engines which will calculate these metrics for each iteration.\n",
        "\n",
        "* `training_history`: it stores the training loss and accuracy\n",
        "* `validation_history`:it stores the validation loss and accuracy\n",
        "* `last_epoch`: it stores the last epoch untill the model is trained\n",
        "\n",
        "\n",
        "----\n",
        "* create_supvervised.. 를 쓰면 trainer, train set+vadiation set에 대한 evaluator 3가지를 쉽게 얻을 수 있다.\n",
        "* metrics로 accuracy, confusionmatrix, loss를 가져옴.\n",
        "* 그외 변수 3가지를 추가로 생성하여 history 기록\n",
        "  * training_history : loss, accuracy저장, \n",
        "  * val~~ : loss, accuracy 저장\n",
        "  * last_epoch : 마지막 epoch를 저장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMO-8kmP42-I"
      },
      "source": [
        "## 중요\n",
        "1. evaluator를 validation만 하지말고 train evaluator를 생성하면 train loss뿐 아니라 metrics를 따로 기록할 수 있다!!!!\n",
        "2. 또한 pytorch 로 직접 짜지 않아도 loss 와 metric을 저장할 변수를 만들어서 custom logging을 trainer에 붙일 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7EaSDMW6ps5"
      },
      "outputs": [],
      "source": [
        "# defining the number of epochs\n",
        "epochs = 12\n",
        "# creating trainer,evaluator\n",
        "# dict form이 아니라서 prepare batch 함수를 따로 전달할 필요가 없다.\n",
        "\"\"\" 예시) dict form 인경우 인덱스 접근이 불가하므로 직접 key를 이용하여 찢어서 넣어줘야 한다.\n",
        "def prepare_batch(batch, device=None, non_blocking=False):\n",
        "    return _prepare_batch((batch[\"img\"], batch[\"seg\"]), device, non_blocking)\n",
        "\n",
        "\n",
        "## Ignite - create_supervised_trainer\n",
        "trainer = create_supervised_trainer(\n",
        "    net, opt, loss, device, False, prepare_batch=prepare_batch\n",
        ")\n",
        "\"\"\"\n",
        "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
        "\n",
        "## engine.state.metrics에 아래의 키값들이 저장됌.\n",
        "metrics = {\n",
        "    'accuracy':Accuracy(),\n",
        "    'nll':Loss(criterion),\n",
        "    'cm':ConfusionMatrix(num_classes=10)\n",
        "}\n",
        "train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
        "val_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
        "training_history = {'accuracy':[],'loss':[]}\n",
        "validation_history = {'accuracy':[],'loss':[]}\n",
        "last_epoch = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aonym06RabyL"
      },
      "source": [
        "### Metrics - RunningAverage\n",
        "\n",
        "To start, we will attach a metric of `RunningAverage` to track a running average of the scalar loss output for each batch. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LXaAfga6ptD"
      },
      "outputs": [],
      "source": [
        "# 이걸 뺴면 어떻게 될지 확인해보자.!!!!!!!!!!!!!!\n",
        "# engine's state metrics['loss']에 값을 넣게 된다. -> progressbar에서 추적\n",
        "RunningAverage(output_transform=lambda x: x).attach(trainer, 'loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljcmQIFE42-J"
      },
      "outputs": [],
      "source": [
        "# Ignite의 progress bar를 trainer에 연결, metrics 키를 전달. 이렇게 되면 진행바는 engine.state.metrics['loss']를 추적함\n",
        "pbar = ProgressBar(persist=True, bar_format=\"\")\n",
        "pbar.attach(trainer, ['loss'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vDAID6BabyP"
      },
      "source": [
        "### EarlyStopping - Tracking Validation Loss\n",
        "\n",
        "Now we will setup a `EarlyStopping` handler for this training process. EarlyStopping requires a score_function that allows the user to define whatever criteria to stop trainig. In this case, if the loss of the validation set does not decrease in 10 epochs, the training process will stop early. Since the `EarlyStopping` handler relies on the validation loss, it's attached to the `val_evaluator`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mcIq0lc6ptN",
        "outputId": "91c0e089-6179-4f88-eb27-0fdc1bd2670b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<ignite.engine.events.RemovableEventHandle at 0x7f49b73b1bb0>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def score_function(engine):\n",
        "    val_loss = engine.state.metrics['nll']\n",
        "    return -val_loss   # -를 붙이면 낮을 수록 좋음\n",
        "\n",
        "handler = EarlyStopping(patience=10, score_function=score_function, trainer=trainer)\n",
        "val_evaluator.add_event_handler(Events.COMPLETED, handler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZzf0wtLabyR"
      },
      "source": [
        "### Attaching Custom Functions to Engine at specific Events\n",
        "\n",
        "Below you will see ways to define your own custom functions and attaching them to various `Events` of the training process.\n",
        "\n",
        "The functions below both achieve similar tasks, they print the results of the evaluator run on a dataset. One function does that on the training evaluator and dataset, while the other on the validation. Another difference is how these functions are attached in the trainer engine.\n",
        "\n",
        "The first method involves using a decorator, the syntax is simple - `@` `trainer.on(Events.EPOCH_COMPLETED)`, means that the decorated function will be attached to the trainer and called at the end of each epoch. \n",
        "\n",
        "The second method involves using the add_event_handler method of trainer - `trainer.add_event_handler(Events.EPOCH_COMPLETED, custom_function)`. This achieves the same result as the above. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMAJW26x42-K"
      },
      "source": [
        "**커스텀 log 출력함수를 만든다.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFQNaZDx6ptV",
        "outputId": "faede6aa-404b-48c0-bc3b-d72519fc5fbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<ignite.engine.events.RemovableEventHandle at 0x7f49b73a0bb0>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# log 출력 함수\n",
        "# training시, train evaluator의 loss, accuracy + validation evluateor의 loss, accuracy 출력\n",
        "\n",
        "@trainer.on(Events.EPOCH_COMPLETED)\n",
        "def log_training_results(trainer):\n",
        "    train_evaluator.run(train_loader)\n",
        "    metrics = train_evaluator.state.metrics\n",
        "    accuracy = metrics['accuracy']*100\n",
        "    loss = metrics['nll']\n",
        "    last_epoch.append(0)    # last_epoch.append(trainer.state.epoch) 아닌가?\n",
        "    training_history['accuracy'].append(accuracy)  # 이렇게 중간 결과를 저장가능하다!\n",
        "    training_history['loss'].append(loss)\n",
        "    print(\"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
        "          .format(trainer.state.epoch, accuracy, loss))\n",
        "\n",
        "def log_validation_results(trainer):\n",
        "    val_evaluator.run(val_loader)\n",
        "    metrics = val_evaluator.state.metrics\n",
        "    accuracy = metrics['accuracy']*100\n",
        "    loss = metrics['nll']\n",
        "    validation_history['accuracy'].append(accuracy)\n",
        "    validation_history['loss'].append(loss)\n",
        "    print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
        "          .format(trainer.state.epoch, accuracy, loss))\n",
        "    \n",
        "trainer.add_event_handler(Events.EPOCH_COMPLETED, log_validation_results)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4ZHDOs1abyT"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5NOsTQxabyU"
      },
      "source": [
        "Confusion matrix gives us a better idea of what our classification model is getting right and what types of errors it is making.\n",
        "\n",
        "We visualize the `confusion matrix` using the `seaborn.heatmap` from `seaborn` library.\n",
        "\n",
        "----\n",
        "seaborn의 heatmap으로 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVrVyE8X6pth"
      },
      "outputs": [],
      "source": [
        "\n",
        "# validation evaluator에 연결\n",
        "\n",
        "@trainer.on(Events.COMPLETED)\n",
        "def log_confusion_matrix(trainer):\n",
        "    val_evaluator.run(val_loader)\n",
        "    metrics = val_evaluator.state.metrics\n",
        "    cm = metrics['cm']\n",
        "    cm = cm.numpy()\n",
        "    cm = cm.astype(int)\n",
        "    classes = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']\n",
        "    fig, ax = plt.subplots(figsize=(10,10))  \n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, ax = ax,fmt=\"d\")\n",
        "    # labels, title and ticks\n",
        "    ax.set_xlabel('Predicted labels')\n",
        "    ax.set_ylabel('True labels') \n",
        "    ax.set_title('Confusion Matrix') \n",
        "    ax.xaxis.set_ticklabels(classes,rotation=90)\n",
        "    ax.yaxis.set_ticklabels(classes,rotation=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX-NImoSabyW"
      },
      "source": [
        "### ModelCheckpoint\n",
        "\n",
        "Lastly, we want to checkpoint this model. It's important to do so, as training processes can be time consuming and if for some reason something goes wrong during training, a model checkpoint can be helpful to restart training from the point of failure.\n",
        "\n",
        "Below we will use Ignite's `ModelCheckpoint` handler to checkpoint models at the end of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGVhrmoZ6ptp",
        "outputId": "95bf91eb-96a1-4360-eec8-e9978a174bcc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<ignite.engine.events.RemovableEventHandle at 0x7f49b73b15b0>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpointer = ModelCheckpoint('./models', 'fashionMNIST', n_saved=2, create_dir=True, save_as_state_dict=True, require_empty=False)\n",
        "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpointer, {'fashionMNIST': model})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YK6lGPHabyY"
      },
      "source": [
        "### Run Engine\n",
        "\n",
        "Next, we will run the trainer for 12 epochs and monitor results. Below we can see that custom functions defined above helps prints the `loss` and `accuracy` per epoch.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3W2RkO542-M",
        "outputId": "5e6498cd-c61d-4ef4-9c1a-aa71054c9f58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.10.0a0+0aef44c'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lW6m6Stp6pty",
        "outputId": "46fc9077-b4ee-4e36-dade-797869c16dab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Current run is terminating due to exception: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "Engine run is terminating due to exception: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_33657/702884084.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Current run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate_single_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_fire_event\u001b[0;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mothers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/contrib/handlers/tqdm_logger.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, engine, logger, event_name)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mpbar_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_max_number_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar_total\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ignite/contrib/handlers/tqdm_logger.py\u001b[0m in \u001b[0;36m_reset\u001b[0;34m(self, pbar_total)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbar_total\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         self.pbar = self.pbar_cls(\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbar_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         )\n",
            "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0munit_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0munit_scale\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_printer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplayed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# Prepare IPython progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mIProgress\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# #187 #451 #558 #872\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;34m\"IProgress not found. Please update jupyter and ipywidgets.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;34m\" See https://ipywidgets.readthedocs.io/en/stable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
          ]
        }
      ],
      "source": [
        "trainer.run(train_loader, max_epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTwbdtI_abyg"
      },
      "source": [
        "### Plotting the loss and accuracy\n",
        "Next, we will plot the loss and accuracy which we have stored in the `training_history` and `validation_history` dictionary to see how loss and accuracy are changing with each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SptDgBR66pt4"
      },
      "outputs": [],
      "source": [
        "plt.plot(training_history['accuracy'],label=\"Training Accuracy\")\n",
        "plt.plot(validation_history['accuracy'],label=\"Validation Accuracy\")\n",
        "plt.xlabel('No. of Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(frameon=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4iomcl36pt-"
      },
      "outputs": [],
      "source": [
        "plt.plot(training_history['loss'],label=\"Training Loss\")\n",
        "plt.plot(validation_history['loss'],label=\"Validation Loss\")\n",
        "plt.xlabel('No. of Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(frameon=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW9ze2HCabyp"
      },
      "source": [
        "### Loading the saved model from the disk\n",
        "Loading the saved pytorch model from the disk for inferencing.\n",
        "\n",
        "----\n",
        "\n",
        "모델 껍데기에 pickle파일 load만하면 됌."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SU4y96CI6puH"
      },
      "outputs": [],
      "source": [
        "## 맨 마지막꺼 로드함.\n",
        "# loading the saved model\n",
        "def fetch_last_checkpoint_model_filename(model_save_path):\n",
        "    import os\n",
        "    checkpoint_files = os.listdir(model_save_path)\n",
        "    checkpoint_files = [f for f in checkpoint_files if '.pt' in f]\n",
        "    checkpoint_iter = [\n",
        "        int(x.split('_')[2].split('.')[0])\n",
        "        for x in checkpoint_files]\n",
        "    last_idx = np.array(checkpoint_iter).argmax()\n",
        "    print(checkpoint_files)\n",
        "    print(last_idx)\n",
        "    print(checkpoint_files[last_idx])\n",
        "    return os.path.join(model_save_path, checkpoint_files[last_idx])\n",
        "\n",
        "model.load_state_dict(torch.load(fetch_last_checkpoint_model_filename('./saved_models')))\n",
        "print(\"Model Loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNRWgV0Kabys"
      },
      "source": [
        "### Inferencing the model \n",
        "Below code will be used for inferencing from the model and visualizing the results.\n",
        "\n",
        "Here we do iteration from the `val_loader` and then select the class with highest probability and then compare it with actul class.\n",
        "\n",
        "------------\n",
        "* 모델 구조에서 log_softmax까진 입혀있었음.-> exponential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWojxHNy6puN"
      },
      "outputs": [],
      "source": [
        "# classes of fashion mnist dataset\n",
        "classes = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']\n",
        "# creating iterator for iterating the dataset\n",
        "dataiter = iter(val_loader)\n",
        "images, labels = dataiter.next()\n",
        "images_arr = []\n",
        "labels_arr = []\n",
        "pred_arr = []\n",
        "# moving model to cpu for inference \n",
        "model.to(\"cpu\")\n",
        "# iterating on the dataset to predict the output\n",
        "\n",
        "######### ke test\n",
        "img, label = images[0], labels[0]\n",
        "print(img.shape)    # torch.Size([1, 28, 28])\n",
        "img = img.unsqueeze(0)  \n",
        "label = label.item()  \n",
        "print(img.shape)  # batch 차원을 임의로 한개 늘림  torch.Size([1, 1, 28, 28])\n",
        "print(label)  # 1\n",
        "\n",
        "pred_img = model(img)\n",
        "print(pred_img.shape)  # torch.Size([1, 10])\n",
        "print(pred_img)  # tensor([[-25.8288,   0.0000, -29.3317, ..  -28.9239]], grad_fn=<LogSoftmaxBackward0>)\n",
        "\n",
        "pred_img = torch.exp(pred_img)  # [[3.7309e-01, 2.9141e-06, 5.7604e-01, 2.7260e-02, 2.0285e-02, .. ]]\n",
        "print(pred_img.shape, pred_img) # (1, 10)\n",
        "print(pred_img.sum())  # 1\n",
        "\n",
        "pred_img = pred_img.data.numpy().squeeze()  # 한껍데이 벗겨냄\n",
        "print(pred_img.shape) # (10, )\n",
        "\n",
        "aa = np.argmax(pred_img)  # label index출력\n",
        "print(aa)\n",
        "\n",
        "\n",
        "for i in range(0,10):\n",
        "    images_arr.append(images[i].unsqueeze(0))\n",
        "    labels_arr.append(labels[i].item())\n",
        "    ps = torch.exp(model(images_arr[i]))    # 모델 구조에서 log_softmax까진 입혀있었음.-> exponential\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "    pred_arr.append(np.argmax(ps))\n",
        "# plotting the results\n",
        "fig = plt.figure(figsize=(25,4))\n",
        "for i in range(10):\n",
        "    ax = fig.add_subplot(2, 20/2, i+1, xticks=[], yticks=[])\n",
        "    ax.imshow(images_arr[i].resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax.set_title(\"{} ({})\".format(classes[pred_arr[i]], classes[labels_arr[i]]),\n",
        "                 color=(\"green\" if pred_arr[i]==labels_arr[i] else \"red\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWXOEpQ4abyv"
      },
      "source": [
        "### Refrences \n",
        "* [Pytorch Ignite Text CNN example notebook](https://github.com/pytorch/ignite/blob/master/examples/notebooks/TextCNN.ipynb)\n",
        "* [Pytorch Ignite MNIST example](https://github.com/pytorch/ignite/blob/master/examples/mnist/mnist.py)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "sp3-st6-inference-FashionMNIST_igniteList.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}